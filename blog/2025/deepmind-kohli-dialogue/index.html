<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> DeepMind科学负责人深度访谈：如何筛选并攻克变革性挑战 | Chao Yang </title> <meta name="author" content="Chao Yang"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://emigmo.github.io/blog/2025/deepmind-kohli-dialogue/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Chao</span> Yang </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/chinese/">中文简介 </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/publications/">publications</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/projects/">projects</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/blog/">blog</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">DeepMind科学负责人深度访谈：如何筛选并攻克变革性挑战</h1> <p class="post-meta"> Created in July 15, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/category/blog"> <i class="fa-solid fa-tag fa-sm"></i> blog</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <h1 id="deepmind科学负责人深度访谈如何筛选并攻克变革性挑战">DeepMind科学负责人深度访谈：如何筛选并攻克变革性挑战</h1> <p><em>访谈对象：Pushmeet Kohli（Google DeepMind科学负责人）</em><br> <em>时间：2025年7月</em><br> <em>来源：深度访谈整理</em></p> <hr> <ul> <li><a href="#deepmind-%E7%9A%84%E7%A7%91%E5%AD%A6%E6%A1%86%E6%9E%B6%E5%A6%82%E4%BD%95%E7%AD%9B%E9%80%89%E5%B9%B6%E6%94%BB%E5%85%8B%E5%8F%98%E9%9D%A9%E6%80%A7%E6%8C%91%E6%88%98">DeepMind 的科学框架：如何筛选并攻克变革性挑战</a></li> <li><a href="#%E4%BB%8E%E4%B8%93%E7%94%A8%E6%A8%A1%E5%9E%8B%E5%88%B0%E9%80%9A%E7%94%A8%E6%99%BA%E8%83%BDimo-%E9%87%91%E7%89%8C">从专用模型到通用智能：IMO 金牌</a></li> <li><a href="#%E4%BB%8Ealphafold-%E6%95%B0%E6%8D%AE%E5%BA%93%E5%88%B0ai-%E5%8D%8F%E5%90%8C%E7%A7%91%E5%AD%A6%E5%AE%B6">从 AlphaFold 数据库到 AI 协同科学家</a></li> <li><a href="#%E6%9C%AA%E6%9D%A5%E5%B1%95%E6%9C%9B%E8%BF%88%E5%90%91%E7%A7%91%E5%AD%A6-api%E7%9A%84%E6%97%B6%E4%BB%A3">未来展望：迈向“科学 API”的时代</a></li> </ul> <p>从破解生命密码、催生诺贝尔奖级成果的 AlphaFold，到为谷歌节省数亿美元、优化千亿级别计算资源的 AlphaEvolve，再到找到连顶尖数学家都未曾发现的新解法，这些颠覆性成果的背后，并非简单的模型迭代，而是一套严谨到近乎苛刻的问题筛选法则。</p> <p>今天，Google DeepMind 科学负责人 Pushmeet Kohli 首次为我们揭开这套内部心法：他们只瞄准三类问题——具有变革性、公认 5 到 10 年内无人能解、但 DeepMind 却有信心在短时间内攻克的不可能的任务。</p> <h2 id="deepmind-的科学框架如何筛选并攻克变革性挑战">DeepMind 的科学框架：如何筛选并攻克变革性挑战</h2> <p>在访谈的一开始，Pushmeet Kohli 便明确指出，DeepMind 的科学团队并非寻求渐进式的改进，而是专注于那些能够带来变革性影响（transformative impact）的宏大目标。为了系统性地筛选这些项目，他们建立了一套独特的框架和方法论，确保资源能被投入到最关键、最有可能产生颠覆性成果的领域。</p> <p>首先，Kohli 将智能的能力划分为三个层次，这为理解 DeepMind 的问题选择提供了背景：</p> <ol> <li> <p>第一层：普遍人类智能 这是大多数人都具备的基础能力，例如图像识别、阅读手写文字等。AI 在这个领域已经取得了长足的进步</p> </li> <li> <p>第二层：专家级智能 这类智能需要经过专门的训练和学习，例如医生根据症状进行诊断，或程序员根据需求编写复杂的代码</p> </li> <li> <p>第三层：超人类智能 这是指那些即便是最聪明的人类专家也无法凭直觉或推理解决的问题。一个典型的例子就是蛋白质折叠预测：在 AlphaFold 出现之前，即使给一位顶尖生物学家一个蛋白质的氨基酸序列，他也无法直接推断出其复杂的三维结构。解决这类问题往往需要耗费数年时间和数百万美元的实验成本</p> </li> </ol> <p>DeepMind 的科学项目正是瞄准了第三个层次——那些未知的领域，致力于构建能够解决人类当前无法解决问题的智能系统。为了从众多可能性中筛选出合适的项目，团队遵循一个由三条核心原则构成的决策算法：</p> <ol> <li>变革性与可行性：项目的首要标准是必须具备产生变革性影响的潜力，无论是科学、商业还是社会层面。同时，它必须是可行的，即在科学规律的范畴内，而非像“时间旅行”那样天马行空的幻想。社区需要普遍认同该问题的解决将带来巨大价值。</li> <li>公认的难度：项目必须具有极高的挑战性，以至于行业内的普遍共识是，在未来 5 到 10 年内无人能够解决它。如果一个问题在 6 个月内就可能被其他人攻克，那么它就不属于 DeepMind 科学团队的目标范畴。他们专注于那些需要跨学科合作、顶尖 AI 研究、卓越工程能力以及庞大计算或数据资源才能解决的硬骨头</li> <li>颠覆共识的信心：尽管外界普遍认为该问题需要 5 到 10 年才能解决，但 DeepMind 团队必须有充分的信心，相信自己能够凭借独特的方法，在预期时间的一半甚至三分之一内取得突破</li> </ol> <p>只有当一个潜在项目同时满足这三个严苛的条件时，团队才会正式立项。这个框架确保了 DeepMind 能够持续地在最具挑战性的科学前沿取得突破。基于这个框架，他们产出的成果也根据其主要影响被分为三类：</p> <p>科学影响： AlphaFold 是最杰出的代表。它解决了困扰生物学界数十年的蛋白质结构预测问题，将过去耗时数年、耗资百万美元的过程缩短到几秒钟和几美分。自 2020 年发布以来，AlphaFold 已被全球科研人员广泛应用，成为引用率最高的科学论文之一，其核心贡献者 Demis Hassabis 和 John Jumper 也因此获得了诺贝尔奖，其科学影响力不言而喻。</p> <p>商业影响： AlphaEvolve 是一个很好的例子。它是一个由 Gemini 驱动的代码优化智能体，旨在解决那些顶尖计算机科学家也难以优化的复杂问题。例如，通过优化谷歌数据中心的作业调度算法，AlphaEvolve 成功节省了整个计算集群约 0.7% 的算力，这在谷歌的庞大规模下意味着巨大的成本节约。同时，它还显著提升了 Gemini 模型自身的训练速度。有趣的是，AlphaEvolve 在解决公开的数学难题时也表现出色，对 75% 的问题达到了当前最优水平，并对其中 20% 的问题找到了超越人类数学家的更优解。</p> <p>社会影响： SynthID 是一个致力于解决生成式 AI 风险的典范。随着生成内容的质量越来越高，区分真实内容和 AI 合成内容变得愈发困难。SynthID 是一种先进的数字水印技术，它可以在 AI 生成的文本、图像和视频中嵌入一种人眼无法察觉但机器可以检测的信号，且这种信号对常规的图像编辑和转换具有鲁棒性。谷歌已将该技术应用于所有模态的生成式AI内容中，旨在维护信息生态系统的透明度和可信度，让用户能够清晰地了解内容的来源。</p> <h2 id="从专用模型到通用智能imo-金牌">从专用模型到通用智能：IMO 金牌</h2> <p>国际数学奥林匹克（International Mathematical Olympiad, IMO）是中学生数学竞赛的巅峰，其问题难度极高，考验着深刻的逻辑推理和创造力。DeepMind 将其视为衡量和推动 AI 推理能力的重要标尺。访谈中，Pushmeet Kohli 详细讲述了团队如何从构建专用模型，最终发展到利用通用模型在 IMO 竞赛中取得金牌级水平的历程，这不仅是一个技术上的巨大飞跃，也体现了 DeepMind 科学团队与 Gemini 团队之间紧密的合作模式</p> <p>去年的成果是基于两个高度专业化的模型：</p> <p>AlphaGeometry： 顾名思义，这个模型专门用于解决几何问题。</p> <p>AlphaProof： 这个模型更为复杂。它的核心是一个大型语言模型（LLM），但其工作方式并非直接给出答案。它首先会将自然语言描述的数学问题，转换成一种名为 Lean 的领域特定形式化语言。Lean 语言的优势在于，任何通过它生成的证明都是可以被机器验证的，确保了结果的绝对正确性。AlphaProof 实质上是在所有可能的证明路径空间中进行智能搜索，一旦找到一条通往结论的路径，就意味着它生成了一个形式上完全正确的证明。</p> <p>这种方法虽然强大，但依赖于专门的模型和形式化语言的转换，使得整个系统较为复杂且不易普及。而今年的突破则标志着一个根本性的转变，其核心是 DeepThink，一个基于 Gemini 2.5 Pro 的模型。这一转变的背后，是两个团队之间深度的技术转移和协同创新。</p> <p>从 AlphaProof 到 DeepThink 的技术转移路径非常关键：</p> <p>1.利用专用模型生成高质量训练数据： AlphaProof 拥有一个独特的能力——它能生成海量的、经过机器验证的、绝对正确的数学问题及其证明。团队利用这个能力，让 AlphaProof 解决了成千上万甚至数百万个数学问题。</p> <p>2.反哺通用模型： 这些由 AlphaProof 生成的“问题-正确证明”数据对，构成了一个规模庞大且质量极高的训练数据集。这些数据随后被用来训练和微调下一代的 Gemini 模型。这就像是让一个初出茅庐的学生（Gemini）学习一位数学大师（AlphaProof）的所有解题过程和思路，从而极大地提升了 Gemini 在数学和逻辑推理方面的能力。</p> <p>这一策略带来了几个革命性的成果：</p> <p>从专用走向通用： 最新的 IMO 金牌级成果不再依赖于 AlphaGeometry 和 AlphaProof 这类专用模型。所有的解题能力都被成功地整合进了 DeepThink 这一通用的 Gemini 模型中。这意味着 AI 的顶尖数学能力不再是孤立的，而是成为了一个更广泛智能系统的一部分。</p> <p>实现自然语言交互： 新系统不再需要将问题翻译成 Lean 这样的形式化语言。用户可以直接用自然语言（如英语）输入 IMO 级别的复杂数学题，模型就能理解并直接给出解答过程。这极大地降低了使用门槛，使其更接近人类的自然思考和交流方式。</p> <p>当被问及这种强大的数学能力是否能泛化到其他领域时，Kohli 坦言这本身就是一个前沿的研究问题，目前尚无定论。团队正在通过严谨的消融实验（ablation studies）来系统性地研究，即通过在训练数据中添加或移除这些数学证明数据，来观察模型在其他非数学任务上的表现变化，从而以经验性的方式来探索数学推理能力与其他通用智能之间的关联。</p> <h2 id="从-alphafold-数据库到-ai-协同科学家">从 AlphaFold 数据库到 AI 协同科学家</h2> <p>Pushmeet Kohli 强调，DeepMind 的使命不仅在于实现科学突破，更在于将这些突破性的能力交到全世界的科学家手中，从而加速整个人类科学的进步。AI Co-scientist（AI 协同科学家）则代表了这一理念的未来方向。</p> <p>其中最成功的案例就是 AlphaFold。团队并没有将这个强大的蛋白质结构预测系统保留为内部工具，而是采取了多种方式使其普惠全球：</p> <p>开放数据库：他们利用 AlphaFold 预测了地球上几乎所有已知蛋白质的结构，并将这些超过 2 亿个预测结构全部免费公开在一个名为 AlphaFold Database 的数据库中。</p> <p>赋能全球研究者：这一举措彻底改变了结构生物学的研究范式。正如 Kohli 所描述的，一位在巴西或非洲研究被忽视的热带病的研究者，过去可能因为缺乏资金和设备而无法获得其研究靶点蛋白质的结构。现在，他/她只需访问一个网页，输入蛋白质序列，点击按钮，就能在几秒钟内获得高质量的结构预测。这极大地拉平了全球科研资源的差距。</p> <p>提供 API 接口： 除了数据库，他们还通过 API 的形式让开发者和研究机构能将 AlphaFold 的能力集成到自己的研究流程中。</p> <p>同样的理念也体现在其他项目中，例如 AlphaGenome，团队为其开发了定制的用户界面（UI），让研究者可以方便地探索人类基因组中的变异如何影响基因功能。这些努力的核心思想是，将复杂的 AI 模型封装成易于使用的工具，让非 AI 领域的专家也能从中受益。</p> <p>展望未来，AI Co-scientist 项目将这种理念推向了一个新的高度。它不再仅仅是一个解决特定问题的工具，而是一个模拟并增强整个科学研究过程的智能系统。</p> <p>多智能体协作系统：AI Co-scientist 的核心是一个多智能体（multi-agent）系统，其中 Gemini 模型扮演了科学研究生态中的多个不同角色。它既是“假设生成者（hypothesis generator）”，负责提出新颖的科学想法；又是“审稿人（reviewer）”和“批判者（critique）”，负责严格地审视和挑战这些想法的逻辑和可行性。系统内部会进行想法的生成、批判、排序和迭代，模拟了一个高效运转的科研团队。</p> <p>惊人的洞察力：这种内部的思想碰撞机制让系统能够产生出乎意料的深刻见解。Kohli 分享了一个轶事：团队曾邀请伦敦帝国理工学院的一位教授提供一个他所在领域的前沿难题。当团队将 AI Co-scientist 生成的几条核心假设反馈给这位教授时，他惊愕地发现，其中排名第一的假设，正是他自己的团队耗费数年心血研究、并且刚刚投稿到顶级期刊的最新成果。他一度怀疑自己的论文被泄露了。这个故事有力地证明了 AI Co-scientist 已经能够独立地思考，并触及到人类科学研究的最前沿。</p> <p>AI Co-scientist 的终极愿景：在未来，当谷歌宣布一项由 AI 促成的重大科学突破时，实现这一突破的将不再是传统的顶尖科研机构的博士团队，而可能是世界某个角落里的一位普通人，他仅仅因为拥有强大的 AI 工具作为伙伴，便得以释放其创造力，做出了诺贝尔奖级别的贡献。</p> <h2 id="未来展望迈向科学-api的时代">未来展望：迈向“科学 API”的时代</h2> <p>在访谈的最后，话题转向了对未来的展望，即我们是否会最终拥有一个“科学的 API（API for science）”。这个概念的背后，是 AI 正在逐步降低各领域专业技能门槛的大趋势。正如今天编写软件已经比十年前容易得多，未来从事高水平的科学研究是否也能变得更加普及？</p> <p>Pushmeet Kohli 对此表示了肯定的看法，但他同时指出了实现这一愿景的核心挑战——“归约问题（the specification question）”。</p> <p>无论是编程还是科学研究，最困难的部分之一往往不是执行，而是清晰、准确地定义问题本身。一个程序应该做什么？一个科学实验的目标是什么？这背后需要深刻的洞察力和严谨的逻辑。</p> <p>因此，通往“科学 API”的道路，关键在于构建能够让用户（无论是开发者还是科学家）与 AGI（通用人工智能）进行高效、自然沟通的交互界面。我们需要让 AI 更好地理解人类模糊、高层次的意图，并将其转化为精确、可执行的步骤。</p> <p>这不仅是一个技术问题，也是一个产品和设计问题。如何设计接口，如何收集和利用用户反馈，如何建立一个从人类灵感到 AGI 执行的无缝沟通渠道，将是未来几年 AI 社区需要重点解决的问题。这恰恰凸显了像主持人 Logan Kilpatrick 这样的开发者关系专家的重要性，他们是连接 AI 技术与实际使用者之间的桥梁。</p> <p>总而言之，从 AlphaFold 到 AI Co-scientist，再到对未来“科学 API”的构想，DeepMind 正在系统性地利用 AI 解锁科学的边界，并致力于将这些强大的能力赋予每一个人，最终目标是构建一个人类智慧与机器智能协同共进，共同解决人类面临的最重大挑战的新时代。</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <p class="mb-2">相关文章推荐：</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/2025-01-15-xiaohanding-paper-suggestion/"></a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/anthropic-claude-agent-methodology/">Anthropic 研究员详解：构建高效 Claude 智能体的完整方法论</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/claude-code-knowledge-management/">Claude Code自定义命令在知识管理与内容创作中的系统化应用研究</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/habit/">18个改变人生的习惯：科学证据支持的长期主义指南</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/openai-gpt5-researcher-vision/">OpenAI双巨头首次详解GPT-5：不是下一代GPT，终极形态是AI研究员</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/kimi-yang-dialogue/">KIMI创始人杨植麟深度访谈：攀登无限之山</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/jason-wei-ai-insights/">Jason Wei：理解2025年AI进展的三种关键思路</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/anthropic-pretraining-nick-joseph/">Nick Joseph访谈：Anthropic预训练的核心思考与实践</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/xuyangsheng-CUHK-SZ/">徐扬生院士：人工智能时代的教育</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/karpathy-agent-ten-years/">Andrej Karpathy深度对话：Agent的十年征程与AI的幽灵本质</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Chao Yang. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-\u4e2d\u6587\u7b80\u4ecb",title:"\u4e2d\u6587\u7b80\u4ecb",description:"",section:"Navigation",handler:()=>{window.location.href="/chinese/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-publications",title:"publications",description:"publications by categories in reversed chronological order. generated by jekyll-scholar.",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-projects",title:"projects",description:"A growing collection of your cool projects.",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"nav-cv",title:"cv",description:"",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"nav-repositories",title:"repositories",description:"Edit the `_data/repositories.yml` and change the `github_users` and `github_repos` lists to include your own GitHub profile and repositories.",section:"Navigation",handler:()=>{window.location.href="/repositories/"}},{id:"nav-teaching",title:"teaching",description:"Materials for courses you taught. Replace this text with your description.",section:"Navigation",handler:()=>{window.location.href="/teaching/"}},{id:"dropdown-publications",title:"publications",description:"",section:"Dropdown",handler:()=>{window.location.href=""}},{id:"dropdown-projects",title:"projects",description:"",section:"Dropdown",handler:()=>{window.location.href=""}},{id:"dropdown-blog",title:"blog",description:"",section:"Dropdown",handler:()=>{window.location.href="/blog/"}},{id:"post-",title:"",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/2025-01-15-xiaohanding-paper-suggestion/"}},{id:"post-anthropic-\u7814\u7a76\u5458\u8be6\u89e3-\u6784\u5efa\u9ad8\u6548-claude-\u667a\u80fd\u4f53\u7684\u5b8c\u6574\u65b9\u6cd5\u8bba",title:"Anthropic \u7814\u7a76\u5458\u8be6\u89e3\uff1a\u6784\u5efa\u9ad8\u6548 Claude \u667a\u80fd\u4f53\u7684\u5b8c\u6574\u65b9\u6cd5\u8bba",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/anthropic-claude-agent-methodology/"}},{id:"post-claude-code\u81ea\u5b9a\u4e49\u547d\u4ee4\u5728\u77e5\u8bc6\u7ba1\u7406\u4e0e\u5185\u5bb9\u521b\u4f5c\u4e2d\u7684\u7cfb\u7edf\u5316\u5e94\u7528\u7814\u7a76",title:"Claude Code\u81ea\u5b9a\u4e49\u547d\u4ee4\u5728\u77e5\u8bc6\u7ba1\u7406\u4e0e\u5185\u5bb9\u521b\u4f5c\u4e2d\u7684\u7cfb\u7edf\u5316\u5e94\u7528\u7814\u7a76",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/claude-code-knowledge-management/"}},{id:"post-18\u4e2a\u6539\u53d8\u4eba\u751f\u7684\u4e60\u60ef-\u79d1\u5b66\u8bc1\u636e\u652f\u6301\u7684\u957f\u671f\u4e3b\u4e49\u6307\u5357",title:"18\u4e2a\u6539\u53d8\u4eba\u751f\u7684\u4e60\u60ef\uff1a\u79d1\u5b66\u8bc1\u636e\u652f\u6301\u7684\u957f\u671f\u4e3b\u4e49\u6307\u5357",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/habit/"}},{id:"post-openai\u53cc\u5de8\u5934\u9996\u6b21\u8be6\u89e3gpt-5-\u4e0d\u662f\u4e0b\u4e00\u4ee3gpt-\u7ec8\u6781\u5f62\u6001\u662fai\u7814\u7a76\u5458",title:"OpenAI\u53cc\u5de8\u5934\u9996\u6b21\u8be6\u89e3GPT-5\uff1a\u4e0d\u662f\u4e0b\u4e00\u4ee3GPT\uff0c\u7ec8\u6781\u5f62\u6001\u662fAI\u7814\u7a76\u5458",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/openai-gpt5-researcher-vision/"}},{id:"post-kimi\u521b\u59cb\u4eba\u6768\u690d\u9e9f\u6df1\u5ea6\u8bbf\u8c08-\u6500\u767b\u65e0\u9650\u4e4b\u5c71",title:"KIMI\u521b\u59cb\u4eba\u6768\u690d\u9e9f\u6df1\u5ea6\u8bbf\u8c08\uff1a\u6500\u767b\u65e0\u9650\u4e4b\u5c71",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/kimi-yang-dialogue/"}},{id:"post-jason-wei-\u7406\u89e32025\u5e74ai\u8fdb\u5c55\u7684\u4e09\u79cd\u5173\u952e\u601d\u8def",title:"Jason Wei\uff1a\u7406\u89e32025\u5e74AI\u8fdb\u5c55\u7684\u4e09\u79cd\u5173\u952e\u601d\u8def",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/jason-wei-ai-insights/"}},{id:"post-nick-joseph\u8bbf\u8c08-anthropic\u9884\u8bad\u7ec3\u7684\u6838\u5fc3\u601d\u8003\u4e0e\u5b9e\u8df5",title:"Nick Joseph\u8bbf\u8c08\uff1aAnthropic\u9884\u8bad\u7ec3\u7684\u6838\u5fc3\u601d\u8003\u4e0e\u5b9e\u8df5",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/anthropic-pretraining-nick-joseph/"}},{id:"post-\u5f90\u626c\u751f\u9662\u58eb-\u4eba\u5de5\u667a\u80fd\u65f6\u4ee3\u7684\u6559\u80b2",title:"\u5f90\u626c\u751f\u9662\u58eb\uff1a\u4eba\u5de5\u667a\u80fd\u65f6\u4ee3\u7684\u6559\u80b2",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/xuyangsheng-CUHK-SZ/"}},{id:"post-andrej-karpathy\u6df1\u5ea6\u5bf9\u8bdd-agent\u7684\u5341\u5e74\u5f81\u7a0b\u4e0eai\u7684\u5e7d\u7075\u672c\u8d28",title:"Andrej Karpathy\u6df1\u5ea6\u5bf9\u8bdd\uff1aAgent\u7684\u5341\u5e74\u5f81\u7a0b\u4e0eAI\u7684\u5e7d\u7075\u672c\u8d28",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/karpathy-agent-ten-years/"}},{id:"post-sutton-\u5927\u8bed\u8a00\u6a21\u578b\u8d70\u9519\u4e86\u8def-\u4e0d\u7b26\u5408-\u82e6\u6da9\u6559\u8bad-\u7cbe\u795e",title:"Sutton\uff1a\u5927\u8bed\u8a00\u6a21\u578b\u8d70\u9519\u4e86\u8def\uff0c\u4e0d\u7b26\u5408\u300c\u82e6\u6da9\u6559\u8bad\u300d\u7cbe\u795e",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/sutton-llm-is-wrong-way/"}},{id:"post-patrick-hsu-evo2\u534e\u4eba\u79d1\u5b66\u5bb6-\u865a\u62df\u7ec6\u80de\u8fc8\u5411gpt-2\u9636\u6bb5-\u5408\u6210\u751f\u7269\u5b66\u5c06\u6df1\u523b\u6539\u53d8\u4e16\u754c",title:"Patrick Hsu-Evo2\u534e\u4eba\u79d1\u5b66\u5bb6\uff1a\u865a\u62df\u7ec6\u80de\u8fc8\u5411GPT-2\u9636\u6bb5\uff0c\u5408\u6210\u751f\u7269\u5b66\u5c06\u6df1\u523b\u6539\u53d8\u4e16\u754c",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/patrick-hsu-evo2/"}},{id:"post-anthropic\u5185\u90e8ai\u4ee3\u7801\u9769\u547d-\u73b0\u5b9e\u8fd8\u662f\u7092\u4f5c-\u5f00\u53d1\u8005\u793e\u533a\u7684\u6df1\u5ea6\u8d28\u7591",title:"Anthropic\u5185\u90e8AI\u4ee3\u7801\u9769\u547d\uff1a\u73b0\u5b9e\u8fd8\u662f\u7092\u4f5c\uff1f\u5f00\u53d1\u8005\u793e\u533a\u7684\u6df1\u5ea6\u8d28\u7591",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/claude-code-sofaware/"}},{id:"post-\u59da\u987a\u96e8-ai\u4e0eagent\u7814\u7a76\u89c2\u70b9\u96c6",title:"\u59da\u987a\u96e8\uff1aAI\u4e0eAgent\u7814\u7a76\u89c2\u70b9\u96c6",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/yao-shunyu-agent-research/"}},{id:"post-\u59da\u987a\u96e8ai\u4e0eagent\u7814\u7a76\u89c2\u70b9\u96c6",title:"\u59da\u987a\u96e8AI\u4e0eAgent\u7814\u7a76\u89c2\u70b9\u96c6",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/yao-shunyu-ai-agent-insights/"}},{id:"post-\u6768\u690d\u9e9f\u89c2\u70b9\u7cbe\u534e-ai\u65f6\u4ee3\u7684\u6280\u672f\u54f2\u5b66\u4e0e\u5b9e\u8df5",title:"\u6768\u690d\u9e9f\u89c2\u70b9\u7cbe\u534e\uff1aAI\u65f6\u4ee3\u7684\u6280\u672f\u54f2\u5b66\u4e0e\u5b9e\u8df5",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/yang-zhilin-ai-philosophy/"}},{id:"post-openai\u59da\u987a\u96e8\u6df1\u5ea6\u8bbf\u8c08-ai\u4e0b\u534a\u573a\u7684agent\u9769\u547d",title:"OpenAI\u59da\u987a\u96e8\u6df1\u5ea6\u8bbf\u8c08\uff1aAI\u4e0b\u534a\u573a\u7684Agent\u9769\u547d",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/openai-yao-dialogue/"}},{id:"post-deepmind\u79d1\u5b66\u8d1f\u8d23\u4eba\u6df1\u5ea6\u8bbf\u8c08-\u5982\u4f55\u7b5b\u9009\u5e76\u653b\u514b\u53d8\u9769\u6027\u6311\u6218",title:"DeepMind\u79d1\u5b66\u8d1f\u8d23\u4eba\u6df1\u5ea6\u8bbf\u8c08\uff1a\u5982\u4f55\u7b5b\u9009\u5e76\u653b\u514b\u53d8\u9769\u6027\u6311\u6218",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/deepmind-kohli-dialogue/"}},{id:"post-church-nature-ai\u9a71\u52a8\u86cb\u767d\u8d28\u8bbe\u8ba1-\u9769\u547d\u6027\u8303\u5f0f\u7684\u5168\u6d41\u7a0b\u89e3\u6790",title:"Church @ Nature\uff1aAI\u9a71\u52a8\u86cb\u767d\u8d28\u8bbe\u8ba1\uff0c\u9769\u547d\u6027\u8303\u5f0f\u7684\u5168\u6d41\u7a0b\u89e3\u6790",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/nature-ai-driven-protein-design/"}},{id:"news-one-offline-rl-paper-accepted-by-aaai-2024-sparkles-sparkles",title:'One Offline RL Paper accepted by **AAAI 2024**. <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"><img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20">',description:"",section:"News"},{id:"news-two-papers-llama-excitor-videodistill-are-accepted-by-cvpr-2024-sparkles-sparkles",title:'Two Papers(LLaMA-Excitor, VideoDistill) are accepted by **CVPR 2024**. <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"><img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20">',description:"",section:"News"},{id:"news-one-llm-safety-survey-paper-accepted-by-naacl-2024-sparkles-smile",title:'One LLM safety survey paper accepted by **NAACL 2024**. <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> <img class="emoji" title=":smile:" alt=":smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" height="20" width="20">',description:"",section:"News"},{id:"news-one-paper-accepted-by-ijcai-2024-survey-track-sparkles-sparkles",title:'One Paper accepted by **IJCAI 2024** Survey Track. <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"><img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20">',description:"",section:"News"},{id:"news-robocodex-is-accepted-by-icml-2024-sparkles-sparkles",title:'RoboCodeX is accepted by **ICML 2024**. <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"><img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20">',description:"",section:"News"},{id:"news-three-papers-emulated-disalignment-structured-reasoning-multi-objective-dpo-are-accepted-by-acl-2024-sparkles-sparkles",title:'Three Papers (Emulated Disalignment, Structured Reasoning, Multi-Objective DPO) are accepted by **ACL 2024**.<img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"><img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20">...',description:"",section:"News"},{id:"news-mm-safetybench-a-benchmark-for-safety-evaluation-of-multimodal-large-language-models-is-accepted-by-eccv-2024-project-page-https-isxinliu-github-io-project-mm-safetybench-sparkles-sparkles",title:"MM-SafetyBench (A Benchmark for Safety Evaluation of Multimodal Large Language Models) is accepted...",description:"",section:"News"},{id:"news-inference-time-language-model-alignment-via-integrated-value-guidance-is-accepted-by-emnlp-2024-arixv-link-https-arxiv-org-pdf-2409-17819-sparkles-sparkles",title:"Inference-Time Language Model Alignment via Integrated Value Guidance is accepted by **EMNLP 2024**....",description:"",section:"News"},{id:"news-weak-to-strong-search-align-large-language-models-via-searching-over-small-language-models-is-accepted-by-neurips-2024-neurips-link-https-proceedings-neurips-cc-paper-files-paper-2024-file-088d99765bc121c6df215da7d45bc4e9-paper-conference-pdf-sparkles-sparkles",title:"Weak-to-Strong Search: Align Large Language Models via Searching over Small Language Models is...",description:"",section:"News"},{id:"news-we-proposal-a-new-law-ai-45-law-toward-trustworthy-agi-arxiv-link-https-arxiv-org-abs-2412-14186-sparkles",title:'We proposal a new law, **AI 45\xb0-Law** toward trustworthy AGI! [Arxiv Link](https://arxiv.org/abs/2412.14186) <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20">...',description:"",section:"News"},{id:"news-icml2025-emergent-response-planning-in-llm-https-arxiv-org-abs-2502-06258-and-c-3po-compact-plug-and-play-proxy-optimization-to-achieve-human-like-retrieval-augmented-generation-https-arxiv-org-abs-2502-06205-are-accepted-by-icml2025-sparkles",title:"[**ICML2025**] [Emergent Response Planning in LLM](https://arxiv.org/abs/2502.06258) and [C-3PO: Compact Plug-and-Play Proxy Optimization to...",description:"",section:"News"},{id:"news-our-paper-adversarial-preference-learning-for-robust-llm-alignment-is-accepted-by-acl2025-arxiv-link-https-arxiv-org-abs-2505-24369-sparkles",title:"Our paper Adversarial Preference Learning for Robust LLM Alignment is accepted by **ACL2025**....",description:"",section:"News"},{id:"news-we-find-patches-from-harmful-content-enabling-them-to-bypass-data-moderation-and-generate-dangerous-responses-when-encountering-the-full-image-or-related-text-vlms-can-aggregate-scattered-training-patchesk-https-arxiv-org-abs-2506-03614-sparkles",title:"We find patches from harmful content, enabling them to bypass data moderation and...",description:"",section:"News"},{id:"news-big-project-release-we-introduce-safework-r1-a-cutting-edge-multimodal-reasoning-model-that-demonstrates-the-coevolution-of-capabilities-and-safety-safework-r1-https-arxiv-org-abs-2507-18576-rocket-sparkles",title:"\ud83c\udf89 **Big Project Release!** We introduce **SafeWork-R1**, a cutting-edge multimodal reasoning model that...",description:"",section:"News"},{id:"projects-project-1",title:"project 1",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%79%61%6E%67%63%68%61%6F [%41%54] %70%6A%6C%61%62 [%44%4F%54] %6F%72%67 [%44%4F%54] %63%6E","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=https://scholar.google.com/citations?hl=en&user=5KRbHPMAAAAJ&view_op=list_works&sortby=pubdate","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/emigmo","_blank")}},{id:"socials-dblp",title:"DBLP",section:"Socials",handler:()=>{window.open("https://dblp.org/pid/00/5867-26.html","_blank")}},{id:"socials-youtube",title:"YouTube",section:"Socials",handler:()=>{window.open("https://youtube.com/@chaoyang4587","_blank")}},{id:"socials-rss",title:"RSS Feed",section:"Socials",handler:()=>{window.open("/feed.xml","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>