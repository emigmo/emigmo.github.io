<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Anthropic 研究员详解：构建高效 Claude 智能体的完整方法论 | Chao Yang </title> <meta name="author" content="Chao Yang"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://emigmo.github.io/blog/2025/anthropic-claude-agent-methodology/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Chao</span> Yang </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/chinese/">中文简介 </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/publications/">publications</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/projects/">projects</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/blog/">blog</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Anthropic 研究员详解：构建高效 Claude 智能体的完整方法论</h1> <p class="post-meta"> Created in November 06, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/category/blog"> <i class="fa-solid fa-tag fa-sm"></i> blog</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <h1 id="anthropic-研究员详解构建高效-claude-智能体的完整方法论">Anthropic 研究员详解：构建高效 Claude 智能体的完整方法论</h1> <p><em>访谈对象：Alex Albert (Claude 关系负责人)、Erik Schluntz (多智能体研究员)</em><br> <em>时间：2025年11月</em><br> <em>来源：Anthropic 官方播客</em></p> <hr> <h2 id="前言">前言</h2> <blockquote> <p><strong>“编码是智能体最基本、最核心的技能。一旦拥有了一个出色的编码智能体，这个智能体几乎可以完成任何其他类型的工作。”</strong></p> <p><strong>“工具应该映射 UI，而非 API——这是构建智能体工具最常见也最严重的错误观念。”</strong></p> </blockquote> <p>最近，来自 Anthropic 的两位核心成员——Claude 关系负责人 Alex Albert 与多智能体研究员 Erik Schluntz，深入探讨了 AI 智能体在过去数月中的快速演进。他们分享了从简单的”工作流”过渡到复杂的”多智能体系统”的实践经验，并详细阐述了如何通过代码、Claude Skills、MCP 和工具的最佳实践来构建更高效、更自主的 Claude 智能体。</p> <p><strong>三个核心洞察：</strong></p> <ol> <li> <strong>编码能力是一切的基础</strong>：强大的编码智能体可以泛化到任何领域，这种”溢出效应”是 Claude 在所有任务上表现出色的关键</li> <li> <strong>架构演进路径清晰</strong>：从静态工作流 → 单一智能体循环 → 智能体工作流 → 多智能体系统，复杂度逐级递增</li> <li> <strong>UI映射原则至关重要</strong>：工具设计应模拟用户界面而非后端API，这能显著提升智能体效率</li> </ol> <hr> <h2 id="目录">目录</h2> <ul> <li><a href="#%E4%B8%80claude-%E4%BD%9C%E4%B8%BA%E6%99%BA%E8%83%BD%E4%BD%93%E7%9A%84%E5%9F%BA%E7%A1%80%E7%BC%96%E7%A0%81%E8%83%BD%E5%8A%9B%E7%9A%84%E6%BA%A2%E5%87%BA%E6%95%88%E5%BA%94">一、Claude 作为智能体的基础：编码能力的”溢出效应”</a></li> <li><a href="#%E4%BA%8C%E5%BC%80%E5%8F%91%E8%80%85%E5%B7%A5%E5%85%B7%E7%9A%84%E6%BC%94%E8%BF%9B%E4%BB%8E-sdk-%E5%88%B0-skills">二、开发者工具的演进：从 SDK 到 Skills</a></li> <li><a href="#%E4%B8%89%E6%99%BA%E8%83%BD%E4%BD%93%E7%B3%BB%E7%BB%9F%E7%9A%84%E6%9E%B6%E6%9E%84%E6%BC%94%E8%BF%9B">三、智能体系统的架构演进</a></li> <li><a href="#%E5%9B%9B%E6%99%BA%E8%83%BD%E4%BD%93%E5%BC%80%E5%8F%91%E8%80%85%E7%9A%84%E6%A0%B8%E5%BF%83%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5">四、智能体开发者的核心最佳实践</a></li> <li><a href="#%E4%BA%94%E6%9C%AA%E6%9D%A5%E5%B1%95%E6%9C%9B%E9%95%BF%E7%A8%8B%E4%BB%BB%E5%8A%A1%E7%9A%84%E8%87%AA%E5%8A%A8%E4%BA%A4%E4%BB%98">五、未来展望：长程任务的自动交付</a></li> <li><a href="#%E7%BB%93%E8%AF%AD%E4%BB%8E%E5%B7%A5%E5%85%B7%E5%88%B0%E4%BC%99%E4%BC%B4%E7%9A%84%E8%B7%83%E8%BF%81">结语：从工具到伙伴的跃迁</a></li> </ul> <hr> <h2 id="一claude-作为智能体的基础编码能力的溢出效应">一、Claude 作为智能体的基础：编码能力的”溢出效应”</h2> <h3 id="11-智能体能力的训练根源">1.1 智能体能力的训练根源</h3> <p>要理解如何构建高效的智能体，首先要明白 Claude 为何擅长执行智能体任务。Erik 指出，核心在于<strong>大量的刻意练习</strong>。</p> <p><strong>训练策略：</strong></p> <ul> <li>在训练过程中，Claude 被要求处理许多开放式问题</li> <li>这些任务要求采取多个步骤、使用工具、探索环境</li> <li>通过强化学习对编码、搜索等不同场景进行大量练习</li> </ul> <p>这种训练方式让 Claude 积累了丰富的”作为智能体”的经验，因此在智能体任务上表现出色。</p> <h3 id="12-为什么编码是最重要的技能">1.2 为什么编码是最重要的技能</h3> <p>外界普遍认为 Claude 在编码方面异常强大，但常误以为这种能力仅限于技术领域。Erik 提出了不同的看法：</p> <blockquote> <p><strong>编码是智能体最基本、最核心的技能。</strong></p> </blockquote> <p>Anthropic 的理念是<strong>“先训练最难的东西”</strong>——即编码，那么其他一切都会变得更容易。</p> <p><strong>编码能力的泛化场景：</strong></p> <ul> <li> <strong>搜索任务</strong>：编写代码调用 Web 搜索 API</li> <li> <strong>行程规划</strong>：编写代码创建日程表或数据结构</li> <li> <strong>数据分析</strong>：编写脚本处理和可视化数据</li> </ul> <p>编码能力的”溢出效应”极其显著，它是使 Claude 在所有领域都表现出色的基石。</p> <h3 id="13-从直接生成到代码生成的效率革命">1.3 从直接生成到代码生成的效率革命</h3> <p>这种以编码为核心的理念，已经体现在 Claude.ai 网页版的功能中：Claude 能通过编写代码来创建实际的文件。</p> <p><strong>典型案例：</strong></p> <p>Erik 分享了一个亲身经历。他让 Claude 帮他为演示文稿制作图表：</p> <ol> <li> <strong>简单图表</strong>：Claude 直接编写 SVG 代码生成</li> <li> <strong>复杂图表</strong>：当需要大量重复性细节时，Claude 改变策略——编写一段脚本来生成 SVG 文件</li> </ol> <blockquote> <p><strong>效率对比：脚本运行速度远远快于 Claude 逐字生成图像文件的速度。</strong></p> </blockquote> <p><strong>核心原则：</strong> 对于许多复杂或重复性的任务，让智能体编写代码来生产某个”人工产物”，比让它直接创建这个产物要高效得多。</p> <hr> <h2 id="二开发者工具的演进从-sdk-到-skills">二、开发者工具的演进：从 SDK 到 Skills</h2> <h3 id="21-claude-code-sdk通用智能体框架">2.1 Claude Code SDK：通用智能体框架</h3> <p>当开发者真正开始构建自己的智能体时，<strong>Claude Code SDK</strong> 正变得越来越受欢迎。</p> <p><strong>SDK 的核心价值：</strong></p> <ul> <li>解决了”重复造轮子”问题</li> <li>内置了所有基础工作：循环、工具构建、工具执行、文件系统交互、MCP 处理</li> <li>虽然名字里有”Code”，但本质上是一个<strong>通用智能体框架</strong> </li> </ul> <p><strong>使用建议：</strong></p> <p>Erik 强烈建议开发者将这个 SDK 作为智能体循环的核心。这样开发者可以把时间花在真正有价值的地方：</p> <ul> <li>通过 MCP 添加独特的工具</li> <li>定制业务逻辑</li> <li>实现特定功能</li> </ul> <p><strong>高度可定制性：</strong></p> <p>开发者可以移除编码相关部分，然后填入自己需要的任何提示或工具。Erik 甚至用它规划过约会——通过集成网络搜索工具，这个”编码 SDK”帮他搜索了地区活动和餐馆，推荐了长木花园和附近的中餐馆。</p> <h3 id="22-claude-skills从指令到资源的跃迁">2.2 Claude Skills：从指令到资源的跃迁</h3> <p><strong>技能的起源：Claude.md 文件</strong></p> <p>开发者可以在项目根目录放置 <code class="language-plaintext highlighter-rouge">Claude.md</code> 文件，向 Claude 提供项目背景信息：</p> <ul> <li>编程风格偏好</li> <li>项目目录结构</li> <li>技术栈说明</li> </ul> <p><strong>Skills 的革命性扩展：</strong></p> <p>Skills 不再局限于提供纯文本”指令”，而是允许开发者为 Claude 提供<strong>任何类型的文件作为”资源”</strong>。</p> <p><strong>资源类型示例：</strong></p> <ol> <li> <strong>模板文件</strong>：公司官方 PowerPoint 模板</li> <li> <strong>辅助脚本</strong>：Claude 可调用的现成代码</li> <li> <strong>资产文件</strong>：图像、Logo、高管照片等</li> </ol> <blockquote> <p><strong>从”给指令”到”给资源”</strong>——这标志着智能体工具的重大转变。</p> </blockquote> <p><strong>“黑客帝国”比喻：</strong></p> <p>Alex 用《黑客帝国》中 Neo 学习功夫的场景作比喻：当”功夫”程序被注入大脑后，他瞬间掌握了技能。给 Claude 一项”技能”的感觉非常相似——比如给它一个”如何创建电子表格”的技能包，Claude 就像变成了专业的”银行家”，能够构建复杂的财务模型。</p> <hr> <h2 id="三智能体系统的架构演进">三、智能体系统的架构演进</h2> <h3 id="31-从工作流到智能体循环">3.1 从工作流到智能体循环</h3> <p>几个月前，智能体领域正处于过渡期：从”工作流”向”单一智能体系统”转变。</p> <p><strong>工作流 vs 智能体循环：</strong></p> <table> <thead> <tr> <th>类型</th> <th>特点</th> <th>适用场景</th> </tr> </thead> <tbody> <tr> <td>工作流</td> <td>链接的提示词序列，每步单次执行</td> <td>需要极低延迟的简单任务</td> </tr> <tr> <td>智能体循环</td> <td>模型在循环中运行，可反馈和纠正</td> <td>追求绝对质量的复杂任务</td> </tr> </tbody> </table> <p><strong>为什么智能体循环胜出：</strong></p> <p>Claude 在”响应反馈”和”纠正自身工作”方面的能力已经非常出色，因此智能体循环在追求质量的任务上表现远超工作流。</p> <h3 id="32-智能体工作流串行的智能体链">3.2 智能体工作流：串行的智能体链</h3> <p>Erik 观察到的最新趋势：<strong>“智能体工作流”(Workflows of Agents)</strong>。</p> <p><strong>案例对比：数据查询与图表绘制</strong></p> <p><strong>旧的工作流（Workflow）：</strong></p> <ol> <li>步骤一（单次尝试）：Claude 编写 SQL 命令加载数据</li> <li>步骤二（单次尝试）：基于数据绘制图表</li> <li> <strong>失败点</strong>：如果步骤一的 SQL 失败，步骤二对此一无所知，基于错误数据继续执行</li> </ol> <p><strong>新的智能体工作流（Workflow of Agents）：</strong></p> <ol> <li>步骤一（完整智能体）： <ul> <li>尝试编写 SQL 查询</li> <li>运行并查看输出</li> <li>如果失败，迭代重试直到获得正确数据</li> </ul> </li> <li>步骤二：当且仅当步骤一确认成功后，才移交给下一个智能体</li> </ol> <blockquote> <p><strong>从”链接提示”演进到”链接智能体”</strong>——这是智能体架构的重要里程碑。</p> </blockquote> <h3 id="33-可观测性挑战与简单性原则">3.3 可观测性挑战与简单性原则</h3> <p><strong>复杂性带来的难题：</strong></p> <p>随着系统变得越来越复杂，<strong>可观测性</strong>会变得”非常困难”。</p> <p><strong>Erik 的核心建议：</strong></p> <blockquote> <p><strong>永远从最简单的方法开始，只有在绝对必要时才增加复杂性。</strong></p> </blockquote> <p><strong>推荐的渐进路径：</strong></p> <ol> <li> <strong>第一步</strong>：尝试单次调用能否解决问题</li> <li> <strong>第二步</strong>：使用 Claude Code SDK 等简单智能体循环</li> <li> <strong>第三步</strong>：只有在简单方法无法满足需求时，才构建复杂的多层系统</li> </ol> <p>每增加一层复杂性，系统的可观测性就会变得更难。</p> <h3 id="34-多智能体系统并行的协作架构">3.4 多智能体系统：并行的协作架构</h3> <p><strong>智能体工作流 vs 多智能体：</strong></p> <table> <thead> <tr> <th>类型</th> <th>执行方式</th> <th>特点</th> </tr> </thead> <tbody> <tr> <td>智能体工作流</td> <td>串行（Sequential）</td> <td>一个智能体完成后传递给下一个</td> </tr> <tr> <td>多智能体</td> <td>并行（Parallel）</td> <td>多个智能体同时工作</td> </tr> </tbody> </table> <p><strong>多智能体的典型应用场景：</strong></p> <p><strong>场景一：并行委托</strong></p> <p>一个”父智能体”将任务委托给多个”子智能体”并行工作。</p> <p><strong>示例：Anthropic 的深度研究搜索产品</strong></p> <ul> <li>主”协调器”智能体决定创建几个子智能体</li> <li>子智能体同时执行大量搜索任务</li> <li>用户更快获得最终答案</li> </ul> <p><strong>场景二：上下文保护</strong></p> <p>主智能体将繁重的子任务外包给子智能体。</p> <p><strong>示例：代码库搜索</strong></p> <ul> <li>任务可能需要消耗数万个 token（在庞大代码库中查找）</li> <li>最终答案却很简短（文件名和行号）</li> <li>子智能体在自己的上下文中处理，只返回简短答案</li> <li>保护主智能体的上下文窗口</li> </ul> <h3 id="35-claude-学习成为管理者">3.5 Claude 学习成为”管理者”</h3> <p><strong>实现机制：</strong></p> <p>多智能体通过<strong>工具调用框架</strong>实现。对主智能体来说，子智能体就像一个可调用的”工具”。</p> <p><strong>Claude 的”管理挑战”：</strong></p> <p>Erik 目前的研究重点之一，是训练 Claude 成为更好的”管理者”。</p> <blockquote> <p><strong>Claude 会犯和人类”新手管理者”一样的错误。</strong></p> </blockquote> <p><strong>常见错误：</strong></p> <ul> <li>向子智能体提供不完整或含糊的指令</li> <li>错误地期望子智能体拥有和它一样的上下文背景</li> </ul> <p><strong>改进方向：</strong></p> <p>通过训练，Claude 开始：</p> <ul> <li>变得更啰嗦、更详细</li> <li>有意识地向子智能体提供任务的”整体背景”</li> <li>学习如何成为更称职的管理者</li> </ul> <hr> <h2 id="四智能体开发者的核心最佳实践">四、智能体开发者的核心最佳实践</h2> <h3 id="41-保持简单按需增加复杂性">4.1 保持简单，按需增加复杂性</h3> <p><strong>首要原则：</strong></p> <blockquote> <p><strong>Start simple and make sure you only add complexity as you need.</strong></p> </blockquote> <p><strong>推荐路径：</strong></p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>单次调用 → 简单智能体循环（如 SDK） → 复杂多层系统
</code></pre></div></div> <p>智能体系统的可观测性非常困难，复杂架构会加剧这一难题。</p> <h3 id="42-采用智能体的视角换位思考">4.2 采用智能体的视角（换位思考）</h3> <p><strong>核心思维：</strong></p> <blockquote> <p><strong>从智能体的角度去思考，设身处地站在 Claude 的立场上。</strong></p> </blockquote> <p><strong>最有效的实践方法：</strong></p> <ol> <li>阅读智能体看到的原始日志</li> <li>查看它在工具调用中实际看到的信息</li> <li>问自己：”如果我是智能体，只看到这些信息，我真的有足够信息解决这个问题吗？”</li> </ol> <p><strong>关键认知：</strong></p> <p>开发者容易忘记——我们（人类）能看到一切，而模型”只看得到我们展示给它的东西”。</p> <h3 id="43-工具应映射-ui而非-api最重要">4.3 工具应映射 UI，而非 API（最重要）</h3> <p>这是 Erik 强调的<strong>最常见且最严重的错误观念</strong>。</p> <p><strong>错误观念 vs 正确心智：</strong></p> <table> <thead> <tr> <th>错误观念</th> <th>正确心智</th> </tr> </thead> <tbody> <tr> <td>工具应与后端 API 一一对应</td> <td>工具应与用户界面（UI）一一对应</td> </tr> </tbody> </table> <p><strong>核心原因：</strong></p> <p>模型（Claude）是工具的”用户”，它不像”传统程序”那样工作。</p> <p><strong>经典案例：Slack 对话理解</strong></p> <p><strong>错误方式：API 映射</strong></p> <p>后端有三个独立端点：</p> <ol> <li> <code class="language-plaintext highlighter-rouge">load_slack_conversation()</code>：返回 user ID 和 channel ID</li> <li> <code class="language-plaintext highlighter-rouge">turn_user_id_into_username()</code>：ID 转用户名</li> <li> <code class="language-plaintext highlighter-rouge">turn_channel_id_into_channel_name()</code>：ID 转频道名</li> </ol> <p>如果提供这三个独立工具，智能体必须连续进行三次工具调用才能理解任何事情。<strong>极其低效。</strong></p> <p><strong>正确方式：UI 映射</strong></p> <p>反问：人类用户如何看待 Slack？</p> <p>我们看到的是”所有内容都已完美渲染好”的界面，不需要”点击用户 ID 来看他的名字”。</p> <p><strong>解决方案：</strong></p> <ul> <li>创建一个工具，一次性呈现所有信息</li> <li>需要尽可能少的交互</li> <li>在后台自己完成那三次 API 调用</li> <li>返回已经”渲染”好的、包含用户名和频道名的完整对话文本</li> </ul> <p><strong>核心思想：</strong></p> <blockquote> <p><strong>不要让智能体去做那些连你作为用户都会觉得”糟糕透顶”的、繁琐的交互操作。</strong></p> </blockquote> <hr> <h2 id="五未来展望长程任务的自动交付">五、未来展望：长程任务的自动交付</h2> <h3 id="51-自我验证的闭环系统">5.1 自我验证的闭环系统</h3> <p>Erik 预测，智能体将变得更加普及，首先从”可验证”领域开始，比如软件工程。</p> <p><strong>当前状态：</strong></p> <ul> <li>开发者在智能体写完代码后，必须自己充当”QA 工程师”测试</li> </ul> <p><strong>未来突破：</strong></p> <ul> <li>智能体能够自己”封闭测试循环”</li> <li>不仅编写网络应用，还能自己打开、测试、找到自己的 Bug</li> <li>不再等待人类发现问题</li> </ul> <h3 id="52-计算机使用能力的革命性影响">5.2 计算机使用能力的革命性影响</h3> <p><strong>关键能力融合：</strong></p> <p>将”软件工程能力”与”计算机使用”(Computer Use) 能力相结合。</p> <p><strong>计算机使用的含义：</strong></p> <ul> <li>像人一样操作计算机</li> <li>滚动、点击、编辑文本</li> </ul> <p><strong>解锁的新场景：</strong></p> <p>一旦智能体掌握了这种能力，将解锁大量目前被”拒之门外”的领域。</p> <p><strong>具体案例：Google Doc 编辑</strong></p> <p><strong>现状：</strong></p> <ul> <li>在 Claude 界面和文档之间来回复制粘贴</li> </ul> <p><strong>未来：</strong></p> <ul> <li>直接说：”嘿 Claude，帮我清理一下这篇 Google Doc”</li> <li>Claude 直接在文档中操作：滚动、点击、编辑文本</li> </ul> <blockquote> <p><strong>“无论你在哪里，Claude 都能与你同在”</strong>——这将是截然不同的、更高效的交互体验。</p> </blockquote> <h3 id="53-从编码智能体到通用智能体">5.3 从编码智能体到通用智能体</h3> <p><strong>演进路径：</strong></p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>编码智能体 → 自我测试编码智能体 → 计算机使用智能体 → 通用自主智能体
</code></pre></div></div> <p>当智能体能够：</p> <ol> <li>理解任务需求</li> <li>编写代码实现</li> <li>自我测试验证</li> <li>操作任何软件界面</li> </ol> <p>它就真正成为了可以自主完成长程任务的通用智能体。</p> <hr> <h2 id="结语从工具到伙伴的跃迁">结语：从工具到伙伴的跃迁</h2> <h3 id="核心要点回顾">核心要点回顾</h3> <p><strong>1. 编码能力是基础</strong></p> <ul> <li>强大的编码能力可以泛化到所有领域</li> <li>“先训练最难的”策略证明有效</li> </ul> <p><strong>2. 工具演进路径清晰</strong></p> <ul> <li>SDK 解决了基础架构问题</li> <li>Skills 提供了从指令到资源的跃迁</li> </ul> <p><strong>3. 架构复杂度需谨慎</strong></p> <ul> <li>从简单开始，按需增加复杂性</li> <li>可观测性随复杂度指数级下降</li> </ul> <p><strong>4. UI 映射原则至关重要</strong></p> <ul> <li>工具设计应模拟用户界面</li> <li>最小化智能体的交互次数</li> </ul> <h3 id="对开发者的启示">对开发者的启示</h3> <p><strong>构建智能体时的三个关键转变：</strong></p> <ol> <li> <strong>思维转变</strong>：从”调用 API”到”模拟 UI”</li> <li> <strong>架构转变</strong>：从”链接提示”到”链接智能体”</li> <li> <strong>角色转变</strong>：从”编写代码”到”管理智能体”</li> </ol> <h3 id="通往未来的路径">通往未来的路径</h3> <p>当前的智能体开发仍处于早期阶段，但演进路径已经清晰：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>单一智能体 → 智能体工作流 → 多智能体系统 → 自主长程任务执行
</code></pre></div></div> <blockquote> <p><strong>最终目标不是替代人类开发者，而是让 AI 成为真正的协作伙伴。</strong></p> </blockquote> <p>当智能体能够理解你的意图、自主规划任务、执行并验证结果，我们就进入了一个全新的人机协作时代。这不是科幻，而是正在发生的现实。</p> <hr> <p><strong>来源：</strong> Anthropic 官方播客<br> <strong>整理：</strong> Anthropic 研究员深度解析 Claude 智能体构建方法论<br> <strong>整理时间：</strong> 2025年11月6日</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <p class="mb-2">相关文章推荐：</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/2025-01-15-xiaohanding-paper-suggestion/"></a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/drfeifei-spatial-intelligence/">李飞飞:从文字到世界,空间智能是AI的下一个前沿</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/claude-code-knowledge-management/">Claude Code自定义命令在知识管理与内容创作中的系统化应用研究</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/habit/">18个改变人生的习惯：科学证据支持的长期主义指南</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/openai-gpt5-researcher-vision/">OpenAI双巨头首次详解GPT-5：不是下一代GPT，终极形态是AI研究员</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/kimi-yang-dialogue/">KIMI创始人杨植麟深度访谈：攀登无限之山</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/jason-wei-ai-insights/">Jason Wei：理解2025年AI进展的三种关键思路</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/anthropic-pretraining-nick-joseph/">Nick Joseph访谈：Anthropic预训练的核心思考与实践</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/xuyangsheng-CUHK-SZ/">徐扬生院士：人工智能时代的教育</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/karpathy-agent-ten-years/">Andrej Karpathy深度对话：Agent的十年征程与AI的幽灵本质</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Chao Yang. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-\u4e2d\u6587\u7b80\u4ecb",title:"\u4e2d\u6587\u7b80\u4ecb",description:"",section:"Navigation",handler:()=>{window.location.href="/chinese/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-publications",title:"publications",description:"publications by categories in reversed chronological order. generated by jekyll-scholar.",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-projects",title:"projects",description:"A growing collection of your cool projects.",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"nav-cv",title:"cv",description:"",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"nav-repositories",title:"repositories",description:"Edit the `_data/repositories.yml` and change the `github_users` and `github_repos` lists to include your own GitHub profile and repositories.",section:"Navigation",handler:()=>{window.location.href="/repositories/"}},{id:"nav-teaching",title:"teaching",description:"Materials for courses you taught. Replace this text with your description.",section:"Navigation",handler:()=>{window.location.href="/teaching/"}},{id:"dropdown-publications",title:"publications",description:"",section:"Dropdown",handler:()=>{window.location.href=""}},{id:"dropdown-projects",title:"projects",description:"",section:"Dropdown",handler:()=>{window.location.href=""}},{id:"dropdown-blog",title:"blog",description:"",section:"Dropdown",handler:()=>{window.location.href="/blog/"}},{id:"post-",title:"",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/2025-01-15-xiaohanding-paper-suggestion/"}},{id:"post-\u674e\u98de\u98de-\u4ece\u6587\u5b57\u5230\u4e16\u754c-\u7a7a\u95f4\u667a\u80fd\u662fai\u7684\u4e0b\u4e00\u4e2a\u524d\u6cbf",title:"\u674e\u98de\u98de:\u4ece\u6587\u5b57\u5230\u4e16\u754c,\u7a7a\u95f4\u667a\u80fd\u662fAI\u7684\u4e0b\u4e00\u4e2a\u524d\u6cbf",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/drfeifei-spatial-intelligence/"}},{id:"post-anthropic-\u7814\u7a76\u5458\u8be6\u89e3-\u6784\u5efa\u9ad8\u6548-claude-\u667a\u80fd\u4f53\u7684\u5b8c\u6574\u65b9\u6cd5\u8bba",title:"Anthropic \u7814\u7a76\u5458\u8be6\u89e3\uff1a\u6784\u5efa\u9ad8\u6548 Claude \u667a\u80fd\u4f53\u7684\u5b8c\u6574\u65b9\u6cd5\u8bba",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/anthropic-claude-agent-methodology/"}},{id:"post-claude-code\u81ea\u5b9a\u4e49\u547d\u4ee4\u5728\u77e5\u8bc6\u7ba1\u7406\u4e0e\u5185\u5bb9\u521b\u4f5c\u4e2d\u7684\u7cfb\u7edf\u5316\u5e94\u7528\u7814\u7a76",title:"Claude Code\u81ea\u5b9a\u4e49\u547d\u4ee4\u5728\u77e5\u8bc6\u7ba1\u7406\u4e0e\u5185\u5bb9\u521b\u4f5c\u4e2d\u7684\u7cfb\u7edf\u5316\u5e94\u7528\u7814\u7a76",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/claude-code-knowledge-management/"}},{id:"post-18\u4e2a\u6539\u53d8\u4eba\u751f\u7684\u4e60\u60ef-\u79d1\u5b66\u8bc1\u636e\u652f\u6301\u7684\u957f\u671f\u4e3b\u4e49\u6307\u5357",title:"18\u4e2a\u6539\u53d8\u4eba\u751f\u7684\u4e60\u60ef\uff1a\u79d1\u5b66\u8bc1\u636e\u652f\u6301\u7684\u957f\u671f\u4e3b\u4e49\u6307\u5357",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/habit/"}},{id:"post-openai\u53cc\u5de8\u5934\u9996\u6b21\u8be6\u89e3gpt-5-\u4e0d\u662f\u4e0b\u4e00\u4ee3gpt-\u7ec8\u6781\u5f62\u6001\u662fai\u7814\u7a76\u5458",title:"OpenAI\u53cc\u5de8\u5934\u9996\u6b21\u8be6\u89e3GPT-5\uff1a\u4e0d\u662f\u4e0b\u4e00\u4ee3GPT\uff0c\u7ec8\u6781\u5f62\u6001\u662fAI\u7814\u7a76\u5458",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/openai-gpt5-researcher-vision/"}},{id:"post-kimi\u521b\u59cb\u4eba\u6768\u690d\u9e9f\u6df1\u5ea6\u8bbf\u8c08-\u6500\u767b\u65e0\u9650\u4e4b\u5c71",title:"KIMI\u521b\u59cb\u4eba\u6768\u690d\u9e9f\u6df1\u5ea6\u8bbf\u8c08\uff1a\u6500\u767b\u65e0\u9650\u4e4b\u5c71",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/kimi-yang-dialogue/"}},{id:"post-jason-wei-\u7406\u89e32025\u5e74ai\u8fdb\u5c55\u7684\u4e09\u79cd\u5173\u952e\u601d\u8def",title:"Jason Wei\uff1a\u7406\u89e32025\u5e74AI\u8fdb\u5c55\u7684\u4e09\u79cd\u5173\u952e\u601d\u8def",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/jason-wei-ai-insights/"}},{id:"post-nick-joseph\u8bbf\u8c08-anthropic\u9884\u8bad\u7ec3\u7684\u6838\u5fc3\u601d\u8003\u4e0e\u5b9e\u8df5",title:"Nick Joseph\u8bbf\u8c08\uff1aAnthropic\u9884\u8bad\u7ec3\u7684\u6838\u5fc3\u601d\u8003\u4e0e\u5b9e\u8df5",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/anthropic-pretraining-nick-joseph/"}},{id:"post-\u5f90\u626c\u751f\u9662\u58eb-\u4eba\u5de5\u667a\u80fd\u65f6\u4ee3\u7684\u6559\u80b2",title:"\u5f90\u626c\u751f\u9662\u58eb\uff1a\u4eba\u5de5\u667a\u80fd\u65f6\u4ee3\u7684\u6559\u80b2",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/xuyangsheng-CUHK-SZ/"}},{id:"post-andrej-karpathy\u6df1\u5ea6\u5bf9\u8bdd-agent\u7684\u5341\u5e74\u5f81\u7a0b\u4e0eai\u7684\u5e7d\u7075\u672c\u8d28",title:"Andrej Karpathy\u6df1\u5ea6\u5bf9\u8bdd\uff1aAgent\u7684\u5341\u5e74\u5f81\u7a0b\u4e0eAI\u7684\u5e7d\u7075\u672c\u8d28",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/karpathy-agent-ten-years/"}},{id:"post-sutton-\u5927\u8bed\u8a00\u6a21\u578b\u8d70\u9519\u4e86\u8def-\u4e0d\u7b26\u5408-\u82e6\u6da9\u6559\u8bad-\u7cbe\u795e",title:"Sutton\uff1a\u5927\u8bed\u8a00\u6a21\u578b\u8d70\u9519\u4e86\u8def\uff0c\u4e0d\u7b26\u5408\u300c\u82e6\u6da9\u6559\u8bad\u300d\u7cbe\u795e",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/sutton-llm-is-wrong-way/"}},{id:"post-patrick-hsu-evo2\u534e\u4eba\u79d1\u5b66\u5bb6-\u865a\u62df\u7ec6\u80de\u8fc8\u5411gpt-2\u9636\u6bb5-\u5408\u6210\u751f\u7269\u5b66\u5c06\u6df1\u523b\u6539\u53d8\u4e16\u754c",title:"Patrick Hsu-Evo2\u534e\u4eba\u79d1\u5b66\u5bb6\uff1a\u865a\u62df\u7ec6\u80de\u8fc8\u5411GPT-2\u9636\u6bb5\uff0c\u5408\u6210\u751f\u7269\u5b66\u5c06\u6df1\u523b\u6539\u53d8\u4e16\u754c",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/patrick-hsu-evo2/"}},{id:"post-sam-altman-\u4e30\u6c9b\u667a\u80fd-\u6df1\u5ea6\u89e3\u6790-ai\u57fa\u7840\u8bbe\u65bd\u7684\u5b8f\u5927\u613f\u666f\u4e0e\u6218\u7565\u8def\u5f84",title:"Sam Altman\u300a\u4e30\u6c9b\u667a\u80fd\u300b\u6df1\u5ea6\u89e3\u6790:AI\u57fa\u7840\u8bbe\u65bd\u7684\u5b8f\u5927\u613f\u666f\u4e0e\u6218\u7565\u8def\u5f84",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/sam-altman-abundant-intelligence/"}},{id:"post-anthropic\u5185\u90e8ai\u4ee3\u7801\u9769\u547d-\u73b0\u5b9e\u8fd8\u662f\u7092\u4f5c-\u5f00\u53d1\u8005\u793e\u533a\u7684\u6df1\u5ea6\u8d28\u7591",title:"Anthropic\u5185\u90e8AI\u4ee3\u7801\u9769\u547d\uff1a\u73b0\u5b9e\u8fd8\u662f\u7092\u4f5c\uff1f\u5f00\u53d1\u8005\u793e\u533a\u7684\u6df1\u5ea6\u8d28\u7591",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/claude-code-sofaware/"}},{id:"post-\u59da\u987a\u96e8-ai\u4e0eagent\u7814\u7a76\u89c2\u70b9\u96c6",title:"\u59da\u987a\u96e8\uff1aAI\u4e0eAgent\u7814\u7a76\u89c2\u70b9\u96c6",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/yao-shunyu-agent-research/"}},{id:"post-\u59da\u987a\u96e8ai\u4e0eagent\u7814\u7a76\u89c2\u70b9\u96c6",title:"\u59da\u987a\u96e8AI\u4e0eAgent\u7814\u7a76\u89c2\u70b9\u96c6",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/yao-shunyu-ai-agent-insights/"}},{id:"post-\u6768\u690d\u9e9f\u89c2\u70b9\u7cbe\u534e-ai\u65f6\u4ee3\u7684\u6280\u672f\u54f2\u5b66\u4e0e\u5b9e\u8df5",title:"\u6768\u690d\u9e9f\u89c2\u70b9\u7cbe\u534e\uff1aAI\u65f6\u4ee3\u7684\u6280\u672f\u54f2\u5b66\u4e0e\u5b9e\u8df5",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/yang-zhilin-ai-philosophy/"}},{id:"post-openai\u59da\u987a\u96e8\u6df1\u5ea6\u8bbf\u8c08-ai\u4e0b\u534a\u573a\u7684agent\u9769\u547d",title:"OpenAI\u59da\u987a\u96e8\u6df1\u5ea6\u8bbf\u8c08\uff1aAI\u4e0b\u534a\u573a\u7684Agent\u9769\u547d",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/openai-yao-dialogue/"}},{id:"post-deepmind\u79d1\u5b66\u8d1f\u8d23\u4eba\u6df1\u5ea6\u8bbf\u8c08-\u5982\u4f55\u7b5b\u9009\u5e76\u653b\u514b\u53d8\u9769\u6027\u6311\u6218",title:"DeepMind\u79d1\u5b66\u8d1f\u8d23\u4eba\u6df1\u5ea6\u8bbf\u8c08\uff1a\u5982\u4f55\u7b5b\u9009\u5e76\u653b\u514b\u53d8\u9769\u6027\u6311\u6218",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/deepmind-kohli-dialogue/"}},{id:"post-church-nature-ai\u9a71\u52a8\u86cb\u767d\u8d28\u8bbe\u8ba1-\u9769\u547d\u6027\u8303\u5f0f\u7684\u5168\u6d41\u7a0b\u89e3\u6790",title:"Church @ Nature\uff1aAI\u9a71\u52a8\u86cb\u767d\u8d28\u8bbe\u8ba1\uff0c\u9769\u547d\u6027\u8303\u5f0f\u7684\u5168\u6d41\u7a0b\u89e3\u6790",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2025/nature-ai-driven-protein-design/"}},{id:"news-aaai2024-one-offline-rl-paper-critic-guided-decision-transformer-for-offline-reinforcement-learning-https-arxiv-org-abs-2312-13716-accepted-by-aaai-2024-sparkles-sparkles",title:"**[AAAI2024]** One Offline RL Paper [Critic-Guided Decision Transformer for Offline Reinforcement Learning](https://arxiv.org/abs/2312.13716) accepted...",description:"",section:"News"},{id:"news-cvpr2024-two-papers-llama-excitor-https-arxiv-org-abs-2310-07259-videodistill-https-arxiv-org-abs-2404-00973-are-accepted-by-cvpr-2024-sparkles-sparkles",title:'**[CVPR2024]** Two Papers([LLaMA-Excitor](https://arxiv.org/abs/2310.07259), [VideoDistill](https://arxiv.org/abs/2404.00973)) are accepted by CVPR 2024. <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"><img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20">',description:"",section:"News"},{id:"news-naacl2024-one-llm-safety-survey-paper-attacks-defenses-and-evaluations-for-llm-conversation-safety-a-survey-https-arxiv-org-abs-2402-09283-accepted-by-naacl-2024-sparkles-smile",title:"**[NAACL2024]** One LLM safety survey paper [Attacks, Defenses and Evaluations for LLM Conversation...",description:"",section:"News"},{id:"news-ijcai2024-one-paper-attacks-defenses-and-evaluations-for-llm-conversation-safety-a-survey-https-arxiv-org-abs-2402-09283-accepted-by-ijcai-2024-survey-track-sparkles-sparkles",title:"**[IJCAI2024]** One Paper [Attacks, Defenses and Evaluations for LLM Conversation Safety: A Survey](https://arxiv.org/abs/2402.09283)...",description:"",section:"News"},{id:"news-icml2024-robocodex-multimodal-code-generation-for-robotic-behavior-synthesis-https-arxiv-org-abs-2402-16117-is-accepted-by-icml-2024-sparkles-sparkles",title:"**[ICML2024]** [RoboCodeX: Multimodal Code Generation for Robotic Behavior Synthesis](https://arxiv.org/abs/2402.16117) is accepted by ICML...",description:"",section:"News"},{id:"news-acl2024-three-papers-emulated-disalignment-https-arxiv-org-abs-2402-12343-seer-structured-reasoning-https-arxiv-org-abs-2401-13246-multi-objective-dpo-https-arxiv-org-abs-2310-03708-are-accepted-by-acl-2024-sparkles-sparkles",title:"**[ACL2024]** Three Papers ([Emulated Disalignment](https://arxiv.org/abs/2402.12343), [SEER: Structured Reasoning](https://arxiv.org/abs/2401.13246), [Multi-Objective DPO](https://arxiv.org/abs/2310.03708)) are accepted by...",description:"",section:"News"},{id:"news-eccv2024-mm-safetybench-a-benchmark-for-safety-evaluation-of-multimodal-large-language-models-is-accepted-by-eccv-2024-project-page-https-isxinliu-github-io-project-mm-safetybench-sparkles-sparkles",title:"**[ECCV2024]** MM-SafetyBench (A Benchmark for Safety Evaluation of Multimodal Large Language Models) is...",description:"",section:"News"},{id:"news-emnlp2024-inference-time-language-model-alignment-via-integrated-value-guidance-is-accepted-by-emnlp-2024-arixv-link-https-arxiv-org-pdf-2409-17819-sparkles-sparkles",title:"**[EMNLP2024]** Inference-Time Language Model Alignment via Integrated Value Guidance is accepted by EMNLP...",description:"",section:"News"},{id:"news-neurips2024-weak-to-strong-search-align-large-language-models-via-searching-over-small-language-models-is-accepted-by-neurips-2024-neurips-link-https-proceedings-neurips-cc-paper-files-paper-2024-file-088d99765bc121c6df215da7d45bc4e9-paper-conference-pdf-sparkles-sparkles",title:"**[NeurIPS2024]** Weak-to-Strong Search: Align Large Language Models via Searching over Small Language Models...",description:"",section:"News"},{id:"news-we-proposal-a-new-law-ai-45-law-toward-trustworthy-agi-arxiv-link-https-arxiv-org-abs-2412-14186-sparkles",title:'We proposal a new law, **AI 45\xb0-Law** toward trustworthy AGI! [Arxiv Link](https://arxiv.org/abs/2412.14186) <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20">...',description:"",section:"News"},{id:"news-icml2025-emergent-response-planning-in-llm-https-arxiv-org-abs-2502-06258-and-c-3po-compact-plug-and-play-proxy-optimization-to-achieve-human-like-retrieval-augmented-generation-https-arxiv-org-abs-2502-06205-are-accepted-by-icml2025-sparkles",title:"**[ICML2025]** [Emergent Response Planning in LLM](https://arxiv.org/abs/2502.06258) and [C-3PO: Compact Plug-and-Play Proxy Optimization to...",description:"",section:"News"},{id:"news-acl2025-our-paper-adversarial-preference-learning-for-robust-llm-alignment-is-accepted-by-acl2025-arxiv-link-https-arxiv-org-abs-2505-24369-sparkles",title:"**[ACL2025]** Our paper Adversarial Preference Learning for Robust LLM Alignment is accepted by...",description:"",section:"News"},{id:"news-neurips2025-we-find-patches-from-harmful-content-enabling-them-to-bypass-data-moderation-and-generate-dangerous-responses-when-encountering-the-full-image-or-related-text-vlms-can-aggregate-scattered-training-patches-https-arxiv-org-abs-2506-03614-is-accepted-by-neurips2025-sparkles",title:"**[NeurIPS2025]** We find patches from harmful content, enabling them to bypass data moderation...",description:"",section:"News"},{id:"news-big-project-release-we-introduce-safework-r1-a-cutting-edge-multimodal-reasoning-model-that-demonstrates-the-coevolution-of-capabilities-and-safety-safework-r1-https-arxiv-org-abs-2507-18576-rocket-sparkles",title:"\ud83c\udf89 **Big Project Release!** We introduce **SafeWork-R1**, a cutting-edge multimodal reasoning model that...",description:"",section:"News"},{id:"news-aaai2026-shadow-dynamic-aware-credit-assignment-for-efficient-long-horizon-agent-training-is-accepted-by-aaai2026-sparkles",title:"**[AAAI2026]** SHADOW: Dynamic-Aware Credit Assignment for Efficient Long-Horizon Agent Training is accepted by...",description:"",section:"News"},{id:"projects-project-1",title:"project 1",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"projects-\u674e\u98de\u98de-\u7a7a\u95f4\u667a\u80fd\u662fai\u7684\u4e0b\u4e00\u4e2a\u524d\u6cbf",title:"\u674e\u98de\u98de:\u7a7a\u95f4\u667a\u80fd\u662fAI\u7684\u4e0b\u4e00\u4e2a\u524d\u6cbf",description:"\u4ece\u6587\u5b57\u5230\u4e16\u754c,World Labs\u5f00\u542f\u7a7a\u95f4\u667a\u80fd\u65b0\u65f6\u4ee3",section:"Projects",handler:()=>{window.location.href="/projects/2_spatial_intelligence/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%79%61%6E%67%63%68%61%6F [%41%54] %70%6A%6C%61%62 [%44%4F%54] %6F%72%67 [%44%4F%54] %63%6E","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=https://scholar.google.com/citations?hl=en&user=5KRbHPMAAAAJ&view_op=list_works&sortby=pubdate","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/emigmo","_blank")}},{id:"socials-dblp",title:"DBLP",section:"Socials",handler:()=>{window.open("https://dblp.org/pid/00/5867-26.html","_blank")}},{id:"socials-youtube",title:"YouTube",section:"Socials",handler:()=>{window.open("https://youtube.com/@chaoyang4587","_blank")}},{id:"socials-rss",title:"RSS Feed",section:"Socials",handler:()=>{window.open("/feed.xml","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>