# KIMI创始人杨植麟深度访谈：攀登无限之山

_主持人：张小珺_  
_时间：2025年7月_  
_地点：北京知春路京东科技大厦13层_

---

## 目录

### 第一章 一座无限的山

- [01 The Beginning of Infinity - 无穷的开始](#01-the-beginning-of-infinity)
- [02 它还是一个"缸中之脑"](#02-它还是一个缸中之脑)
- [03 L1到L5不一定是串行关系](#03-l1到l5不一定是串行关系)

### 第二章 K2是乔戈里峰

- [04 喂一样多的数据，"脑子"长得更多](#04-喂一样多的数据脑子长得更多)
- [05 Muon你去训的时候，它会炸](#05-muon你去训的时候它会炸)
- [06 当从"缸中之脑"变成跟世界交互的系统](#06-当从缸中之脑变成跟世界交互的系统)

### 第三章 既简单又复杂的系统

- [07 开源 vs 闭源](#07-开源-vs-闭源)
- [08 多模态不损伤"脑子"已经很好了](#08-多模态不损伤脑子已经很好了)
- [09 当你通过新的交互，收集的信号噪声减少](#09-当你通过新的交互收集的信号噪声减少)
- [10 Long Context架构会影响"智商"](#10-long-context架构会影响智商)
- [11 边界与现实](#11-边界与现实)

### 第四章 在自己的故事里面

- [12 用RL的方式去管理，而不是用SFT](#12-用rl的方式去管理而不是用sft)
- [13 AI是人类文明的放大器](#13-ai是人类文明的放大器)
- [14 任何中间状态都有可能成为被批评的对象](#14-任何中间状态都有可能成为被批评的对象)

---

## 第一章 一座无限的山

### 01 The Beginning of Infinity

张小珺：在你创业第一年结束的时候，2024年我们访谈标题是《向延绵而未知的雪山前进》。现在又过了一年，站在此刻，2025年7月，你最新的感受是怎样的？

杨植麟：你刚刚提到这个词，我感觉好像过了很久……AI一天，人间一年。AI的一年我不知道是人间多少天。确实很多东西发生了变化，但你说的"雪山的感觉"，倒是差不太多。

往山顶方向，我们又走了一段距离。

张小珺：现在行进到哪里了？

杨植麟：站在现在看，模型的进步挺大——两年前写一篇文章都写不太明白，现在不光可以写很好的文章，还能连续工作几小时，帮你完成一个很复杂的代码任务。这在两年前很难想象。

在爬雪山的过程中，解锁了一些新的场景，大概知道中间这条路是什么样的；但同时，在往上的过程中，你还是观察到类似的景象——接下来，仍然会有很多未知的技术问题要去解决。

张小珺：在四下都是大雪的山峰上，你是更清晰了，还是更迷惘了？

杨植麟：肯定会有很多东西变得更清楚。两年前各种强化学习（RL，Reinforcement Learning）的范式该怎么做，怎么让模型有更强的推理能力，或更强的Agentic（智能体式）能力，当时都没那么清楚。那时更多关注模型的预训练（Pre-Training）怎么做得更好，怎么用RLHF（Reinforcement Learning from Human Feedback，人类反馈强化学习）提升对话体验。

但现在有一些问题得到了答案，同时这些答案又展开，带来了新的其他问题。

现在虽然可以做强化学习，但它最终还是依赖一个很好的评估或验证机制。你让模型去做一道数学题，或者做一些有test case（测试样例）的编程任务，可能做得比较好。但如果让它去做一个更复杂的端到端任务，有时很难找到一个合适的评估或衡量方式。所以，这个系统又会产生新的问题。

这有点像我最近在看的一本书，叫The Beginning of Infinity（无穷的开始），我看了好几遍。书中说，有两句话可以刻在石头上：一句是"问题是不可避免的"，另一句是"问题是可以解决的"。

《无穷的开始》（The Beginning of Infinity）是物理学家David Deutsch撰写的一本科普哲学著作。

**书中观点**：科学知识和理性探究能带来无限的进步和理解，世界上的问题无穷无尽，但绝大多数问题都可以通过理性思考和科学方法得到解决。知识的增长无界限，科学探索是一个不断解决问题、产生新问题的过程，这是人类文明不断前进的动力。

你可以认为，启蒙运动前，这个社会是静态的。大家不追求创新，会用很多神秘主义来解释所看到的现象，但这些解释并不是好的解释。比如，你看到天上打雷，会觉得雷公在发怒；你看到冬天下雪，会说某个神心情不好——整个社会结构是静态的，只有极少数人在真正做科学研究或知识创造。

但启蒙运动之后，社会变成了动态的，新的知识不断被创造。每当你解决一个问题，就会带来新的问题。问题是源源不断的，因为你的知识边界在拓展，你就会遇到新的问题。

现在做AI研发也恰好处于这样的状态。你解决了强化学习的一些问题，接下来就遇到评估、衡量、验证这些问题，又需要我们寻找新的答案。

但这也正是它有意思的地方——你总是会有新的问题去解决，而每当你解决一个问题，技术就能再往上攀登几百米。

也许有一天会发现，这座雪山没有尽头——我不知道——我希望它一直没有尽头。

The Beginning of Infinity的意思就是这样：

它是一座无限的山。

### 02 它还是一个"缸中之脑"

张小珺：我们回望一下，过去一年全球大模型在你脑海中最重要的几件事是什么？有哪些是人工智能范式级的变化？

杨植麟：一个是长思考的推理模型（Reasoning Model），以o1作为第一个做出来的代表。本质上，它通过让模型在过程中做很多尝试和反思，反思是其中的重点。

反思是两种能力：一种是提出新的猜想，一种是验证猜想。

你可以理解为：模型在解决问题的过程中，会不断提出新的猜想，这个猜想会得到自我验证。比如，它提出这个猜想之后，要判断是对是错，需要具备一定的验证能力。虽然你不是显式地训练一个验证模型，但它在推理过程中隐式地进行了验证。它对这个问题做了多次猜想和验证，最后得到一个答案。

这大大提升了模型的能力。你本来只能做一次，直接给出一个答案，这个答案可能对，也可能错，你没有这个过程。但现在你可以不断提出猜想去验证，相当于等价尝试了好几次。

你可以把Pass@k变成Pass@1，本质是这样的道理。

**Pass@k**：用于评估大模型的一种指标，表示模型在一次任务中生成k个候选答案时，至少有一个答案正确的概率。

这跟人做科研或解题的过程很像，不断提出新的猜想，然后验证它。

张小珺：是一个自由探索的过程，而不是一个线性的过程。

杨植麟：它有效的工作方式，很多时候还是比较线性的。如果不考虑并行采样，假设做的是串行采样，它就是线性过程。

你每次提出新的猜想，这个猜想可能基于之前的猜想，甚至是你已经否定过的猜想，再提出一个新的猜想。它会接近更线性的过程。

现在你也可以把线性过程和并行策略搭配，比如同时采样很多个，结合了并行和串行两种方式。最近也有一些paper讲串行采样上限更高，这跟我们的实验结论一致。

上面说的是一种范式，但它还是一个“缸中之脑”（brain in a vat），并不需要跟外界交互。

张小珺：缸中之脑？

杨植麟：想象一个鱼缸，你把一个脑子放在里面，跟外界没有联系。它只是在自己大脑里面想，一直想，不需要跟外界产生任何交互，就能解一道题。

但有另一个很重要的范式，就是基于多轮的Agent（智能体）强化学习范式，或者通过强化学习技术训练出来的Agentic模型，它的特点是会跟外界做很多交互。

比如我边思考边去做一些操作，可能做很多轮操作，一会儿调用一个搜索，一会儿使用一下浏览器，一会儿写几行代码，通过多轮解决一个问题。

它就不再是“缸中之脑”，是跟外界有交互的——我的下一步行为，是根据交互中得到的反馈，和外界给我的新状态的更新有关系。

但这两个东西都指向了同一个东西，是：test-time scaling（测试时扩展）。意思是，可以在测试时，或者在推理时，做到更好的规模化。

比如之前做Chat（聊天），更多是单轮地输出一个结果：我让你写一篇文章，你就写一篇文章；我再让你润色一下，你又输出几百个token（词元），这个token数量是很少的。但不管是基于长思考的强化学习，还是Agent的强化学习，本质上都是一种在预测时对token进行规模化扩展的方式。

你不管是把轮数打得更多，还是在每一轮有更多思考的token，都是一种规模化token的方法，让你能完成更复杂的任务。

这也伴随完成时间更长。你现在花几小时去做一件复杂的事，过程中不需要人工参与。比如，把一个代码仓库克隆下来，翻译成另一种新语言，调试、测试，把所有bug（漏洞）修复，让它能正常运行。这样的工作可以端到端完成，得益于测试时计算（test-time）的规模化。

还有一个很有意思的趋势是，现在有更多模型公司去做“一方的Agent产品”。

**"一方的Agent产品"**：指模型公司自己下场做产品，自己控制上下文环境、工具接口、prompt结构等，也就是自己当"使用方"，而不是只给别人提供模型API。
一开始，我们看半年前或者去年，很多产品是基于基础模型，你在上面搭一些脚手架，或者设计一些工具去更好地让模型使用，从而搭建一个产品。
张小珺：享受模型溢出的能力。
杨植麟：对，它本质做的是逆向工程这个模型的训练过程。因为模型训练过程也是通过各种手段——你可以认为Anthropic在内部（in-house）的环境、工具、脚手架，可能训练出这样一个模型，但它没有直接开放给你。

你通过逆向，更接近拟合它的分布——到底用什么工具效果会好？到底用什么样的System Prompt（系统提示）效果会好？到底用什么样的Context Engineering（上下文工程）效果会好？这是一个逆向的过程。

但你会发现，如果模型公司去做“一方的产品”，逻辑完全不一样。

你不再需要这个逆向的过程，更多是正向的做法。我先把这些工具设计好，我的Context Engineering（上下文工程）的方法都设计好，我就在这个环境里训练这个模型，所以模型天然在你的环境里表现更好。

这是两种不同思路，但第二种思路上限也许更高。

你可以更好整合工具和模型。模型如果有些地方解决不好，你可以调整工具设计，把它设计得更好，同时又可以端到端训练。这也是在开发方式一个比较大的变量。

张小珺：让大家比较好理解。第一种你说的脚手架，就是像Manus这种开发方式；第二种是你们这样的端到端训练模型的方式。

杨植麟：对。当然，我们现在在“一方产品”投入还不算特别多，是以模型为主线。但Claude Code或ChatGPT Agent，就是“一方的产品”，应该也会是一个很大趋势。

后面就看“一方”和“三方”产品怎么配合，在生态里会是什么样的状态。

### 03 L1到L5不一定是串行关系

张小珺：说到主线，OpenAI设置了从L1到L5的分级，我一直很好奇它背后的内在逻辑。

L1是Chatbot（聊天机器人），L2是Reasoner（推理者），L3是Agent（智能体），L4是Innovator（创新者），L5是Organizer（组织者）。

为什么是在有了Chatbot和Reasoner之后才有Agent？为什么接下来又是Innovator和Organizer？这个顺序在能力结构上是怎样递进的？

杨植麟：它是能力一步一步的依赖。Agent的（L3）上限取决于，你有很强的Reasoning（L2、推理）能力，但并不是必须先有Reasoning。

假设我们把技术发展的顺序稍微换一下，你先做出来Agent能力，再去做狭义的Reasoning，就是long CoT（长链式思维）的Reasoning，可能也是成立的。

你可以认为Claude的路线就是bet（押注）这一点：它在Reasoning上做得不是特别多，但在Agent上做得非常好。这背后是不同技术路径的bet（押注）。但最终你绕不开，如果你想往山顶再多爬几步，这两个能力都要有，只是时间问题。

所以，他们并不一定是互相依赖的。不是非得先做Reasoning再做Agent。但要做到最好的Agent，就必须把Reasoning也做到最好。而有了Agent的能力，就可以去做后面的一些事。

为什么说下一阶段（L4）是Innovation（创新）？这里面最关键的是：模型什么时候能参与模型本身的开发？只有当模型参与到开发过程，才能解锁真正的Innovator（创新者）阶段。

我们希望K2能参与到K3的开发，如果你没有Agentic能力，很难做到这件事。但当你具备了Agentic能力，它就可以提出一些新的想法，做对应的实验，分析实验结果，得出结论，迭代下一版想法，或者优化某个Infra（基础设施）性能。这些都依赖很强的Agentic能力才能做。

Innovation（L4、创新）和Organization（L5、组织）也不一定是完全线性的关系，有的也是并行的。我们已经看到这样的趋势——

比如说，当你有了一个Agent，就可以拓展成Multi-Agent System（多智能体系统）。你可以从一个Agent fork（分叉）出很多不同的Agents，让它们去做不同的事情。有些是串行的，有些是并行的，然后再合并，再拆分成不同的task（任务）。可能有的写测试，有的写文档，有的设计软件框架，有各自的分工。

**Multi-Agent System（多智能体系统）**：由多个相互独立但可以协作或竞争的智能体组成的系统。多智能体系统可以表现为多个由语言模型驱动的Agent在一个环境中协作、对话、解决任务，例如：一个Agent负责规划（planner），一个负责执行（executor），另一个监督结果（evaluator）。多个Agent扮演不同专家角色，围绕一个复杂问题展开"思辨式"讨论。
所以它不一定是线性关系，可能两个（L4和L5）同时发生。

但Reasoning（L2）和Agent（L3），可能是Innovation（L4）和Organization（L5）的前提。

张小珺：Innovation（L4）的标志是模型自我迭代，那Organization（L5）呢？

杨植麟：比较简单的一个思考是，它会是一个 Multi-Agent（多智能体）系统。

当然，你怎么把Multi-Agent系统很好地做端到端训练，不要过拟合到某几种Agent类型，让它有更好的泛化性，比较有挑战。

张小珺：Organization是模型的“雪山封顶”吗？

杨植麟：也不是，可能它真的就没有顶。

张小珺：所以你把L1到L5的分级当作一个什么样的刻度？

杨植麟：它是几个重要的技术milestone（里程碑），但它并不一定是串行关系。它不是我们预期某一个能力被解决之后，才去解决下面的问题。

比如Reasoning。如果你真的要解决开放性推理问题，就需要做很强的Innovation，提出新的模型架构，而这又对推理能力提出了更高要求。本质上，是用L4的方法去解决L2的问题，把L2做得更好。

这几个能力，随着时间推移，会持续变得更好。

不过，你在里面有不同技术bet，会让你短期路径出现一些区别。这些短期路径的区别也会有影响——因为你面对的是动态的市场。

张小珺：以前我们会固化认为终点是AGI，今天的终点不是AGI了，那么AGI是什么？

杨植麟：AGI不是某一级台阶，你爬到了这级台阶，突然一夜之间达到AGI。而是说：它是一个方向。

今天在很多领域，你可以认为已经AGI了，做得比99%人类更好。很多数学或编程竞赛，按现在的提升速度，预想很快有很多问题被充分解决。

AGI有两个层面：一方面技术一直在提升；另一方面是技术对人类社会的影响。后者是一个更长周期的事情，也是AGI的一部分。

这有点像蒸汽机产生后，社会变化需要几十、几百年去消化。一些工作变得不再必要，但会产生新的工作。每个人变成“超人”，可以做更多事情。社会的工作方式和运行效率会发生巨大变化。

虽然我们用“登月”（Moonshot）命名公司，但它跟登月有区别。登月是你站上月球那一刻，可以号称“我达到了”。而AI很难在某个时间突然喊出口号，说“我们此时此刻实现了AGI”。

你一直在往上爬。

甚至，过一段时间之后，不一定是你自己在爬，是你用AI在爬。现在我们让K2做数据处理、模型分析、模型训练，以前都要人工做，以后慢慢交给模型做——它像一个放大器，帮你更好地攀登这座山。

张小珺：如果雪山是无尽的，你追求的是什么？

杨植麟：就是攀登的过程。

你原来在山底下，现在又往上提升了一点，能看到的景色不一样。

它是一个动态进化的过程。

## 第二章 K2是乔戈里峰

### 04 喂一样多的数据，“脑子”长得更多

张小珺：我们来复盘一下，你创业这两年的关键决策。2023到2024年你的关键决策是——在23年2月决定了创业、开始融资、组建团队；到了下半年，Kimi上线了、bet了长文本。

2024到2025年，这一年你的几个关键决策是什么？

杨植麟：很重要的一点是，技术上我们从以预训练和SFT（Supervised Fine-Tuning，监督微调）为重点研发范式，转变成以预训练和强化学习为重点的方式。这就需要做很多事——不管是人才的储备，还是研发方式的改变。

另一点是，从对话到Agent是一个重要范式转变，很大程度影响我们的实际工作方式。

张小珺：过去半年你们推出了K1.5和K2，它们分别对Kimi意味着什么？

杨植麟：K1.5更多是强化学习技术的验证。

张小珺：追赶o1？

杨植麟：对，我们比较早在这个技术路线投入，得到一些结果，看背后的技术到底怎么做。

当时我们发现不太需要太多的process reward（过程奖励），或者value function（价值函数），甚至它们在训练过程中还有一些副作用。

我们发现，你可能直接用端到端的reward（奖励信号），就能把训练做得非常好。这在早期还不是非常明确。这个过程中，我们积累了一些强化学习的基建，还有一些算法的know-how（诀窍）。

K2的重点有几个：一是我们希望它是一个非常好的基础模型（Base Model）。如果你想有更好的Base Model，就要去看现在整个领域预训练的瓶颈在哪。

我们发现高质量数据的增长确实很缓慢，多模态数据又无法很好提升文本本身的“智商”，你可以认为高质量数据接近一个常数。这种情况下，我们希望能最大化地使用每一份数据，就是所谓的token efficiency（token效率）。

你希望在吃下一样多数据的情况下，脑子能长得更多，你能得到更多智能。

这里和之前的思路不太一样。你现在假设在训练系统做很多性能优化，让训练更快，这当然有价值。但训得更快本身，并不能提升智能上限，因为token数量还是那么多。你训得更快，只是更短时间完成训练，但模型效果不一定变好，这是训练效率或compute efficiency（计算效率）上的优化。

之前有人做过这方面，我们现在更希望提升token efficiency，把一份数据当成几份用。

我们很关注，比如Muon优化器。它很有意思，对token efficiency提升很大。像Adam优化器用了10年，大部分的模型训练都会用Adam，但它的token efficiency并不够好。

Muon优化器不是把每个元素独立考虑，而是把一个矩阵的参数整体考虑它们之间的dependency（依赖关系）。通过这种方式，获得更好的学习效率——你学同样一份数据，能学到更多智能。

我们早期的实验，如果在compute optimal（计算最优）的情况下，基本会有两倍提升。也就是，你学一份数据，相当于用Adam学两份数据。

假设你有30T的高质量token，等价于你现在有60T的高质量token。

张小珺：但它实际还是那么多数据啊。

杨植麟：它学了之后，脑子会长得更快。因为学习效率更高，优化器更好，吸收得更快。

你喂它一样多的数据，它吸收得更好，压缩率会涨得更快，loss（损失）会降得更快。

张小珺：Muon优化器是你们原创吗？

杨植麟：Muon优化器是Keller Jordan（一位计算机科学家和机器学习工程师，于2024年12月加入OpenAI）提出的，我们在他的基础上做了很多优化，使它能适配并训练非常大规模的语言模型。

我们之前有一个Moonlight的工作，让它能够第一次在一定规模的语言模型上训练。后来在进一步规模化的过程中，发现了很多新的坑，比如max logit（最大logit值，观察训练是否正常的一个指标）可能会出现爆炸的问题。

这个问题在小规模实验中很难发现，但在大规模训练时会遇到。于是我们提出了一些新的方法，比如clipping（截断）技术，让它在非常大规模的情况下，仍然能很好地训练。

这非常重要——因为token数量有限，你希望每一份token能产生更大价值。

张小珺：我读了你们的技术报告，你们尝试已有模型改写现有数据，生成新的语料，具体的改写策略是什么样的？——这个在报告里没有提。

杨植麟：我们会对数据做很多Rephrase（改写）操作。比如你有30T token，但其中高质量数据更少，可能只有几十b或者几百b级别（百亿到千亿级参数量）。你希望这些高质量数据能被很好地利用，我们对这些数据做了一些改写，让它们更好地被模型吸收，并且有更好的泛化能力。

主要思想是，如果你同一份数据学很多次，它可能泛化不一定那么好，有一些过拟合问题。我们希望通过改写，让它有一定程度的泛化。

具体改写方式有非常多种，我们找到一种在实验里效果比较好的。

张小珺：哪种？

杨植麟：这个空间也很大，有非常多的研究机会。

张小珺：你怎么看待一种观点——“改写和扩充其实没用，能够写出来知识，说明知识本身就在里面，没有新知识，除非改写的时候用到其他方法。”

杨植麟：这是一个很好的问题，确实跟改写方式有关系。理论上，还是看你有没有新的熵的输入。它对改写方式有一些要求。但我们现在也不一定用了最好的改写方式，有很多探索的空间。

回到刚讲的点，K2这个模型，一方面是希望它成为一个好的Base Model。我们很希望提升它的token efficiency，这些是我们对应的设计，包括通过更大的稀疏度去加更多的参数。

那它的token efficiency也会更高，因为你参数多了之后，虽然学一样多的数据，但你会吸收得更好。反正通过实验可以验证，确实有更好的token efficiency。

第二是我们希望它有好的Agentic能力。你通过各种强化学习，或者对工具和环境的模拟，让它能有比较好的泛化性。

对于一个Agentic模型来讲，现在最大挑战是在模型的泛化上。

因为现在的RL技术，局限性在于，不管是训练任务还是评价指标，很多时候都是单点。比如你就训SWE-bench同分布的数据，它就提升SWE-bench，是很确定的东西。但是你的指标提升上去之后，并不意味着模型的泛化会变得更好。

**SWE-bench**（ICLR 2024）：一个用于评估大模型在真实软件工程任务中表现的基准测试集。

我们也在尝试去解决一部分泛化问题。不希望过拟合到某一些工具，或者过拟合到某一些环境，或者过拟合到某一些具体任务上。这些任务可能是很好的观测，但我们不希望过拟合它。

这个问题在Agent训练更严重。相比于对话模型，Agent的泛化是一个更大挑战。

张小珺：Agentic能力现在更多在Post-Train阶段训练，为什么不在Pre-Train阶段去训？

杨植麟：这个也是接下来我们想探索的东西。

张小珺：这有可能提高泛化性吗？

杨植麟：取决于你的做法，比如数据分布是不是足够广泛，有没有很好的方法评估。

现在整体的评估，是阻碍Agent模型变得更泛化的重要瓶颈。你会慢慢观察到，现在Agent能用的Benchmark（基准测试）不是非常多。你在那些Benchmark上观察到一个分数，很多时候它并不是对这个能力的反映，比较片面。这是大家要去想办法解决的问题。

有一种潜在思路，我们需要用更AI native（原生人工智能）的方式去训练AI。我们希望让模型参与到更多训练过程。比如，如果你的AI能做很好的alignment research（对齐研究），它理论上会有更好的泛化，不仅只是在优化一些单点任务。

今天Agent还不像对话有这么好的泛化性——接下来雪山上几百个台阶，有可能是这个。

张小珺：听起来K1.5是跟着OpenAI跑，K2是在抢跑。

杨植麟：我们借鉴了很多技术上的方向，但也希望有一些自己的创新。

至少在公开资料，我们是第一个使用非Adam的，或者基于矩阵正交化的方式，去用新的优化器，在这么大规模的模型上去训练。这是一个创新点。

我们在一些Agent数据的做法，至少在公开可查资料里也是比较早去做的。

很有意思的是，当你在雪山上越往上爬，你会发现空间是在变大。因为现在你完成同一个任务用到的token在变多，问题复杂度变得更复杂。

就像刚刚讲的：问题不可避免，但问题总可以被解决。

这些不可避免的问题，看起来会比之前更多，但你的研究空间也会随之更广阔。

_（相比2024年1月访谈时，月之暗面已搬到一个更明亮的办公室。在北京知春路的京东科技大厦13层，那架白色钢琴还在。）_

### 05 Muon你去训的时候，它会炸

张小珺：我们具体说到K2这个项目，它是怎么立项的？中间筹备了多长时间？

杨植麟：筹备是比较长时间的，涉及很多技术从去年开始研究。

像Muon的技术，研究需要比较长周期。你一开始做早期实验，发现这个想法有潜力。我们会有一些小的实验验证这个idea（想法）潜力有多大。

有了想法之后，到最后你能把它放到一个万亿模型去训练，要通过不同的scaling（规模化）实验去验证它的有效性。有些问题只有当你scale（扩展）到一定规模之后才会发现——所以周期比较长。

当然，如果你只看这个模型训练，从按下训练按钮到训练结束，时间并没有那么长。但研发需要更前置做很多事，才能最后保证训练比较顺利。

张小珺：做Agentic LLM（智能体大语言模型）这个bet是什么时间点？

杨植麟：也要做很多积累，只是说，不同时间点做法不太一样。

一开始你不一定端到端去做，但会积累一些环境和数据，到了后面更端到端去做强化学习。你中间需要很多基建和数据积累。很难说一两个月就能做得非常好。

我整体觉得，大模型和相关技术很需要时间积累。还是“要做时间的朋友”吧。技术曲线还是有点陡峭，不是今天想做就能做出来。

张小珺：所以什么时候立项的？为什么立这个项？

杨植麟：一年前积累各种技术，但K2肯定是最近几个月，我们决定要去训一个这样的模型，然后把哪些技术用上，大概是这样一个决策。但不是我今天想训这个模型，从0去搞。

我们一直训练下一代模型嘛。无非是一个决策：我下一代模型要加入哪些技术？你期待它是什么样的模型？就像现在也在考虑，K2之后下一代模型应该长什么样？——这是持续要思考和决策的。

每次会看，现在工具箱又多了很多新东西，把哪些拿出来用？是这么一个过程。

张小珺：你们做研究和做训练的团队是分开的吗？如果一年前已经开始研究这些技术，做正式训练，是一个团队在做整件事吗？

杨植麟：是一个团队，这些东西很难分开。你在实际训练中会遇到问题，如果之前不了解，没办法解决它。

张小珺：K2研发过程中遇到什么挑战没有？

杨植麟：Muon你去训的时候，它就会炸。

我们有画一些图在paper里，你的max logit会涨得非常高，涨到几百甚至更高。我们认为这个东西对训练稳定性有影响，你可能训久了，它很多所谓的内科指标（internal metrics）不正常，对模型上限有害。

我们等于又回过头去revisit（重新审视），修复它。因为这个东西是你在小规模实验上没办法预测的，小规模上不会有爆炸的问题。

其他基本还好，都在小规模上做了很多实验，是可迁移的，问题不是很大。唯一有这个问题是你小规模上验证不了，需要在scale（扩展）过程中再临时解决。

张小珺：最近K2火了，你的心情有起伏变化吗？

杨植麟：也没有，还好——这是一个漫长的旅程。

要持续去做下一代模型，还是回到那两句刻在石头上的话：会产生新的问题，然后就去解决它。这也是最有意思的部分。

张小珺：听说，你在内部群里形容K2意味着乔戈里峰。

杨植麟：K2本来就是世界上最难攀登的山峰之一，名字有点重合。

它不是终点，因为它不是最高的山峰，但可能是最难的。这是因为现在有很多范式转变，从对话到Agent，你的Base Model规模进一步变大，本身存在难度。

**乔戈里峰（K2）**：世界第二高峰，海拔8611米，仅次于珠穆朗玛峰（海拔8848米），位于中国与巴基斯坦交界的喀喇昆仑山脉中。它以极其险峻著称，攀登难度远超珠穆朗玛峰，被登山界誉为"山中之王"或"杀手峰"，因其恶劣的天气条件、复杂的地形和高死亡率而闻名。乔戈里峰多次成为登山者挑战极限的象征，也代表着极端高山探险的终极考验。
张小珺：K2发布的结果超出你预期了吗？

杨植麟：差不多，模型训得怎么样，在过程中就已经知道了，没什么惊喜或意外。

张小珺：你在K2训练中收获的最重要几个know-how（技术诀窍）是什么？

杨植麟：我们都写在paper（论文）里写了。

我们都很open（开放），还是想更多跟社区分享嘛。

### 06 当从“缸中之脑”变成跟世界交互的系统

张小珺：因为K2是一个Agentic大语言模型，你会怎么定义Agent（智能体）并对Agent进行分类？

杨植麟：它可能是一个从“缸中之脑”变成可以跟世界交互，因为所谓Agent最重要的特征，就是它可以多轮地使用工具。

有两个关键点：一个是多轮，一个是工具。

多轮就是你能做很多次，是test time scaling（测试时扩展）的一种方式；工具则是连接这个“脑”跟外部世界的方式。

比如，你用搜索引擎，就可以把模型跟整个互联网连接起来；你可以写代码，就能让“脑”跟数字世界连接，因为数字世界几乎所有自动化都可以用代码描述，它能拥有这种自动化能力。

这两个是我想象中Agent的特征，接下来会有越来越多的工具。当然，工具会呈现长尾分布。如果模型泛化得好，它不只是使用常见工具，能使用非常个性化的工具。

比如，模型能访问公司内部数据库、个人文档，甚至访问定制的API，完成退票、下单等业务操作。它应该能泛化到没见过的工具上。我一直觉得Agent最缺的是泛化能力。

如果泛化能力强，大家讨论的各种垂直Agent就没那么必要了。因为通用Agent泛化到长尾工具上，很多领域专有问题都能通过接入不同工具解决。只要给它加上定制数据库、定制API、定制文档接口，就能做一个非常垂直的Agent。它的普适性会强很多。

多轮主要是实现test time scaling（测试时扩展），可以做复杂任务。不像对话模型一次输出一轮，这个可以做不同的事情——就像人一样——人每天的工作，你可以认为是，多轮使用工具的序列。你希望把人的序列拟合进去，但你又搜集不到这样的数字化数据，你就可以用强化学习来构造。

它本质是在模拟人的行为——不过，你也不能简单说是模拟人，叫“模拟人的行为”不太准确，它其实是通用的。

张小珺：什么叫不能简单说在模拟人，人也很通用。

杨植麟：对，人是通用的，人是所谓的universal constructor（万能构造器）。

**"万能构造器"（universal constructor）**：指一种能够制造任何物体或系统的机器或装置。这个概念源自理论计算机科学和自动机理论，最早由数学家约翰·冯·诺依曼提出。万能构造器能够读取自身的"蓝图"或程序指令，然后根据这些信息复制自己，或者制造其他复杂结构，理论上可以构建任意复杂的系统。
但它主要目的不是去模拟人，主要目的是通用性，这才是设计的目的。

它跟人的做法类似，只是一个恰巧的结果，并不是设计系统的目的。

张小珺：这就好比设计飞机，是为了让它成为交通工具，目的并不是像鸟一样能飞。

杨植麟：我们做Agent系统，更多是为了做一个通用的智能，是跟这个目标对齐；但它刚好跟人相似。

张小珺：怎么提高Agent通用性？你们探索到什么方法没有？

杨植麟：这是很难的问题。今天Agent的泛化有一个风险，可能会陷入某些Benchmark过拟合，但现在又缺少很好的Benchmark。这是接下来的挑战。

不过可能有些解法，我还是觉得能用更多的AI去训练AI，可以一定程度缓解这个问题。

张小珺：什么时候能做到用AI训练AI？现在的瓶颈是什么？

杨植麟：现在部分已经做到，但你希望它做更多。现在很多还是依赖人的设计。

张小珺：这样就到下一个阶段Innovator（L4、创新者）的阶段了。

杨植麟：这很有意思，你要用一些Innovation方式去解决Agent问题。因为Agent泛化不够，你得用创新去解决——用L4的技术去解决L3的问题。

所以L1到L5的定义可能真的不是线性的。没有好的Innovation，没有用AI去训练，或者用AI对齐AI的方式，Agent很难做到好的泛化。

你人工定义一些 task（任务），只fit（拟合）那个 task，但在别的看不见的task表现就不好。只刷几个task分数，但用户在更多OOD（分布外，out-of-distribution）场景中体感没有那么好。

现在这个领域面临的是，Benchmark不够用或失效，Agent泛化有问题的阶段。

张小珺：为什么数学和代码是相对容易泛化的领域？

杨植麟：其实也没有。如果做强化学习，现在也有类似问题。

强化学习本身的泛化性，比做SFT（监督微调）要好，因为过程中有更多的on-policy（基于当前策略）sample（采样），模型从自身采样中学习，泛化看起来更好，而且有负梯度。这两个因素导致从证据来看，泛化表现更好。

但泛化是有限的。比如说，你在某种类型的数学竞赛做到99分，别的数学问题可能提升5个点，但很难直接做到99分。如果不做对应的RL任务，就很难直接做到这样的泛化性。

所以做数学题也有类似问题，是被分布所制约的——还是“种瓜得瓜，种豆得豆”。

但是我们希望强化学习或后训练用更多AI ，让模型摆脱“种瓜得瓜”的情况。

张小珺：有没有可能最终就是摆脱不了，大幅提升不了泛化性？

杨植麟：还是回到刚刚说的，问题不可避免，但问题可以被解决。你每次都会往前推进——泛化会变得更好，它不一定有尽头，一直会有更好的泛化。

张小珺：对于Agent来说，任务和环境非常重要。怎么定义好的任务？怎么定义好的环境？你在探索过程中有没有一些思考？

杨植麟：一种方式是，我给定一个模型，然后设计一些环境，去逆向拟合这个模型。当然你也可以正向设计，假设你是一方的开发者，正向设计工具和环境，让模型在这些环境里提升能力。

关键是让这个设计有更好的通用性。它能做很多任务，不应该为了某些特定任务专门设计工具和环境。当设计足够通用时，模型能在这其中学习，而不是反过来拟合模型。这可能是更好的做法。

张小珺：我注意到一点：一般大家认为在任务设计上，倾向于设计一个足够有挑战的任务，这样会催生一些更本质的新方法；但K2设计的是一些中等难度任务。这是出于什么考虑？这会影响通用性吗？

杨植麟：它也是一个爬山过程。你不能一上来就让模型去证明一个还没有人证明过的数学问题，样本效率（sample efficiency）会非常低。

现在比较好的方法是，强化学习如果搭配好的采样策略，本质是隐式的课程学习（curriculum learning）机制，希望模型从合适的难度开始学习，逐步提升难度，而不是一开始就学非常难的任务。否则采样效率低，基本学不到什么东西，算力可能都会被浪费掉。

但挑战在于，今天的很多任务还是基于人类存量数据或人工设计的任务，AI native的部分还比较少，会带来泛化性问题。

张小珺：在你眼中，Coding Agent（编程智能体）和通用Agent（通用智能体）是什么关系？

杨植麟：Coding Agent是任务的一个子集，但可能是很重要的一个子集。

最后还是希望不仅仅做Coding。包括现在我们训练的模型，也不是只让它做Coding，因为它本身有一些局限性。

张小珺：可以这样说？——Coding相当于人类的手。

相对来说，Coding对Agent是比较容易的任务，是吗？

杨植麟：它比较好验证，所以比较好学习。它也会面临类似挑战——泛化性问题，即便是Coding Agent也会遇到一样的挑战。

Coding Agent是很重要的一个子集在于，它代表了数字世界的自动化。现在很多Agent工具集合是固定的，如果你想创建一个新的工具，本质是写一段或者一大段代码实现。或者如果你想做更好的上下文管理（Context Engineering），背后也对应一个工具，这个工具可能也用代码实现。代码在这里面有独特的位置和作用。

但并不是做了Coding Agent就足够。因为很多非程序员也会用Claude Code完成任务，比如律师、产品经理、设计师，他们用Claude Code是因为模型在一定程度上有泛化能力，不仅仅是写代码。

张小珺：你们想做的是通用Agent，而不是Coding模型？

杨植麟：我们还是希望做通用的模型。

张小珺：从写代码到操纵整个数字世界，Agent目前还缺乏哪些能力？

杨植麟：现在这些高频工具使用还不够好，能力上有很大空间。这也说明现在缺少更好的Benchmark观测。SWE-bench现在可能马上会饱和，很多Benchmark不够好，不够真实反映实际用户体验。

高频工具本身会有空间。长尾工具，在一些你没有见过、完全OOD（Out-of-Distribution，分布外）的情况下，怎么有更好的泛化？也是很重要、需要解决的问题。

张小珺：对于Agent ，Long Context（长上下文）和Long-Term Memory（长期记忆）重要吗？

杨植麟：Long Context也很重要。因为现在很多任务，128K或256K这种Context完全解决不了，你需要百万级甚至更多。

而挑战在于，你不仅要能处理这么长的Context，还要保证“脑子好用”，智商要非常高。

这对于模型的训练，挑战是很大的。一方面你希望压缩率足够高，模型要足够大；另一方面你希望它比较长。这两者之间天然存在一些冲突，所以需要更好的架构。

但是有些架构你会发现，它在更长Context下效果会有提升，但在短Context下不一定会有提升，甚至会有下降，这就涉及架构的平衡问题。

不过这些问题接下来可以逐步被解决，我觉得有一些解法。

此外，当前的RL训练方式还有很大提升空间。比如在训练复杂的多智能体系统（Multi-Agent System）时，如果只使用端到端的reward，很可能不够。中间的reward如何产生？是否能摆脱一些人工设计？

这也是非常值得探索的方向。

## 第三章 既简单又复杂的系统

### 07 开源 vs 闭源

张小珺：我回看我们去年的对话，有一个问题非常想问你。
你去年说，开源会落后于闭源。因为开源的方式跟以前不一样，以前所有人都可以贡献到开源，而现在的大模型开源，本质是中心化的，社区贡献没有经过算力验证。相比之下，闭源阵营会人才和资本聚集，是对市场资源的整合。

你当时说：“领先者不会开源，只有落后者才会这么做。”

但今天你们开源了。

杨植麟：因为我们现在，在全球范围内还没有完全领先（笑）。

有些判断在大方向上是成立的：当你的模型发布，社区可以贡献一些东西。比如，你在推理侧可以做很多事，你可以让模型被更多人免费使用。

但如果要贡献到模型本身、让模型变得更强，目前只有原厂能做。

当然，如果你看Base Model，确实如此；但如果基于一个开源模型去做大量后训练（Post-Training），尤其是Agentic的Post-Training，可能催生新的机会。

假设你现在非常想做一个法律相关Agent，你是创业公司，那你完全可以基于K2，在你的特定工具集合之下训练一个Specialized Agent（专用智能体），它可以在你关注的场景下表现得非常好。这种机会存在。

更多是赋能下游应用，而不是反哺基础模型的提升。当然这个问题要动态观察。

张小珺：你们会长期选择开源吗？

杨植麟：这是我们希望长期做的，但不一定只做开源。我们希望跟社区分享技术know-how，这是加速技术提升的重要点。

大家可以不完全是竞争，也可以有合作，甚至所有开源公司形成一个生态，更好地推动技术发展——雪山可以爬得更好，race to the top（冲向顶峰）。

但也不一定所有都开源。比如跟某些公司合作，不一定都开出来。

张小珺：总的来说，开源是一个技术体系的信仰，还是一个市场博弈的策略？

杨植麟：客观说都有，而且都有好处。但最终我们希望通过这个让技术更安全、更快达到更好的水平。

张小珺：开闭源的生态会怎么演进？在你的认知中，最终开源和闭源全球会剩下几家？

杨植麟：不会很多，但几家还是会有的。你如果看过去两年，这个趋势比较明确——市场逐渐更集中、更收敛、更聚焦。可能一开始有几百个，到几十个，到几个。

几个，或许是最终稳定数量，现在看是大概率的事。

张小珺：你们属于开源那一边还是闭源这一边？

杨植麟：这要动态去观察，我们希望长期分享更多技术。

张小珺：为什么中国公司大部分都开源了？

杨植麟：客观说，有市场博弈的因素。但这对社区是好事。

### 08 多模态不损伤“脑子”已经很好了

张小珺：你怎么看AI时代的产品？做AI产品跟做移动互联网产品有什么不一样？——你以前很喜欢说“模型即产品”。

杨植麟：我只能说AI产品，移动互联网产品没做过。

（模型即产品）现在没有变化。你做一个Agent产品，需要把模型跟工具和Context结合起来。但你会发现，训练模型的时候，基本得把这一整套系统搭好，才能训练这个模型。

模型训练完成，产品也基本完成了。在这个基础上做一些交互上的改进当然有价值，但那是锦上添花的一步。

你的模型性能在训练中已经打磨好，跟工具和环境有非常好的适配——也就是，产品是在训练过程中完成的。

张小珺：去年，你提到现在的开发方式已经演变成——你要做一个巨大的系统，就像20世纪初Google做搜索引擎系统。你今天对于AI时代的巨大系统，有更多的想象吗？

杨植麟：现在的系统复杂性在于，你想让这个模型变得通用。一方面它变简单了，另一方面它变复杂了。

简单在于，你只要把所有东西放在同一个模型，不需要维护那么多模型，也不需要搞一堆的routing策略（路由策略）。从概念上，或从工程实现上，它变简单了。

但同时，它也变得复杂。如果你希望它通用，就希望这个模型在各种场景下都能工作。比如你做Agent模型，你不希望它只在你的工具集工作，而是希望别人用这个模型时，即便是别的工具集，甚至你没见过的工具，或者定义和实现方式不同的工具，它也能工作。这个要求很高。

像现在Agent里面，可能会有几种不同类型的任务，不管是Coding Agent（代码智能体）、Search Agent（搜索智能体），还是其他Agents，你要把它放在同一个通用模型，就可能有打架的问题。也许工具定义不一样，或者数据pattern（模式）不一样。

就是，你把它做成一个通用模型的过程，有很多技术挑战。

但如果你不做成通用模型，它的泛化性又没那么好，只能做一件事。特别是现在的Agent，它需要很多步才能完成任务。即便是程序员，也不仅仅是写代码；就算写代码，也不仅只做SWE-bench。你要做出很通用的、真正可用的东西，随着步数变多，对通用性要求会更高。

它的系统复杂性，体现在训练模型的过程中，要让这个模型足够通用，而不是只拟合到某些单点能力上。你如果只拟合单点能力，可能Benchmark分数很好看，但通用性不够——这是现在这个系统，我能观察到的比较大的挑战。

有一个例子是，如果你想往模型里加多模态能力，你就需要让这个多模态能力不要损伤它的“脑子”。

张小珺：多模态只能做到不损伤？

杨植麟：对，能不损伤已经很好了。

你希望在多模态模式下，跟文本模式下，共用一个“脑子”；你希望它在多模态的模式下，也能把文本那部分的智商激发出来，而不是进入另外一部分参数，那它可能完全丢掉了原来文本学习的部分。

当你做一个通用模型，会面临这样的挑战。当你有各种模态、各种任务类型，还有Agent、Reasoning、Chat这些，要全部融合到一起，是存在挑战的。

而且现在不仅是做SFT，还要做RL，挑战进一步加重。

通用的Pre-Training比较好做，你只要把所有文本放在一起，它基本不会有太多问题。但越到Post-Train后期，越到RL，这个问题会更加严重——这是它的系统复杂性。

### 09 当你通过新的交互，收集的信号噪声减少

张小珺：你看，搜索引擎系统是构建在PC互联网之上，推荐引擎系统是构建在手机，也就是移动互联网之上。在AI时代，新的超级节点会出现在哪里？

杨植麟：它会跑在很多数据中心，Jensen（英伟达创始人兼CEO黄仁勋）经常说的AI factory（人工智能工厂）。但还是会有更多终端，终端有些复用现在的，有些可能是新的。

张小珺：会诞生新的交互方式吗？

杨植麟：肯定会。两年前看，Chat是一种新的交互方式。现在Agent，有很多新的交互方式，比如你让它异步执行一个任务，可以看中间结果。

你看Coding，一开始是Copilot，之后有Cursor，再之后有Claude Code——每一代的交互都发生了变化，交互是随着模型的变化而变化。

当你有新一代模型，能力提升很多，就会发现交互可以改了。你不再需要一个一个点accept（接受）修改，而是多步执行一个Agentic Coding任务。

当然，今天Claude Code的交互也不是终极形态，因为模型还会继续提升，能力提升之后，交互会持续变化。比如你有一个Multi-Agent System，交互方式会怎么样？可能随着能力边界不断变化。

张小珺：今天的Scaling Law（扩展定律）放缓了吗？

杨植麟：Scaling Law遇到数据墙了，这是客观事实。你要突破数据墙，就需要提高token efficiency。这也是我们为什么做提高token efficiency的事情，数据墙是存在的，同时你要scale（扩展）更多算力到各种RL任务上。

但我们现在观察，模型变好的速度并没有减少，甚至在加速。

张小珺：为什么AI产品发展到今天，还没有形成数据飞轮？

杨植麟：因为基于算力的scaling太强大了。

比如你先去scale Pre-Training（预训练），再去scale RL（强化学习），而RL的scaling效率又比Pre-Training高很多。因为它是on-policy（基于当前策略）且带负梯度的训练，所以scaling效率更高。

当你有很高scaling效率的时候，你直接去scale compute（算力）、scale FLOPs（浮点运算次数）带来的提升非常大，相比之下其他手段带来的提升很小。这是一方面。

另一方面，所谓数据飞轮很依赖外部环境的feedback（反馈）。这个feedback，我们不希望它有很多噪声。但现在还没有把这个问题解决得非常好。

大模型的学习对噪声比较敏感，它跟传统的，比如推荐系统不太一样。推荐系统可能没那么怕噪声，但大模型是敏感的。

现在看起来，基于FLOPs的scaling是更有效路径。但这个平衡什么时候会发生变化？——也有可能你通过新的交互，让你收集到的信号的噪声能够减少。

张小珺：这就需要创造一种新的交互范式。

杨植麟：对。但这个交互又要适配模型能力的发展。你的交互不能超越模型能力，应该是在当前模型能力范围内，设计一个好的交互。

这是值得尝试的。只是在今天看，去scale FLOPs的维度，或者提升学习效率，是一个确定性更高、更有效的方法。

张小珺：如果按闫俊杰（MiniMax创始人兼CEO）的说法，用户数据无法提高模型的智能，那今天是不是没必要做To C（面向消费者）产品，就一门心思提升智能就好了。

杨植麟：这要看怎么理解。你可能没办法直接使用用户反馈去训练；但有一定用户量的好处是，你知道需求分布是什么样的，知道哪些地方用户用得好或不好，可以把这些东西抽象成evaluation（评估），再去优化模型。如果模型完全没人用，你不知道该往哪个方向优化。

另外也要看用户的商业价值。现在又到了一个新的分水岭：用户是有可能产生商业价值的。你看OpenAI，C端用户产生了很大商业价值，占了它营收比较大比例。

特别是现在很多Agent产品，能端到端产生价值，所以也要看你是什么用户。如果只是闲聊、查天气，商业价值没那么大。但如果是Agent专业用户，本身有很好的生产力价值。

张小珺：最近一年，你对C端产品有哪些新的思考？

杨植麟：更多还是想模型怎么做，因为模型训好了，产品基本做得差不多了。我们还是会沿着这个方式一直做。

张小珺：有人说，Kimi是从最初想做“中国的OpenAI”——当然你以前并不认同这一说法——转而想做“中国的Anthropic”。你们内部有这样的定位转换吗？

杨植麟：很难用这样的方式去定义。中美的语境、土壤不一样，今天更多是从全球视角去思考问题。“做中国的某某”，不太成立。

其实简单一点，我们希望继续爬山，做时间的朋友，和社区一起加速技术的推进。

### 10 Long Context架构会影响“智商”

张小珺：作为Founder，你现在生活节奏是什么样的？

杨植麟：可能睡得比较晚，哈哈，每天不一样。

但也还好，花很多时间看怎么把模型训得更好。

张小珺：你的时间主要投入在模型训练上？

杨植麟：是吧，但模型训练是个抽象概念，重要的是技术战略，这是公司战略里最关键的一部分——下一步哪些要做，哪些不要做，因为技术空间很大，总要选一些方向重点投入。

我们在很多方向上的bet比较早，且是有效的。我们很早去做long CoT的RL，反应比较快；去做优化器；去做更大规模的Pre-Training；去做第一个Open的Agentic模型，这些都是技术关键决策。这些决策能决定公司五六成走向。

但你要做很好的决策，需要很多证据，还得做很多实验。你得非常了解实验的具体结果，不能拍脑袋，得知道更多信息。

张小珺：这些决策中令你最纠结的是哪个？

杨植麟：也还好。关键是一个收集数据的过程。做实验，看实验是不是扎实。加上你对技术的理解去判断。很多时候只要数据足够充分，判断比较显然。

接下来——至少现在，K2的性能潜力还没完全被压榨出来。我们之前放的更接近是一个Base Model。我们可以加更多Post-Training阶段的FLOPs（浮点运算量），上限应该比现在高很多。

我们还会做下一代模型，但具体怎么做，我们通过实验来决策。

张小珺：也会加多模态吧？

杨植麟：多模态是比较确定的。

但多模态的能力本身要做好不容易。里面有很多工作：怎么让它去借鉴文本的脑子，而不是自己单开一个脑子。比如你MoE（专家混合，Mixture of Experts）里假设有20个expert（专家），专门在做多模态，你可能不希望这种情况出现——这样，你可能学出来的多模态是个“傻的多模态”。

我们希望它是个“聪明的多模态”。

张小珺：接下来还会有哪些重要的技术里程碑？

杨植麟：Agent的泛化性是最重要的。

Long Context的支持，我们会继续研究。特别是在智商很高的情况下，还能有更长的Context，也是很重要的问题。

现在很多Long Context架构还是会影响“智商”。

张小珺：为什么Long Context架构会影响“智商”？

杨植麟：纯粹的Linear Attention（线性注意力机制）可能就是会影响智商，因为这个架构会有一些bias（偏差），这些bias在一些场景下效果没有那么好。但一定程度上是可以被解决的。

张小珺：你怎么看张祥雨（阶跃星辰首席科学家）说的next token prediction（下一个token预测）的本质缺陷？

他的意思是，随着模型规模扩大，对话能力、知识量和情商都在变强，但推理能力尤其是数据表现是先上升后平缓，再扩大反而下降。用更大的模型做数学题，容易跳步、不老实。这是next token prediction的本质缺陷。

杨植麟：所以要搭配强化学习的scaling（扩展）。如果今天不做强化学习，模型很难说很聪明。像数学题，不一定做得非常好。

但更大的base（基础模型），强化学习的上限会更高。因为知识更多，本质是激活一个推理的范式，让它能把知识解锁出来。它的上限更高，但需要搭配RL去激活。

张小珺：你怎么看待世界模型？——有人说，做世界模型是造世界，做Agent是造人。

杨植麟：用AI训练AI有点这个意思。你有一个很好的世界模型，就能模拟这些东西，就是用AI训练AI的方式。

它可能是通往更好泛化的一种路径。

### 11 边界与现实

张小珺：现在，我们来讨论一些现实问题。

基座模型公司和做Agent产品的应用公司，长期看边界在哪？

杨植麟：我没有明确答案。只能说今天，“一方产品”有个好处，可以垂直整合，把模型放在里面训练，模型和工具融为一体，不是分开做再逆向工程。

但因为Agent领域广阔，“一方产品”不一定能做得过来。如果能找到一些空间，比如工具的实现需要非常多领域的know-how，或者evaluation是“一方产品”考虑不过来的东西，是有机会的。

因为有像K2这样的开源模型，大家可以在上面微调（fine-tune），更容易产生Specialize Agent（专用智能体）、垂直Agent的可能性。

张小珺：那要看通用模型通用到什么程度了。

杨植麟：不管多通用，总还是有一些工具你要做。你有可能不一定做模型，而是把工具做得非常好。

这个工具如果做得太通用，就会和“一方产品”overlap（重叠）比较大——这种情况下，垂直整合优势更大。

但如果工具是专门针对某个场景，甚至别人做不了。比如你掌握了一些线下服务入口，你的下订单或者成交的工具别人做不出来，你可能产生独特价值。

当然也有另外一种可能性，当“一方产品”或通用Agent的流量和商业模式足够成熟，很多专有的、本来垄断的工具也愿意接入，因为整体商业化效率会更高。但商业化效率的提升需要时间。在这段时间窗口内，专有Agent也会有空间。

最终，通用之所以有效，是因为整体商业化效率更高。今天，包括很多内容平台，最终有可能你把内容接到通用Agent，商业化效率会比今天更高——但可能要花很长时间。

张小珺：像Manus这种公司，会是你的潜在客户还是竞争对手？

杨植麟：还很早期，很难判断到底是什么样，产品本身也会演进。

短期，更多是合作大于竞争。今天Cursor、Perplexity、Genspark也都可以看到K2的身影。

但未来会演进，有点像Claude和Cursor的关系。Cursor也可能需要动态调整产品策略。它可能需要一方面具备一定的模型能力，因为技术曲线还很陡峭；另一方面，它能不能有一些别人做不到的工具或环境？

现在没法直接回答。只能说目前，一方的整合优势还存在。

张小珺：你今天怎么思考商业模式？API是好生意吗？

杨植麟：目前明确的商业模式：一是API服务，二是“一方产品”。我们都会做一些尝试。今天最主要优先级是把模型做得更好，这依然是首要目标。

在模型提升过程中，如果在某些方面领先，确实有商业化空间。今天市场规模增长非常快，头部公司有几十亿甚至上百亿美元ARR（年度经常性收入），每一两个季度可能实现两三倍增长。我们会动态观察，做出相应尝试。

张小珺：一位你们的用户说，他很喜欢Kimi，但也担心Kimi赚不到钱，你们能赚钱吗？

杨植麟：还是先投资。能不能赚钱，取决于模型效果怎么样。

我们也愿意服务用户的最后一公里体验，为用户交付高价值问题的deliverable（可交付成果）。

全球百亿美金且高速增长的AI市场里，专注把技术做好，其他反而更有确定性。

## 第四章 在自己的故事里面

### 12 用RL的方式去管理，而不是用SFT

张小珺：过去一年，你对组织有新的思考没有？

杨植麟：好问题。最近一直在想一个事，有几个东西是联系在一起。

你看科研，或者创造新知识的过程，很像一个强化学习（RL）的过程。

之前有种经验主义理论说，人是通过经验获取知识。但后来很多观点认为不是这样。人类在地球上存在非常多年，直到几百年前没有任何人说“地球是个球”。你一直在经验里，但你不知道事实是什么样的——经验并不能直接给你知识。而是，你提出这个猜想，说我认为“这个球是圆的”，我想各种方法验证它。

包括训练神经网络，你可能观察到一些内科指标不太对，你提出“为什么它会这样”的猜想，设计实验去验证——这个过程和强化学习非常像。

同时，你发现，管理一个团队，也是这样的方法。这是Tim（周昕宇，月之暗面联合创始人）天天跟我讲的——要用RL的方式去管理，而不是用SFT。

当然现在，你做RL的时候也希望加一点SFT，因为SFT是很好的先验，防止模型“飞太远”。但你又要管住自己的手，你不能SFT太多。SFT太多，团队成员会失去主观能动性，没办法创新。这点我现在也在实践，看起来有一些效果。

核心是掌握SFT和RL的平衡。

SFT是你告诉他“这个事情该这样、这样做”；
RL是你给他一个奖励，如果做成这样是好的，更多反映在目标上。

可能要以RL为主，用一部分SFT通过先验去控制，或者防止它遗忘重要的东西。

RL是一种很本质的东西。在科研、模型训练、组织管理上，是相通的。

但这也带来一个挑战：在RL过程中，怎么定义reward（奖励）。你简单设定一个目标，比如“把所有Benchmark拉高”，大家会不择手段去overfit指标。但分数高了，模型本身并没有真的更好。

所以，奖励的定义就很重要，需要你很理解具体细节是怎么运作的。不然会出现reward hacking（奖励机制被滥用）。

张小珺：所以在组织内部，怎么定义reward？

杨植麟：你建立更多观测指标，尽可能不要过拟合，是一定程度有效的。这样你才有更好的泛化，不会被hack（利用漏洞）。

用RL管理团队最大问题是，你容易被hack。大家看起来各种结果很好，但实际并没有达到你最终想要的——这是风险。用SFT管理团队的风险，是大家失去创造力。最后这几个东西要有一定程度的balance（平衡）。

当然我也在学习，今天不是做到很完美。

### 13 AI是人类文明的放大器

张小珺：过去一年Kimi在波峰波谷来回震荡，身处其中，你的心态是什么样的？需要平衡自己的心态吗？

杨植麟：心态就是，做时间的朋友吧。

张小珺：真实的人的心态不会这么简单的。

杨植麟：像你说的，会有高点和低点。可能很重要的是，还是喜欢做这个事情，想把它做好。所以你也不用想别的，就想怎么把它做好。好像也比较简单，没有什么特别复杂的。

很多复杂性都是人为强行加上去的，实际并没有那么复杂。

张小珺：你对人性有更多的理解没有？

杨植麟：这也还需要时间的打磨，不敢说那么深入。

只能说是在自己的这个故事里面——你不断地感受自己到底是什么样的一个人，你为什么要做这个事情——不断去思考这些问题。

张小珺：你是一个什么样的人？你为什么要做这样事情？

杨植麟：就是觉得有意思。

张小珺：什么有意思呢？做实验有意思，做科研有意思，还是做AI有意思？

杨植麟：寻找真相的过程。去不断发现新的问题、解决它的过程。

张小珺：那你也可以解决别的问题啊，为什么一定要解决这个问题？

杨植麟：因为这个东西很重要，AI很重要。

这个问题我也问过Kimi。他说，这个东西是“人类文明的放大器”，我觉得很有道理。

又回到The Beginning of Infinity，从启蒙运动到现在，人类一直在寻找新的方法突破知识的边界。但是，可能下一个突破边界的，是靠AI，它是一个巨大的杠杆。

你今天在任何一个前沿学科，要花二三十年，才能学到最前沿知识。但是AI一夜之间就能学会，往下去做新的突破。

AI会成为Meta science（元科学）。

它是人类文明的放大器。

张小珺：它有可能摧毁人类文明吗？

杨植麟：这个风险不能说不存在，但我们可以有很多事去做。不管是更安全地对齐，还是更好的社会机制。

比如说，当AI可以做一些事情，它很有可能创造一些新的工作，我们需要有一些方法去完成这个过渡。

我exactly问过Kimi这个问题。他说，虽然有这样的风险，但我们不能放弃。因为如果放弃，就等于放弃了人类文明的上限——你不知道上限能做到什么样，有一点“因噎废食”的感觉。

但我承认，我们得做很多去应对。因为你今天看到很多AI的能力，是有点让人震惊的，半年前根本想不到它能做到。

同时我认为，人类的独特价值在这个过程中会持续存在。人的体验、情感，没有办法被AI替代。所以，可能会有不同的活法，希望是能活得更好。

张小珺：什么样不同的活法？

杨植麟：我之前觉得，人的一生有几个意义：创造、体验和爱。当然每个人不一样，对我是这样。

“创造”的很大一部分，也许AI可以做。我享受这个过程，但不得不承认，有一天很多创造性工作是AI去做。但后两条，“体验”和“爱”，会是以人为中心的。

张小珺：如果AI把创造拿走了，也把生产力拿走了。

杨植麟：这无所谓，人可以享受生产的结果，如果我们有好的机制。

但它是一个缓慢过程，不会一两年做完，需要一二十年逐渐调整。

张小珺：你会频繁地和Kimi聊天吗？

杨植麟：当然。我要测试模型。

张小珺：你会和他聊一些很深刻的话题或者自我探索的话题吗？

杨植麟：有时候会。也还好，还有一些是工作上的问题。

张小珺：过去这一年，你有经历过情绪很低落的时刻吗？

杨植麟：我觉得也还好。更多是：有些东西会work，有些东西不work；会解决一些问题，会有新的问题产生——不断在这个过程中。

只要你觉得这个东西有意思，就一直想继续做下去。

### 14 任何中间状态都有可能成为被批评的对象

张小珺：过去一年，你有没有走过一些弯路？

杨植麟：肯定有。过程中会有很多很多决策，有一些技术决策，有一些业务决策。

很重要的是，一个公司在这个过程中逐渐调整的能力。知识创造的过程也是这样的过程——不可能创造出来的知识，所有东西都是对的，你会发现有些东西也是错的，但它在一定时间内可能是对的，一定时间可能又是错的。但当它错了之后，你就得去做调整。

比如像牛顿做的很多东西，在当时是最好的理论，但不是完美的，在一些场景下是完全错的。万有引力需要有一些别的解释，需要有一些相对论的解释，通过时空的扭曲去解释。

我觉得组织的进化、公司的发展也是一样，是一个动态过程。任何的中间点，你在某个时间点是对的，在另一个时间点可能就是错的。

这也是Kimi跟我讲的——任何中间状态都有可能成为被批评的对象。你总是会有这个时代的局限性。

更重要的是，你怎么在这个过程中，一方面投入一些“不变”的东西，比如人才、技术积累；另一方面适应和调整，针对环境变化和反馈信号做调整。这两个都很重要。

张小珺：互联网产品通过市场推广去扩大DAU，扩大市场规模；AI产品似乎有所不同，增长和获客更依赖模型能力的大幅跃升——智能和推广，哪个更本质？

杨植麟：它还是取决，两个变量哪个大。在技术快速发展的阶段，你很难通过市场推广的方式去赢得战争。它更多是一个辅助手段。

只是说这个辅助手段跟你的主要手段之间，到底什么样的配比？需要动态调整，也取决于你现在商业化进展，或者PMF到底有多强。不同时间点有不同策略。

甚至这个策略也许再过一两年，你发现又是一个好的策略。我觉得也不一定。

我们是用更open的心态去看，但在每个时间点最重要的是去抓住——哪个是最大的变量。

张小珺：又过了一年，你觉得Kimi的成功概率增大了还是失败概率增大？

杨植麟：我觉得（成功概率）增大了。你只要每往上爬，成功概率会变大，因为会有一些人不继续爬了。

张小珺：你恐惧摔下去吗？

杨植麟：肯定有恐惧。

更多要关注你当前这一步，能做什么？——想这个问题更重要。

张小珺：我一直在问你的情绪，你都说：唉，还好、还好。你最近一次或两次“颅内自嗨”是什么情境？

杨植麟：不以物喜，不以己悲。虽然很难做到，但要避免情绪化决策。

张小珺：你会情绪化吗？

杨植麟：多少肯定会——你是一个人嘛。但要避免一些情绪化决策。最终落实到决策和执行上，要更理性一点。

张小珺：过去一年，你最大成长是什么？

杨植麟：认识到这一点：问题不可避免，它会一直存在，持续解决新问题是最重要的，可能也是最有意思的——这是心态上的变化，它会改变很多做事的方式。

张小珺：这听上去是一种正念。

杨植麟：我不知道怎么理解，但可能差不多。（笑）

张小珺：我问你最后几个快问快答。

一个全球范围内你喜欢的食物。

杨植麟：拉面！

张小珺：为什么？

杨植麟：好吃！

张小珺：一个少有人知道但必须知道的知识点。

杨植麟：我好像不太擅长回答这种问题。

张小珺：基于所有读过的书，推荐必读书。

杨植麟：有一本我刚刚一直在讲，就推荐这本。

张小珺：你心目中影响AI进程的几篇论文是什么？

杨植麟：最重要的几篇论文是Backpropagation（反向传播）、Transformer、GPT-3。

当然有一些是building block（基础模块），也很重要，比如ResNet（残差网络），它可能是优化的基础。还有Adam（自适应矩估计优化算法）。现在可能还有Muon。

张小珺：基于当下认知，一个最关键的bet是什么？

杨植麟：泛化的Agent（智能体）。

用Innovation（创新），用L4做L3。

张小珺：这一年，你有没有任何的顿悟时刻？

杨植麟：不知道，我感觉我脑子已经糊了。

我已经把一年的话都讲了。

现场第三位人士：这可能就是，Long Context影响智商。

杨植麟：没办法。

碳基生物的局限性。（笑）
