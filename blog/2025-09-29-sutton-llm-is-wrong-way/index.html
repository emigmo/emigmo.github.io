<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Sutton：大语言模型走错了路，不符合「苦涩教训」精神 | Chao Yang </title> <meta name="author" content="Chao Yang"> <meta name="description" content="2024年图灵奖得主Richard Sutton对LLM发展方向的深度批评与反思"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link defer href="/assets/css/bootstrap-toc.min.css?6f5af0bb9aab25d79b2448143cbeaa88" rel="stylesheet"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://emigmo.github.io/blog/2025-09-29-sutton-llm-is-wrong-way/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Chao</span> Yang </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/chinese/">中文简介 </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/publications/">publications</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/projects/">projects</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/blog/">blog</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="row"> <div class="col-sm-3"> <nav id="toc-sidebar" class="sticky-top"></nav> </div> <div class="col-sm-9"> <div class="post"> <header class="post-header"> <h1 class="post-title">Sutton：大语言模型走错了路，不符合「苦涩教训」精神</h1> <p class="post-meta"> Created in September 29, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/tag/reinforcement-learning-llm-bitter-lesson-ai-philosophy"> <i class="fa-solid fa-hashtag fa-sm"></i> reinforcement-learning LLM bitter-lesson AI-philosophy</a>   ·   <a href="/blog/category/research-insights"> <i class="fa-solid fa-tag fa-sm"></i> research-insights</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <h2 id="前言">前言</h2> <p>Dwarkesh Patel 最新播客迎来了重量级嘉宾：强化学习创始人之一、2024 年图灵奖得主 Richard Sutton。这场对话火药味十足，Sutton 直言不讳地批评了当前 LLM 的发展方向，认为它们根本没有真正的智能，甚至违背了他在 2019 年提出的著名「苦涩教训」（The Bitter Lesson）原则。</p> <p>作为强化学习的奠基者，Sutton 的观点引发了 AI 社区的激烈讨论。他认为真正的智能必须具备持续学习能力，而 LLM 只是在模仿人类，缺乏真正的目标和世界理解。</p> <hr> <h2 id="一核心分歧llm-到底算不算智能">一、核心分歧：LLM 到底算不算智能？</h2> <h3 id="11-sutton-的智能定义">1.1 Sutton 的智能定义</h3> <p>Sutton 的观点犀利且明确：<strong>LLM 只是在模仿人类，而不是真正理解世界。</strong></p> <p>他认为真正的智能必须具备几个关键要素：</p> <ul> <li> <strong>有明确的目标</strong>：能够追求具体的、可衡量的目标</li> <li> <strong>能从经验中学习</strong>：通过与环境交互获得新知识</li> <li> <strong>能预测世界的变化</strong>：理解行动的后果</li> </ul> <h3 id="12-llm-的根本缺陷">1.2 LLM 的根本缺陷</h3> <p><strong>预测目标的错位：</strong></p> <blockquote> <p>它们只是在预测「人会说什么」，而不是预测「世界会发生什么」。</p> </blockquote> <p><strong>缺乏真正的目标：</strong></p> <blockquote> <p>「LLM 没有目标，」Sutton 强调，「预测下一个 token 不是真正的目标，因为它不会改变世界。」</p> </blockquote> <p>在他看来，没有目标就没有智能可言——这就像一个只会鹦鹉学舌的系统，看起来很聪明，实际上并不理解自己在说什么。</p> <h3 id="13-持续学习能力的缺失">1.3 持续学习能力的缺失</h3> <p><strong>致命的局限：</strong> 更为致命的是，LLM 缺乏持续学习能力。它们在训练阶段学习，然后就被冻结了。即使在对话中遇到了意料之外的回应，它们也不会因此而改变或学习。</p> <p>这与真正的智能体，无论是人类还是动物，都形成了鲜明对比。</p> <h2 id="二体验时代-vs-模仿时代">二、体验时代 vs 模仿时代</h2> <h3 id="21-体验时代的愿景">2.1 体验时代的愿景</h3> <p>Sutton 提出了一个重要概念：<strong>体验时代（Era of Experience）</strong>。</p> <p><strong>真正AI的学习方式：</strong> 在他的设想中，真正的 AI 应该像所有动物一样，通过「<strong>感知-行动-奖励</strong>」的循环来学习。这个循环不断重复，构成了生命和智能的基础。智能体通过改变行动来增加奖励，这才是真正的学习。</p> <h3 id="22-模仿学习的根本问题">2.2 模仿学习的根本问题</h3> <p><strong>LLM 的错误路径：</strong> 而 LLM 走的是完全不同的路：它们学习的是「给定情境，人类会怎么做」。</p> <p><strong>缺乏真相标准：</strong> 这种模仿学习有个根本问题：<strong>没有真相（ground truth）</strong>。</p> <ul> <li> <strong>强化学习</strong>：可以通过实际结果来验证预测是否正确</li> <li> <strong>LLM 学习</strong>：没有「正确答案」的定义，只有「人类通常会说什么」</li> </ul> <h3 id="23-对人类学习方式的重新思考">2.3 对人类学习方式的重新思考</h3> <p><strong>质疑模仿学习假设：</strong> Sutton 甚至质疑了「人类通过模仿学习」这个普遍观点。</p> <p><strong>婴儿学习的真相：</strong></p> <blockquote> <p>他认为，婴儿挥舞双手、转动眼睛，这些动作没有人教，也没有模仿的对象。即使是语言学习，孩子也是在尝试发音、观察结果，而不是单纯地复制大人的话。</p> </blockquote> <h2 id="三llm-不符合苦涩教训">三、LLM 不符合「苦涩教训」</h2> <h3 id="31-讽刺的历史转折">3.1 讽刺的历史转折</h3> <p><strong>意外的反转：</strong> 这里的讽刺意味十足。Sutton 在 2019 年写下的「苦涩教训」成了 AI 界最有影响力的文章之一，许多人用它来为 LLM 的大规模扩展辩护。</p> <p><strong>作者的不同观点：</strong> 但 Sutton 本人却认为：<strong>LLM 恰恰违背了这个原则。</strong></p> <h3 id="32-苦涩教训的核心原理">3.2 苦涩教训的核心原理</h3> <p><strong>核心观点：</strong></p> <blockquote> <p>苦涩教训的核心是：依赖计算的通用方法最终会胜过依赖人类知识的方法。</p> </blockquote> <p><strong>LLM 的悖论：</strong> 但 LLM 呢？它们本质上是在利用海量的人类知识：整个互联网的文本。当这些数据耗尽后，它们就会被那些能从经验中学习的系统所超越。</p> <h3 id="33-历史规律的重现">3.3 历史规律的重现</h3> <p><strong>Sutton 的预言：</strong></p> <blockquote> <p>「这就像历史上每一次一样，」Sutton 说，「依赖人类知识的方法一开始看起来很好，但最终会被更通用、更可扩展的方法击败。」</p> </blockquote> <h2 id="四社区激烈交锋">四、社区激烈交锋</h2> <p>这场对话在 AI 社区引发了激烈讨论，各方观点针锋相对。</p> <h3 id="41-调和派观点">4.1 调和派观点</h3> <p><strong>Built2Think(@Built2T)</strong> 试图调和两种观点：</p> <blockquote> <p>自回归 LLM 和 RL 都处理序列或时间序列数据，这是一个基本认识——观察和行动都发生在时间中。LLM 提示设置了类似意图的心理状态，但它们的输出并没有以明显的方式用于满足目标。</p> </blockquote> <h3 id="42-质疑派声音">4.2 质疑派声音</h3> <p><strong>Jacob Beck(@jakeABeck)</strong> 分享了 Sutton 在 RL 会议上的演讲照片，并提出质疑：</p> <blockquote> <p>难道 LLM 不是已经在做所有这些事情了吗？</p> </blockquote> <p>他展示了 Sutton 关于持续学习挑战的观点：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>OaK requires reliable continual learning.
Can we do this yet? We have needed it for 40 years.
We can do it for one-layer (linear) networks.
But Conventional deep learning fails catastrophically.
    Catastrophic forgetting (French 199 and many others)
    Catastrophic loss of plasticity (Dohare et al 2024 and others)
Dohare's Continual Backprop is one of several recent solutions.
Meta-learning of new features may also help.
</code></pre></div></div> <h3 id="43-批评派反击">4.3 批评派反击</h3> <p><strong>Gary Marcus(@GaryMarcus)</strong> 表达不满：</p> <blockquote> <p>Sutton 对 LLM 的批评几乎与我多年来一直在争论的观点完全相同。令人失望的是，@dwarkesh_sp 你不让我展示我的观点。</p> </blockquote> <p><strong>Crucible(@LokiOfKnight)</strong> 最尖锐的批评：</p> <blockquote> <p>当他说人类不通过模仿学习时，我感到尴尬。他有一个有缺陷的观点，所以很难认真对待他说的任何话。</p> </blockquote> <p><strong>Kristoph(@ikristoph)</strong> 直接反驳：</p> <blockquote> <p>恕我直言，@RichardSSutton 的一些陈述是荒谬的。整个人类教育系统都基于模仿标准。你基本上不是因为学到了什么而被评分，而是因为你能否模仿「训练」。</p> </blockquote> <h3 id="44-实用派观点">4.4 实用派观点</h3> <p><strong>Tyler Moore(@TylerMo41608321)</strong> 认为不需要持续学习：</p> <blockquote> <p>增加上下文加上记忆基本上就能完成这项工作。</p> </blockquote> <p><strong>Nick Savage(@impossibilium)</strong> 提出有趣观察：</p> <blockquote> <p>我不太确定 LLM 没有目标这个论点。也许我们只是不理解它们是什么？对 ASI 来说，通过性追求快乐可能感觉毫无意义，就像下一个 token 预测对我们的感觉一样。</p> </blockquote> <blockquote> <p>从经验上看，监督学习显然会发生。如果我在晚饭前偷偷吃饼干，我保证我的儿子会通过模仿学习到这是可以接受的。</p> </blockquote> <h3 id="45-核心分歧的本质">4.5 核心分歧的本质</h3> <p>这场对话揭示了 AI 发展中的根本分歧：</p> <ul> <li><strong>继续沿着模仿人类的道路前进？</strong></li> <li><strong>还是转向真正的经验学习？</strong></li> </ul> <p><strong>Sutton 的答案很明确：只有后者才能通向真正的智能。</strong></p> <h2 id="五完整对话精华深度剖析智能的本质">五、完整对话精华：深度剖析智能的本质</h2> <h3 id="51-关于人类与动物的本质">5.1 关于人类与动物的本质</h3> <p><strong>Dwarkesh</strong>：我们试图复制智能，对吧？没有动物能登月或制造半导体，所以我们想了解是什么让人类特殊。</p> <p><strong>Sutton</strong>：</p> <blockquote> <p>为什么你要区分人类？人类就是动物。我们的共同点更有趣。我们应该少关注区分我们的东西。</p> </blockquote> <blockquote> <p>我喜欢你认为这是显而易见的方式。因为我认为相反的是显而易见的。我认为我们需要理解我们是如何成为动物的。如果我们理解了松鼠，我认为我们就几乎到达了那里。理解人类智能。语言部分只是表面的一小层装饰。</p> </blockquote> <h3 id="52-关于强化学习与大语言模型的本质差异">5.2 关于强化学习与大语言模型的本质差异</h3> <p><strong>Dwarkesh</strong>：从概念上讲，从 RL 的角度思考 AI，我们缺少了什么？</p> <p><strong>Sutton</strong>：</p> <blockquote> <p>强化学习是基础 AI，什么是智能或问题是理解你的世界。强化学习是关于理解你的世界，而大语言模型是关于模仿人们，做人们说你应该做的事，它们不是关于弄清楚该做什么。</p> </blockquote> <p><strong>Dwarkesh</strong>：要模拟互联网文本语料库中的万亿个 token，你必须建立一个世界模型。事实上，这些模型似乎确实有非常强大的世界模型。</p> <p><strong>Sutton</strong>：</p> <blockquote> <p>我不同意你刚才说的大部分内容。仅仅模仿人们说的话根本不是建立世界模型。世界模型能让你预测会发生什么。它们有能力预测一个人会说什么。它们没有能力预测会发生什么。</p> </blockquote> <blockquote> <p>我们想要的，引用 Alan Turing 的话，我们想要的是一台能从经验中学习的机器。经验是你生活中实际发生的事情。你做事，你看到会发生什么。这就是你学习的东西。</p> </blockquote> <h3 id="53-关于目标与智能的本质">5.3 关于目标与智能的本质</h3> <p><strong>Dwarkesh</strong>：但这不就是下一个 token 预测吗？预测下一个是什么，然后根据惊讶进行更新？</p> <p><strong>Sutton</strong>：</p> <blockquote> <p>下一个 token 是它们应该说什么。这个动作应该是什么。这不是世界会给它们什么作为它们所做的回应。</p> </blockquote> <blockquote> <p>让我们回到它们缺乏目标。对我来说，拥有目标是智能的本质。如果某物能实现目标，它就是智能的。我喜欢 John McCarthy 的定义，智能是实现目标能力的计算部分。所以你必须有目标。否则你只是一个行为系统。</p> </blockquote> <p><strong>Dwarkesh</strong>：我认为它们有目标——下一个 token 预测。</p> <p><strong>Sutton</strong>：</p> <blockquote> <p>那不是目标。它不会改变世界。Token 向你袭来。如果你预测它们，你不会影响它们。这不是关于外部世界的目标。这不是实质性目标。你不能看着一个系统说，哦，它有目标，如果它只是坐在那里预测并对自己准确预测感到满意。</p> </blockquote> <h3 id="54-关于苦涩教训的讨论">5.4 关于苦涩教训的讨论</h3> <p><strong>Dwarkesh</strong>：你在 2019 年写了题为《苦涩教训》的文章。这可能是 AI 历史上最有影响力的文章，但人们用它作为扩展 LLM 的理由。所以有趣的是，你的观点是 LLM 实际上不符合苦涩教训。</p> <p><strong>Sutton</strong>：</p> <blockquote> <p>大语言模型是否是苦涩教训的案例是一个有趣的问题。因为它们显然是使用大规模计算的一种方式。可扩展到互联网的极限。但它们也是投入大量人类知识的一种方式。</p> </blockquote> <blockquote> <p>在苦涩教训的每个案例中，你都可以从人类知识开始。然后做可扩展的事情。这总是可能的。但实际上，它总是被证明是糟糕的。因为人们被锁定在人类知识方法中。</p> </blockquote> <h3 id="55-关于未来ai发展方向的思考">5.5 关于未来AI发展方向的思考</h3> <p><strong>Dwarkesh</strong>：给我一个可扩展方法的感觉。</p> <p><strong>Sutton</strong>：</p> <blockquote> <p>可扩展的方法是你从经验中学习。你尝试事物。你看到什么有效。没有人必须告诉你，首先，你有一个目标。所以没有目标，就没有对错或更好更坏的感觉。</p> </blockquote> <blockquote> <p>大语言模型试图在没有目标或更好或更坏的感觉的情况下过关。这就是从错误的地方开始。</p> </blockquote> <hr> <h2 id="六核心观点总结">六、核心观点总结</h2> <h3 id="61-sutton-的智能理论框架">6.1 Sutton 的智能理论框架</h3> <pre><code class="language-mermaid">graph TD
    A[真正的智能] --&gt; B[明确的目标]
    A --&gt; C[持续学习能力]
    A --&gt; D[世界模型预测]

    B --&gt; B1[改变外部世界]
    B --&gt; B2[实质性影响]

    C --&gt; C1[从经验中学习]
    C --&gt; C2[感知-行动-奖励循环]

    D --&gt; D1[预测世界变化]
    D --&gt; D2[而非预测人类行为]

    E[LLM的问题] --&gt; F[缺乏真正目标]
    E --&gt; G[无持续学习]
    E --&gt; H[只模仿人类]

    F --&gt; F1[下一个token预测]
    F --&gt; F2[不改变世界]

    G --&gt; G1[训练后冻结]
    G --&gt; G2[无法适应新情况]

    H --&gt; H1[预测人类会说什么]
    H --&gt; H2[没有真相标准]

    style A fill:#4CAF50
    style E fill:#F44336
</code></pre> <h3 id="62-体验时代-vs-模仿时代">6.2 体验时代 vs 模仿时代</h3> <table> <thead> <tr> <th>维度</th> <th>体验时代（Sutton推崇）</th> <th>模仿时代（LLM现状）</th> </tr> </thead> <tbody> <tr> <td><strong>学习方式</strong></td> <td>感知-行动-奖励循环</td> <td>预测人类文本</td> </tr> <tr> <td><strong>目标性质</strong></td> <td>改变外部世界的实质目标</td> <td>预测下一个token</td> </tr> <tr> <td><strong>验证标准</strong></td> <td>实际结果反馈</td> <td>无客观真相标准</td> </tr> <tr> <td><strong>持续性</strong></td> <td>持续从经验学习</td> <td>训练后冻结</td> </tr> <tr> <td><strong>泛化能力</strong></td> <td>跨环境泛化</td> <td>局限于训练分布</td> </tr> </tbody> </table> <h3 id="63-对苦涩教训的重新解读">6.3 对”苦涩教训”的重新解读</h3> <p><strong>传统理解</strong>：大规模计算胜过人工设计 <strong>Sutton的观点</strong>：LLM违背了苦涩教训，因为它们本质上依赖海量人类知识</p> <p><strong>历史规律</strong>：</p> <ol> <li>依赖人类知识的方法初期表现良好</li> <li>但最终被通用、可扩展的方法超越</li> <li>LLM将被真正从经验学习的系统替代</li> </ol> <h2 id="七深度思考与启示">七、深度思考与启示</h2> <h3 id="71-对ai发展路径的反思">7.1 对AI发展路径的反思</h3> <p>Sutton的观点提醒我们思考几个根本问题：</p> <ol> <li> <p><strong>什么是真正的智能？</strong> 是模仿人类行为，还是具备独立的目标和学习能力？</p> </li> <li> <p><strong>AI的发展方向是否正确？</strong> 当前的LLM路径是否会遇到根本性瓶颈？</p> </li> <li> <p><strong>如何实现真正的通用智能？</strong> 需要什么样的架构和训练范式？</p> </li> </ol> <h3 id="72-对研究者和从业者的启示">7.2 对研究者和从业者的启示</h3> <p><strong>对研究方向的思考</strong>：</p> <ul> <li>重新审视强化学习在AGI中的核心地位</li> <li>探索真正的持续学习机制</li> <li>设计具备实质性目标的AI系统</li> </ul> <p><strong>对产业发展的警示</strong>：</p> <ul> <li>LLM可能不是通向AGI的最终路径</li> <li>需要为范式转换做好准备</li> <li>投资真正的经验学习系统研究</li> </ul> <h2 id="结语">结语</h2> <p>Richard Sutton作为强化学习的奠基者，他对LLM的批评不是简单的技术路线之争，而是对智能本质的深度思考。他提醒我们：</p> <blockquote> <p><strong>真正的智能不是模仿，而是理解；不是预测人类会说什么，而是预测世界会发生什么；不是被动接受训练，而是主动从经验中学习。</strong></p> </blockquote> <p>无论我们是否完全认同Sutton的观点，这场讨论都为AI的未来发展提供了重要的思考维度。在LLM大行其道的今天，保持对不同技术路径的开放态度，或许正是推动AI真正进步的关键所在。</p> <hr> <p><em>本文整理自Dwarkesh Patel与Richard Sutton的播客对话，旨在为中文读者提供这位图灵奖得主对当前AI发展的深度思考。</em></p> </div> </article> </div> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Chao Yang. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="/assets/js/bootstrap-toc.min.js?c82ff4de8b0955d6ff14f5b05eed7eb6"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-\u4e2d\u6587\u7b80\u4ecb",title:"\u4e2d\u6587\u7b80\u4ecb",description:"",section:"Navigation",handler:()=>{window.location.href="/chinese/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-publications",title:"publications",description:"publications by categories in reversed chronological order. generated by jekyll-scholar.",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-projects",title:"projects",description:"A growing collection of your cool projects.",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"nav-cv",title:"cv",description:"",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"nav-repositories",title:"repositories",description:"Edit the `_data/repositories.yml` and change the `github_users` and `github_repos` lists to include your own GitHub profile and repositories.",section:"Navigation",handler:()=>{window.location.href="/repositories/"}},{id:"nav-teaching",title:"teaching",description:"Materials for courses you taught. Replace this text with your description.",section:"Navigation",handler:()=>{window.location.href="/teaching/"}},{id:"dropdown-publications",title:"publications",description:"",section:"Dropdown",handler:()=>{window.location.href=""}},{id:"dropdown-projects",title:"projects",description:"",section:"Dropdown",handler:()=>{window.location.href=""}},{id:"dropdown-blog",title:"blog",description:"",section:"Dropdown",handler:()=>{window.location.href="/blog/"}},{id:"news-one-offline-rl-paper-accepted-by-aaai-2024-sparkles-sparkles",title:'One Offline RL Paper accepted by AAAI 2024. <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"><img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20">',description:"",section:"News"},{id:"news-two-papers-llama-excitor-videodistill-are-accepted-by-cvpr-2024-sparkles-sparkles",title:'Two Papers(LLaMA-Excitor, VideoDistill) are accepted by CVPR 2024. <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"><img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20">',description:"",section:"News"},{id:"news-one-llm-safety-survey-paper-accepted-by-naacl-2024-sparkles-smile",title:'One LLM safety survey paper accepted by NAACL 2024. <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> <img class="emoji" title=":smile:" alt=":smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" height="20" width="20">',description:"",section:"News"},{id:"news-one-paper-accepted-by-ijcai-2024-survey-track-sparkles-sparkles",title:'One Paper accepted by IJCAI 2024 Survey Track. <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"><img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20">',description:"",section:"News"},{id:"news-robocodex-is-accepted-by-icml-2024-sparkles-sparkles",title:'RoboCodeX is accepted by ICML 2024. <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"><img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20">',description:"",section:"News"},{id:"news-three-papers-emulated-disalignment-structured-reasoning-multi-objective-dpo-are-accepted-by-acl-2024-sparkles-sparkles",title:'Three Papers (Emulated Disalignment, Structured Reasoning, Multi-Objective DPO) are accepted by ACL 2024.<img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"><img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20">...',description:"",section:"News"},{id:"news-mm-safetybench-a-benchmark-for-safety-evaluation-of-multimodal-large-language-models-is-accepted-by-eccv-2024-project-page-sparkles-sparkles",title:"MM-SafetyBench (A Benchmark for Safety Evaluation of Multimodal Large Language Models) is accepted...",description:"",section:"News"},{id:"news-inference-time-language-model-alignment-via-integrated-value-guidance-is-accepted-by-emnlp-2024-arixv-link-sparkles-sparkles",title:"Inference-Time Language Model Alignment via Integrated Value Guidance is accepted by EMNLP 2024....",description:"",section:"News"},{id:"news-weak-to-strong-search-align-large-language-models-via-searching-over-small-language-models-is-accepted-by-neurips-2024-neurips-link-sparkles-sparkles",title:"Weak-to-Strong Search: Align Large Language Models via Searching over Small Language Models is...",description:"",section:"News"},{id:"news-we-proposal-a-new-law-ai-45-law-toward-trustworthy-agi-arxiv-link-sparkles",title:'We proposal a new law, AI 45\xb0-Law toward trustworthy AGI! Arxiv Link <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20">...',description:"",section:"News"},{id:"news-icml2025-emergent-response-planning-in-llm-and-c-3po-compact-plug-and-play-proxy-optimization-to-achieve-human-like-retrieval-augmented-generation-are-accepted-by-icml2025-sparkles",title:"[ICML2025] Emergent Response Planning in LLM and C-3PO: Compact Plug-and-Play Proxy Optimization to...",description:"",section:"News"},{id:"news-our-paper-adversarial-preference-learning-for-robust-llm-alignment-is-accepted-by-acl2025-arxiv-link-sparkles",title:"Our paper Adversarial Preference Learning for Robust LLM Alignment is accepted by ACL2025....",description:"",section:"News"},{id:"news-we-find-patches-from-harmful-content-enabling-them-to-bypass-data-moderation-and-generate-dangerous-responses-when-encountering-the-full-image-or-related-text-vlms-can-aggregate-scattered-training-patchesk-sparkles",title:"We find patches from harmful content, enabling them to bypass data moderation and...",description:"",section:"News"},{id:"news-big-project-release-we-introduce-safework-r1-a-cutting-edge-multimodal-reasoning-model-that-demonstrates-the-coevolution-of-capabilities-and-safety-safework-r1-rocket-sparkles",title:"\ud83c\udf89 Big Project Release! We introduce SafeWork-R1, a cutting-edge multimodal reasoning model that...",description:"",section:"News"},{id:"projects-project-1",title:"project 1",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%79%61%6E%67%63%68%61%6F [%41%54] %70%6A%6C%61%62 [%44%4F%54] %6F%72%67 [%44%4F%54] %63%6E","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=https://scholar.google.com/citations?hl=en&user=5KRbHPMAAAAJ&view_op=list_works&sortby=pubdate","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/emigmo","_blank")}},{id:"socials-dblp",title:"DBLP",section:"Socials",handler:()=>{window.open("https://dblp.org/pid/00/5867-26.html","_blank")}},{id:"socials-youtube",title:"YouTube",section:"Socials",handler:()=>{window.open("https://youtube.com/@chaoyang4587","_blank")}},{id:"socials-rss",title:"RSS Feed",section:"Socials",handler:()=>{window.open("/feed.xml","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>