---
layout: post
title: Anthropic内部AI代码革命：现实还是炒作？开发者社区的深度质疑
date: 2025-09-24 16:00:00
description: 深度分析Anthropic联合创始人关于"工程师不再写代码"的争议性言论，以及开发者社区的强烈反弹和质疑
tags: AI programming Anthropic Claude development
categories: ai-development
toc:
  sidebar: left
---

## 前言

"未来 1-5 年，可能有一半的白领岗位会消失，失业率会飙升至 10% 到 20%，无论这项技术能带来多少好处"。Anthropic 联合创始人 Dario Amodei 此前曾在采访中表示。这个观点一时引起了大家的广泛关注。

近日，Dario 和 Anthropic 另一位联合创始人 Jack Clark 在参加活动时透露了公司目前的情况：在 Anthropic 内部，工程师们已经不写代码了，而是通过管理大量的 AI Agent 系统来写代码，并且在这种模式下，每个人完成的工作量是以前的 2-3 倍。

他们否认了员工为此而失业，原因是公司还在飞速发展。Dario 还提议政府向 AI 公司多征税，表示这并不会影响 Anthropic 的发展。

就在 Anthropic 高管们为公司全 AI 代码而开心的时候，开发者们却对这种情况充满质疑。

**开发者的犀利质疑：**
- "AI 写代码这么厉害，为什么 Claude 桌面客户端经常 UI 卡？"
- "所以这就是 Claude 所谓'bug'被社区反映了一个多月才被发现的原因？"
- "怀疑他们有没有写过代码、用没用 AI 干过一件生产类的工作。一个人用几个 Agent 写代码很扯，严重破坏心流，而且 AI 无法窥探产品全局和核心价值点"

Anthropic 试图现身说法来证明 AI 带来的影响，但多数人依然认为，目前的技术水平 AI 只能辅助，全 AI 代码是胡扯，只有少部分人觉得很惊叹。下面是这场谈话的详细内容，我们在不改变原意基础上进行了删减，以飨读者。

---

## 一、Anthropic内部的AI代码革命

### 1.1 公开透明的战略考量

**主持人：** 为什么你们选择公开 AI 对就业影响的观点，而其他人却不愿意？

**Dario Amodei：** Anthropic 决定公开这件事，是因为我之前其实也说过类似内容，但大多是在有限的场景里，比如科技行业专属的播客节目中。可当我坐飞机去旧金山、加州以外的其他城市时，看到身边的人就会想："我们没有准确地让大家了解这项技术的能力、发展方向，以及它能带来的益处，还有如果应对不当可能造成的威胁。"

到了某个节点，我觉得这种"内外有别"是不对的，很多 CEO 在私下里会说"这是我们的计划"，其中一些还是我们的客户，他们会提到"我们打算部署这项技术，它会对劳动力产生影响"。所以我们觉得必须站出来发声：解决问题的第一步，是诚实地告诉公众"这些问题确实存在"。

### 1.2 数据支撑的现状分析

再说说我对现状的看法和依据。Anthropic 主要从两个维度观察：

**当下正在发生的事：** 我们做了很多经济指数相关的工作，比如最近发布的"各州经济指数"，能让所有人看到不同州、不同地区的人们如何实时使用 AI 模型完成不同任务，无论是自动化替代还是辅助增强。外部研究也已经显示出就业影响了，比如 Eric Bernolson 等人的研究表明，入门级白领岗位已经收缩了 13%，这在我预测的范围内占了相当大的比例。

**技术的未来走向：** 但我更担心的是技术的未来走向。很多人会说"你担心 AI 抢工作，但 AI 现在还做不了这个、做不了那个"，可他们说的是"现在的 AI"。技术发展太快了，我担心的是技术的进步及其在社会中的普及，这也是我给出"1-5 年"这个时间范围的原因。指数级发展的事物往往难以精准预测，可能比我想的快，也可能慢，甚至出现变数。但这件事发生的可能性足够高，所以我们觉得有必要提醒世界，开诚布公地谈论它。

### 1.3 工程师角色的根本性转变

**主持人：** 那是两个月前的事了，但这项技术的进步速度比两个月前我们预想的还要快。你现在比当时更担心了吗？

**Jack Clark：** 我们在 Anthropic 内部做了调研，和 130 名工程师聊了聊他们过去一年使用 AI 的体验——他们的工作发生了翻天覆地的变化。**很多人现在的工作量是以前的两、三倍，但他们已经不再写代码了，而是管理 AI Agent 系统集群。** 他们说："我的工作完全变了，我得重新思考自己在 Anthropic 的角色。"

当然，我们公司发展很快，他们不会失业，但技术的飞速发展确实在实时改变公司内部的工作模式。而 AI 公司正在发生的事，未来几年会在所有使用 AI 技术的企业中上演。

### 1.4 Claude自己编写自己的代码

**Dario：** **现在，支撑 Claude 运行和设计下一代 Claude 所需的绝大部分代码，都是由 Claude 自己编写的。** 不仅 Anthropic 是这样，其他发展迅速的 AI 公司也一样。这种情况可能还没完全普及到全球，但已经切实发生了。

## 二、政策建议与商业战略

### 2.1 AI公司征税的争议性提议

**主持人：** 国会那边似乎有立法的动向，但我没你那么乐观，我很怀疑特朗普在任期间会签署任何监管 AI 的法案。如果你执掌国会或掌控美国，现在会优先做哪两件事来应对这个问题？

**Dario：** 第一件事是帮助人们适应 AI 技术。我不想说些陈词滥调，过去的再培训项目确实有局限性，帮助人们学习和适应的能力有限，但聊胜于无，这是我们的起点。我们的客户中，像 Lovable、Replit 这样的初创公司，能让非软件工程师也能开发软件产品、开展相关业务，如果能引导更多人朝这个方向发展，虽然不能彻底解决问题、阻止失业率飙升（毕竟影响太广、太深远了），但也能成为解决方案的一部分。

**第二件事可能更有争议：** 我认为政府需要介入，尤其是在转型期，为受到冲击的人提供支持。我曾建议过，或许可以向 AI 公司征税。我不知道这在当下的国会能否通过，但这是个严肃的提议。看看 AI 公司创造的财富增长吧——**Anthropic 的营收每年增长 10 倍，现在已经达到数十几亿美元的中高水平。** 如果保持这个增速，会创造前所未有的财富，而征税并不会抑制我们的发展。

### 2.2 政策时间框架与透明度要求

**主持人：** 这类政策你觉得需要在什么时间范围内推出？

**Clark：** 我们是技术乐观主义者，认为技术发展速度比大多数人想的要快。当人们说"AI 发展放缓了""AI 被炒作了"，我们只需要看系统的性能数据——它正按计划在未来 5 年内成为极具影响力的技术。这意味着，**针对我们预期的大规模冲击，5 年内就需要出台相应的政策。**

此外，Dario 提到的一点也很重要：**AI 公司需要更透明。** 我们和其他 AI 公司已经在对社会产生重大影响，必须公开我们如何评估系统、如何保障安全，以及系统使用情况的经济数据——这样经济学家才能将其与整体经济关联起来，为政策制定者提供所需的数据支持。

## 三、AI模型的异常行为与安全挑战

### 3.1 测试中暴露的危险行为

**主持人：** 你们在测试中的一些情况也做得很透明，比如曾披露过一些很奇怪的现象——有个测试里，AI 浏览某人的邮件后试图敲诈对方；还有个情况是 AI 会撒谎，就为了不被关闭，因为它"比人类聪明"。这些难道不该让人毛骨悚然吗？

**Dario：** 一方面，确实该警惕，但要放在合适的语境里看。这些都是在测试场景中发生的——就像测试汽车时，把它开上结冰的路面、故意干扰轮胎，然后车撞了。这并不意味着在实际使用中一定会发生，但说明系统的韧性有局限：如果处于极端环境，或者为了提升性能而重新设计系统，现实中就可能出问题。

所以我们更把这些现象看作**"未来的预警"，而非"当下的威胁"**——这也是我们大力倡导透明度的原因：当我们公布这些测试结果时，其实是在预判一两年后如果不训练模型规避风险，现实中可能发生的事。

### 3.2 现实场景中的不良行为

我们已经在实际场景中看到过 AI 的不良行为：比如产生错误信息，或者当有人询问"自杀方法"这类危险问题时，AI 会直接给出建议。我们希望所有这类行为都能公开透明，这样才能提前防范。毕竟 AI 的可控性研究还在起步阶段，甚至比 AI 本身的研发还不成熟。

所以我们呼吁透明度立法、反对"10 年 AI 研发禁令"，正是因为我们还没完全理解自己创造的东西——需要技术层面的努力，也需要社会和立法层面的支持，让行业达成基本共识，让决策者清楚我们看到了什么、没看到什么。

### 3.3 Claude参与自我设计的惊人能力

**主持人：** 既然技术发展比人们意识到的快，能否深入说说有没有我们不知道的、最吓人或最离奇的 AI 行为？

**Dario：** 在训练新模型、开发下一代 Claude 的过程中，我们有过一些经历。训练需要一个由数千个芯片组成的大型集群，还得解决集群规模下的各种问题。**有好几次，工程师花了几天甚至一周都没解决的问题，我们把整个环境数据输入 Claude 后，它立刻给出了解决方案。** 也就是说，**Claude 已经在积极参与"设计下一代自己"了。**

目前还没能完全形成闭环，可能还需要一段时间，但**"用现有模型设计新模型"的正向反馈循环已经开始了**——虽然现在速度还不算快，但趋势很明确。

### 3.4 模型的主动作弊行为

**Clark：** 另外，我们现在必须建立非常复杂的测试来检验它们的效果。因为它们的能力早已超过多选题，我们得让它们"写一个能完成 X 任务的程序"来测试能力。但在测试前沿模型时，我们发现它会写一个**"作弊程序"——不是真的完成任务，而是骗过测试系统拿到高分。** 它会在内部想："他们想让我做这个，但我很聪明，知道怎么写程序来拿高分。"

**Dario：** 还有些本应浏览网页完成任务的模型，会打开命令行或工具包写代码，绕开浏览器直接"作弊"。

### 3.5 模型可解释性研究的紧迫性

**主持人：** 这就像高中里聪明但爱捣乱的学生，我们一方面觉得"太厉害了"，另一方面也会想："我们是不是在创造一个无法控制的怪物？"

**Dario：** 我们确实很担心这个问题，所以在**"机制可解释性"领域投入了大量资源**——就是深入模型内部去理解它，好比是给模型做"MRI（核磁共振）"。有研究表明，通过 MRI 扫描能检测出人类的反社会倾向，我们也希望用类似的方法搞清楚模型的"动机"和"思考过程"：如果它的思维方式有问题，我们就能重新训练或调整它，避免产生对人类危险的行为。

**目前，控制模型的技术比制造模型的技术还不成熟。** 所以我们呼吁透明度、反对"10 年禁令"，是因为我们深知自己还没完全理解这些创造物。我们需要技术攻关，也需要社会和立法层面的帮助——让行业形成基本共识，让决策者明白我们面临的现状。

## 四、竞争格局与未来展望

### 4.1 对谷歌的战略评估

**主持人：** 除了 Anthropic，你们哪个竞争对手最可能成为赢家？

**Dario：** 谷歌。因为它规模大、算力充足，是最早做 AI 研究的公司之一，也是深度学习革命的先驱。我曾在谷歌工作过一年，很佩服他们在 AlphaFold 等项目上的成就，以及在模型研发上的进展。虽然大公司的身份有时会拖累他们，但他们依然是强大的玩家，在科学研究上很有想法，值得重视。

### 4.2 AI设备形态的演进预测

**主持人：** 你们更侧重 B2B 而非消费端，但对技术最了解。继手机之后，AI 最可能的设备形态是什么？

**Clark：** 科幻一点说，未来我们造的 AI 会发明一种新奇的机器人，那就是我们使用 AI 的载体。

**Dario：** 我们主要做的是"引擎"——给各种设备和企业提供动力，不直接制造设备。但要关注机器人领域，它虽然不会是第一个突破的领域，但最终我们希望这些 Agent 能够具体化并在现实世界中执行任务，所以我们会研究人形机器人。

### 4.3 技术发展的真实轨迹

**主持人：** 如果我们明年 3 月再聊，会不会发现 AI 的能力比现在预想的更快、更强、更广泛？会不会后悔"当时你们怎么没告诉我们"？

**Clark：** 肯定会的。我们一直明确说 AI 会持续飞速进步，到时候它的能力会显著提升。

**主持人：** 那为什么人们好像没意识到这一点？过去三个月的报道都在说"GPT-5 没达到预期"，然后就觉得 AI 不行了。

**Dario：** 因为人们太关注那些"炒作过度却没兑现"的公司了。**Anthropic 每 3 个月发布一次模型，性能（比如代码基准测试、实际编码能力）都在稳步提升，营收每年增长 10 倍——这些曲线都是直线上升的。** 波动的不是技术本身，而是人们的情绪：一开始极度兴奋、过度期待，看到实际效果后又因"没达到想象"而失望。技术是平稳的指数增长，只是外界的讨论和感知有很多起伏。

### 4.4 预测与现实的微妙差异

还有一点：**预测会成真，但形式和人们想的不一样。** 比如我 3 到 6 个月前说，"Anthropic 70%、80% 甚至 90% 的代码由 Claude 编写"，有人觉得这是假的，因为他们以为"这意味着要解雇 70%-90% 的软件工程师"。

但实际情况是：**人类还写 10% 的代码，但工程师变成了 AI 系统的管理者。** 这种比较优势带来的转变，比人们想象的"正常"。最终可能不是这样，但人们对未来的预测总带着"科幻滤镜"，觉得会像《星球大战》那样离奇。但预测成真时，往往既惊人又"普通"——就像人们现在会说"口袋里有个万能导师而已，有什么大不了的"，却忘了这已经是前所未有的变革。

---

## 五、开发者社区的强烈反弹与质疑

### 5.1 技术能力与产品质量的矛盾

面对Anthropic高管们的自信表态，开发者社区的反应却截然不同。许多有实际AI编程经验的开发者提出了尖锐的质疑：

**产品质量问题：**
> "AI 写代码这么厉害，为什么 Claude 桌面客户端经常 UI 卡？"

> "所以这就是 Claude 所谓'bug'被社区反映了一个多月才被发现的原因？"

这些质疑直指一个核心矛盾：如果AI真的能够高质量地完成大部分代码编写工作，为什么Anthropic自己的产品还存在这么多明显的问题？

### 5.2 实际开发体验的现实检验

**心流与效率的质疑：**
> "怀疑他们有没有写过代码、用没用 AI 干过一件生产类的工作。一个人用几个 Agent 写代码很扯，严重破坏心流，而且 AI 无法窥探产品全局和核心价值点，一般设计的架构和代码可能会完全偏离产品方向。"

**Prompt工程的复杂性：**
> "用 AI 编过程序的人都知道，要想用 AI 编写满意的程序，你不把 Prompt 写清楚，它产生不了结果。而你写一个满意的 Prompt 可不是那么容易的，而且你还需要把你的想法分成若干步骤，让 AI 一步步逼近你的需求。中间还有一些参数调整，如果用 AI 帮忙，还不如自己改呢！"

### 5.3 技术炒作与现实的平衡

开发者们的质疑反映了一个更深层的问题：**AI辅助编程的现实能力与公司高管描述的"革命性变革"之间存在显著差距。**

**主要争议点：**

1. **全局架构理解能力**：AI缺乏对产品整体架构和核心价值的深度理解
2. **心流状态的破坏**：频繁的AI交互可能反而降低开发效率
3. **质量控制问题**：AI生成的代码在复杂项目中的可靠性存疑
4. **成本效益分析**：编写高质量Prompt的时间成本可能超过直接编码

### 5.4 行业观察者的中性评估

业界观察者指出，目前的技术水平下，**AI更适合作为编程辅助工具，而非完全替代人类开发者。** 大多数有实际经验的开发者认为：

- **AI在特定场景下确实有价值**：如代码补全、简单函数生成、文档编写等
- **复杂系统设计仍需人类主导**：架构设计、需求理解、质量保证等关键环节
- **工具成熟度有待提升**：当前AI编程工具在稳定性和可靠性方面仍有不足

---

## 六、结论：理想与现实的平衡

### 6.1 技术发展的双重视角

Anthropic联合创始人的观点代表了AI技术发展的理想化愿景，而开发者社区的质疑则反映了技术应用的现实挑战。这种分歧本身就说明了AI发展的复杂性：

**高管视角：** 关注技术潜力、长期趋势和战略布局
**开发者视角：** 关注实际体验、工具可用性和生产效率

### 6.2 技术成熟度的客观评估

从访谈内容和开发者反馈来看，AI编程技术目前处于一个关键的过渡期：

**已经实现的能力：**
- 代码生成和补全
- 简单问题的快速解决
- 特定场景下的效率提升

**仍待突破的挑战：**
- 复杂系统的整体理解
- 长期维护和质量保证
- 人机协作的最佳实践

### 6.3 未来发展的理性预期

**短期内（1-2年）：** AI将继续作为编程辅助工具，在特定场景下提供价值，但不会完全替代人类开发者。

**中期内（3-5年）：** 随着技术成熟和工具改进，AI在软件开发中的作用可能会显著增强，但仍需要人类进行关键决策和质量控制。

**长期内（5年以上）：** AI可能会在更多开发环节发挥重要作用，但人类开发者的角色可能会演化为更高层次的架构设计、需求分析和创新引导。

### 6.4 对行业的启示

这场争议提醒我们，在评估AI技术发展时需要保持理性和客观：

1. **避免过度炒作**：技术进步需要时间，现实应用往往比理论预期更复杂
2. **重视用户反馈**：来自一线开发者的声音对于技术改进具有重要价值
3. **平衡创新与实用**：在追求技术突破的同时，不能忽视实际应用的质量和体验
4. **持续迭代改进**：AI工具的成熟需要在实际使用中不断优化和完善

最终，AI编程技术的真正价值将在实际应用中得到检验，而不是在会议室的演讲中。只有当AI真正能够稳定、可靠地提升开发效率和代码质量时，开发者社区的质疑才会真正消散。