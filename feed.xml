<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://emigmo.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://emigmo.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-11-11T03:57:55+00:00</updated><id>https://emigmo.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html"></title><link href="https://emigmo.github.io/blog/2025/2025-01-15-xiaohanding-paper-suggestion/" rel="alternate" type="text/html" title=""/><published>2025-11-11T03:57:55+00:00</published><updated>2025-11-11T03:57:55+00:00</updated><id>https://emigmo.github.io/blog/2025/2025-01-15-xiaohanding-paper-suggestion</id><content type="html" xml:base="https://emigmo.github.io/blog/2025/2025-01-15-xiaohanding-paper-suggestion/"><![CDATA[<h1 id="丁霄汉学术论文写作指导从hard-to-follow到高可读性">丁霄汉：学术论文写作指导–从”Hard to Follow”到高可读性</h1> <p><em>作者：丁霄汉</em><br/> <em>时间：2025年1月15日</em><br/> <em>来源：学术写作经验分享</em></p> <hr/> <h2 id="前言">前言</h2> <p>几年间我主笔或大改了20篇左右的顶会论文,一开始是在清华的实验室里苦思冥想,被拒了好几次才有点长进,基本不会因为写作被秒拒了;后来实习和工作时,在帮实习生和学弟改文章的过程中也发现了一些常见问题。我想总结一些给顶会论文写作新手的建议。如果能帮助同学们少走弯路的话,我将不胜荣幸。</p> <p>这几条建议将分成上下两篇,每篇聚焦于如何避免收到一条致命的”恶评”,分别是:</p> <ul> <li><strong>(上)This paper is hard to follow</strong>(宏观层面,谋篇布局,优化论文结构,卖出核心贡献)</li> <li><strong>(下)The readability can be greatly improved</strong>(微观层面,精耕细作,少犯常见的小错误)</li> </ul> <hr/> <h2 id="目录">目录</h2> <h3 id="第一部分宏观布局避免hard-to-follow">第一部分：宏观布局，避免”hard to follow”</h3> <ul> <li><a href="#审稿人视角">审稿人视角</a></li> <li><a href="#例子1不要完整还原研究的心路历程">例子1：不要完整还原研究的心路历程</a></li> <li><a href="#例子2不要轻言based-on和ab">例子2：不要轻言”based on”和”A+B”</a></li> <li><a href="#总结和其他建议">总结和其他建议</a></li> </ul> <h3 id="第二部分精耕细作提高readability">第二部分：精耕细作，提高”readability”</h3> <ul> <li><a href="#逻辑强度">逻辑强度</a></li> <li><a href="#防御弹性">防御弹性</a></li> <li><a href="#迷惑时间">迷惑时间</a></li> <li><a href="#信息密度">信息密度</a></li> </ul> <hr/> <h2 id="前言-1">前言</h2> <p>几年间我主笔或大改了20篇左右的顶会论文，一开始是在清华的实验室里苦思冥想，被拒了好几次才有点长进，基本不会因为写作被秒拒了；后来实习和工作时，在帮实习生和学弟改文章的过程中也发现了一些常见问题。我想总结一些给顶会论文写作新手的建议。如果能帮助同学们少走弯路的话，我将不胜荣幸。</p> <p>这几条建议将分成上下两篇，每篇聚焦于如何避免收到一条致命的”恶评”，分别是：</p> <ul> <li><strong>（上）This paper is hard to follow</strong>（宏观层面，谋篇布局，优化论文结构，卖出核心贡献）</li> <li><strong>（下）The readability can be greatly improved</strong>（微观层面，精耕细作，少犯常见的小错误）</li> </ul> <hr/> <h2 id="第一部分宏观布局避免hard-to-follow-1">第一部分：宏观布局，避免”hard to follow”</h2> <p>本篇先从”hard to follow”开始。缺乏经验的同学收到这样的恶评外加一个strong reject之后可能会感到迷惑和委屈，所以本文首先从审稿人的角度来分析他们为什么会对你的文章作出这样的评价，然后通过两个例子给出相应的写作建议。</p> <h3 id="审稿人视角">审稿人视角</h3> <p>这个评价可能表示论文的宏观组织形式和内容分布与审稿人所期望的有较大的差距，所以他在耐心耗尽前没能搞懂你做了什么。对同一篇文章，审稿人想的跟作者想的到底差在哪呢？ 一位同学可能会对自己刚完成的论文很满意，因为：</p> <ul> <li>A. 在对一个重要问题的研究过程中，我遇到了几个复杂的子问题，我一环扣一环地解决了这几个问题，最终得到了一个巧妙的解决方案。我记录了这个精彩的过程，审稿人应当为这一方案的系统性和自洽性折服。</li> <li>B. 我讨论的问题有点难以理解，但只要脑子里转过那个弯儿来，经过一系列挑战性十足的思想游戏，就可以把这个问题转化为另一个简单的问题，那么解决方案就自然呼之欲出了。我用两页纸的篇幅进行了这一思辨，逐步推出了最终的结论，审稿人肯定会受到灵魂的启迪。</li> <li>C. 我在别人的工作上加入了本质的创新，变成了全新的东西，最终的效果很好，如假包换的SOTA。审稿人只要能看懂实验结果，就应该给我accept。 那审稿人是怎么看的呢？ 审稿人根本就不在乎。 审稿人点开了你的文章，边看边想：</li> <li>A. 他到底要解决什么问题？怎么一个问题又一个问题？到底哪个是他要解决的？哪个方法是common practice，哪个是他提出来的？</li> <li>B. 这两页纸在写什么东西？前面没总起，后面没总结，中间又是假设又是推论的在干什么？这个结论是怎么回事，这不是很显然的吗？磨叽了两页纸，就这？</li> <li>C. 哦，这个懂了，yet another AAA + BBB，我跳过中间四页直接看看效果吧。这张表里面的这个指标是啥意思，就比别人高了0.2，这个差别很大吗？ 审稿人期望的是什么呢？</li> <li>审稿人想要的是迅速搞明白你提出了什么新东西，而不是听你娓娓道来、抽丝剥茧，跟着你一起由浅入深地感受那四方求索、最终豁然开朗的成就感。写论文的目的在于向读者介绍工作的最终形态，而不是记录研究过程。有的同学会在文章里描述自己从最初的idea艰难跋涉直到最终结果的心路历程，这多半是没用的。</li> <li>审稿人不会逐字逐句地看论文，他希望他直接跳到任何一页上之后都能在所有人都习惯的地方迅速找到他想要看到的内容。所以，如果你的论文组织形式不太常规，审稿人可能根本就懒得看。</li> <li>很多人是为了学到新东西才来审稿的。如果你把一些反直觉、有趣或很实用的结论摆在显眼的地方给他看，他可能会感到有收获。但不要期望每个审稿人都愿意从你的大段文字和意义不明的图表中自己经过思考得到这些结论。</li> </ul> <h3 id="例子1不要完整还原研究的心路历程">例子1：不要完整还原研究的心路历程</h3> <p>我为了解决一个重要的已知问题（问题甲）提出了方案A（跟其他人的方法相比变化很大），发现方案A不够好，研究一下为什么方案A不够好呢，发现这是因为方案A引入了另一个问题（问题乙）；我研究了一下如何解决问题乙，最终提出了改进版方案B（在A的基础上改动很小，加一个trick），所有问题都解决了。而且这个trick用在其他方法中也有提升。我提出了两个方案，还发现了一个别人没发现的问题，我觉得这篇文章很稳。 但审稿人是以不同的视角来看这篇文章的，他并没有亲身经历我的研究过程，不可能像我一样清楚重点在哪里。他可能会问：</p> <ul> <li>如何证明方案A不好使的本质原因是问题乙？</li> <li>方案A也有一定效果，如何证明这是因为解决了问题甲？</li> <li>方案B相对于方案A只有很小的差别，怎么就这么点novelty？</li> <li>你说B的改进用在其他方法上也有提升，那我为什么还需要A？A不也没比其他方法好到哪去吗？ 我觉得很冤：这篇文章的最终结果明明是方案B，B是A的巧妙升级版，差别当然很小了，但是A也是我提出的呀！还有，为什么要纠结A和问题甲的关系，这很重要吗？ 如果审稿人能听到我的抱怨，他会说：</li> <li>你全篇都在鼓吹方案B，你没有强调A，我怎么知道它也是这篇文章主要内容的一部分？</li> <li>就算A是你提出的，它也没有解决你强调的问题乙啊，难道它也算主要贡献？</li> <li>既然A不算主要贡献，那你所强调的B可不就是只有很小的改动吗？ 辩经是没有意义的，我们只能在写作时注意避免引发这种无意义的争论。如果我们稍微改变一下写作的方式，审稿人就更容易看懂了：</li> <li>我提出了一个全新的方法来解决一个重要问题。</li> <li>这个全新的方法包括一个全新的框架和一个通用的trick。</li> <li>分别证明二者的有效性：用这一框架而不用这个trick会导致效果相对变差；这是因为另一个有趣的问题（做一些分析）；这个trick用在其他方法里，也可以有一定的提升；二者结合，效果才是最好的。 为什么审稿人喜欢这样的组织形式呢？因为他一眼就看出你提出了什么东西，以及它们各自有什么作用。他只需要判断你提出的东西技术上是否正确和效果是否显著就可以了。</li> </ul> <h3 id="例子2不要轻言based-on和ab">例子2：不要轻言”based on”和”A+B”</h3> <p>“提出了基于AAA和BBB的XXX”是本科毕业论文里常用的说法，适用于需要稳妥安全而不怎么需要创新性的场合。在顶会论文里这么写，可能会把本来还不错的创新性给写没了。在大多数情况下，不要轻言自己的工作“based on”，你完全可以说自己注意到了某个重要问题，琢磨明白了背后的原理，想到了一个解决方案，提出的是一种新的东西，这种东西自然地用到了AAA和BBB，而不是简单地改了改人家的成果。 设想一下，把ResNet的写作改成“based on”和“A+B”的形式，是不是就把创新性写没了？ 《ResNet: Yet Another Simplified GoogLeNet》 ：我们基于GoogLeNet和VGGNet设计了一种大量用3x3卷积（借鉴VGGNet）和并行shortcut（简化自GoogleNet）的模型，超越了GoogLeNet和VGGNet。为什么效果这么好呢？因为VGGNet和GoogLeNet珠玉在前，Batch Norm也很好用。反正这个工作就是这么简单，我们没有想到理论上有什么创新性，但我们给后续的工作搭建了一个好的baseline。 这样的文章能让读者学到多少东西呢？ ResNet实际上是怎么写的呢？</p> <ul> <li>各位想必都知道当今有个重要的问题：模型越深，居然会越掉点。</li> <li>我们提出的解决方法惊人地简单：将模型中的映射形式从y=f(x)改成y=f(x)+x，也就是所提出的“残差学习”，就能解决这个问题。这是因为模型容易拟合f(x)=0，不容易学出f(x)=x。</li> <li>残差学习非常容易实现，效果非常好。 提出问题——抽象出背后的原理——提出自己的解决方案和具体的实现——实验验证，这才是更符合人类认知规律的论文写法。 有的同学觉得，一篇贡献没那么大的论文硬要写成这样是在”讲故事”，但只要实事求是，只要实验证据能够支撑你的故事，这样的故事既有利于审稿人给你打出高分，也有利于读者学到新知识，更有利于你的观点的传播，属于是赢麻了。</li> </ul> <h3 id="总结和其他建议">总结和其他建议</h3> <ul> <li>上面说的第一件事其实也跟ResNet有关：真实历史上的ResNet来自于对GoogLeNet的拆解研究，并不是突然发现了“残差学习”的原理才有了ResNet，而是孙剑老师带领的团队先通过拆解GoogLeNet发现shortcut结构好用后思考出来的解释。我们上面设想的“丐版”写法虽然是反映了真实的研究过程的，却并不利于背后原理的深挖和核心思想的传播。这个实例正好能够支持本文的观点：研究怎么做和论文怎么写，是两码事。</li> <li>论文是传播知识的工具，是方便别人省时省力地学到新东西的标准化交流方式，不是个人展示个性的舞台。审稿人（读者）习惯于看什么样的论文，我们就写什么样的论文。这本质上跟流行歌曲和通俗小说是一样的，费尽心机来迎合受众而已，不寒碜。</li> <li>没必要在文章结构上寻求创新。大多数文章都可以写成Introduction + Related Work + Method + Experiment + Conclusion的形式。如果你提出的不是单一创新点而是一揽子小改动的组合，可以学习ShuffleNet v2是怎样写的。</li> <li>Be explicit. 你不强调的东西，不要指望别人自己悟出来。</li> <li>要在一个地方集中地完整描述你提出的东西，不要散落得到处都是。不要假设一个读者会有耐心看完50%的篇幅才理解你做了什么。</li> </ul> <hr/> <h2 id="第二部分精耕细作提高readability-1">第二部分：精耕细作，提高”readability”</h2> <p>在《顶会论文写作建议（上）：宏观布局，避免“hard to follow”》中，我们讨论了如何在宏观层面设计论文的结构，以大多数人乐于接受的方式卖出自己的核心贡献。 在本篇中，我们将会聚焦于语言组织的层面，通过十几个我近几年从清华的学弟或实习生同学的论文中收集到的例子，讨论如何提高文章可读性，让读者能心平气和、行云流水地读完，让审稿人能更客观且无痛地评判文章的价值。 需要注意的是，我们讨论的前提是假设论文至少在语法层面是正确的，不再讨论那些可以用Grammarly或ChatGPT自动解决的基础问题。 正如上篇所说，大部分论文都可以写成提出问题——抽象出背后的原理——解决问题的格式（俗称讲故事）。本篇的宏观结构也将遵循这一套路，从而作为对上篇所述宏观写作原则的一次具体实践。 假设本文真的是一篇论文，那么在省略了一大堆关于写作如何重要、写作如何成为了一个重要的研究领域、引用了一大堆关于写作的重要prior work（作者自己也不一定看过，但是看到别人都在引所以就引了）的铺垫语句之后（这些气氛句子本来也没人会看，所以我就不写了），我们的故事现在开始。 本文提出用以下概念来度量文章的可读性：逻辑强度、防御弹性、迷惑时间、信息密度。在此之上，本文提出一些实用的建议和技巧来提高文章的可读性。</p> <h3 id="逻辑强度">逻辑强度</h3> <p>在任何语言的学术写作中，逻辑的连贯都远比用词的华丽更重要。上篇已经介绍了一些宏观逻辑设计上的技巧。在微观层面需要注意的是，逻辑的连贯在于逻辑本身，而不在于衔接词（to this end, in contrast, specifically等等）。 换句话说，我们应该把衔接词当成使语言更加流畅的点缀，而不是通过衔接词来为本没有逻辑的句子强行构造逻辑。例如从总括到具体描述时，用“Specifically, …”；前后两句存在对比关系时，用“In contrast, …”。 而不是反过来！并不是我们写下“In contrast”，前后两句就真的因此而有了对比关系。衔接词与真实逻辑的不匹配会让人疑惑，显著降低文章的可读性。 我们的高中英语写作将衔接词的存在视作逻辑本身，甚至当成作文中的加分项。实际上，用一大堆衔接词不一定能提高文章的流畅程度，反而可能有负面作用。 我们写下每一个衔接词之后都要三省吾身：它前后两句的逻辑关系真实存在吗？它自身放在这个语境下正确吗？不用它行不行？ 例1：衔接词必须自身正确，经得起推敲。 We argue that problem A is critical. To this end, we propose method B. 作者写下这句的时候想的可能只是挑个词来通过problem A引出method B，逻辑是显然的，但写出来的句子却是经不起推敲的：”this end”中的this指的是哪个end？上文说了一个“end“（要做什么/要实现什么目的）吗？上文实际上只是提出了一个观点，并没有说要做什么，所以这个衔接词自身的存在就是错误的。 例2：衔接词不能强加逻辑关系。 The system comprises three modules. First of all, Module A is …. Second, Module B is …. Last but not least, Module C is …. 作者的本意是描述三个并列的事物，这几个衔接词却给这三个本来没有次序关系的东西强加了一定的次序。这时候就不如去掉这些词，分别介绍三个事物即可，根本不用加任何衔接，语言依然流畅：The system comprises three modules. Module A… Module B… Module C.. 例3：衔接词要准确反应真实逻辑关系。 The baseline model is … On top of that, model A employs an extra attention module. In contrast, we propose a novel objective function. 这句话让人迷惑：我们的模型除了这个novel objective function以外是否也用了这个extra attention module呢？读者在寻找“In contrast”对比的对象的时候可以有两种理解。 读者可以理解成model A和我们的模型是用两种方式来解决同一问题，model A用了这一结构而没用这一目标函数，我们是用了这一目标函数而没用这一结构。读者也可以理解成我们试图拿model A和我们自己的方法对比以凸显这个目标函数的效果，所以我们的模型等于model A + 这个新提出的目标函数。 如何修改呢？如果一定要对比的话（比如你的那位不怎么懂但是confidence分数拉满的审稿人一定要让你对比），应该在结构和loss两方面分别讨论从而形成对比，消除歧义，顺便突出我们的优势： From a structural perspective, model A introduces an extra attention module while we use the same model structure as the baseline. In terms of the objective function, method A adopts the vanilla XXX loss, which suffers from …, while we … 这也就是我们所说的，先有逻辑（”我们要从两个方面进行对比！”）后有衔接词（当然不用也行），而不是用衔接词构造逻辑（简单塞进去一个In contrast并期望对比关系就因此而产生）。</p> <h3 id="防御弹性">防御弹性</h3> <p>在写作的时候，我们每写完一句话都要考虑审稿人可能从哪个角度攻击这句话。“防御弹性”指的是我们的语言引起审稿人的质疑的频率和面对审稿人的挑剔时的抵抗能力。 正如写代码时要有“防御式编程”的概念，写作时也要有“防御式写作”的意识，随时考虑笔下的语句是不是无懈可击的。 例4：言出有据。 当我们说“Problem A是本领域的关键问题且尚未得到解决”，这时就要考虑到审稿人可能会问：“为什么说这是关键问题？它造成的后果有多严重？这种后果对最终性能影响大吗？”这就需要我们完善引用： It is reported that problem A results in … [1,2,3] and … [4,5], which are critical to … because … [6, 7, 8]. 丰富且适当的引用会让人觉得作者学识渊博，对本领域理解深刻（哪怕你只看过那些文章的摘要，只是在制造这样的幻象也行）。 例5：轻重适当。 在展示了实验结果之后，我们往往需要解释为什么我们的方法会work。不解释一般是不行的，解释的太绝对了又可能被审稿人challenge（“怎么证明？有什么理论？”），这时就要把握轻重。</p> <ul> <li>我们有直接的证据时：The performance improves, which is attributed to that XXX can … （后面要高调地把证据展示出来）</li> <li>没有直接的证据，但有一些可视化等间接证据：The performance improves, which may be explained that XXX can …</li> <li>几乎没有证据，只是感觉应该是这样的，反正跟我们的motivation是相符的：The performance improves, suggesting that XXX can … 例6：不要用自讨苦吃的主观词汇。 In Table 1, it is obviously exhibited that … 在学术写作这种场合使用诸如obviously之类的带有强烈主观色彩的词汇没有任何好处。如果审稿人能看出你的结果好，不需要你自己强调这个obviously；如果审稿人看不懂，你越强调他就会越迷惑：到底好在哪了，跟我仔细唠唠，我先判你一个overclaim，阁下又该如何应对呢？</li> </ul> <h3 id="迷惑时间">迷惑时间</h3> <p>“迷惑时间”是读者在阅读过程中每一次“咦，这是啥”到“哦，原来是这样”之间的时间的总和。当代人类的耐心是有限的，一篇文章的总的迷惑时间越短，可读性就越高，审稿人就会越心平气和。 例7：提出一个概念后应就近解释。 在深度学习领域中，一个复杂的模型中的一个简单结构根据其功能（和讲故事的需要）可能被命名为XXX Perceiver, XXX Perceptron, XXX Recognizer, XXX Gating Function等等。 建议在给出其名字以后直接解释其实质（we propose XXX, which is implemented with a two-layer MLP）。不然如果在Introduction里只给出了它的名字而在Method部分再给出其实现的话，读者会在很长的一段时间里带着“这么玄乎的东西到底是个啥”的疑惑，最后发现“原来就这啊”，阅读体验很不好。 例8：指代对象应显然且毫无歧义。 We update structure A to solve the problem caused by model B, which is widely used in the literature. 这里“widely used”到底是A还是B？如果我们的写作水平有限，无法让长句完全不带歧义的话，就应该将其拆为短句。没有人会因为你缺少展示高超英语水平的长难句而拒你的文章！ 例9：不要在需要读者集中注意力时多次引用数页后的内容。 我们在introduction里可以提几句我们的结果有多么多么好，带上几个对后面的图表的reference，但不要频繁这么干，尤其是不要在需要读者集中注意力（比如你正在激情四射地展开自己的核心故事，需要读者来判断这个故事是否合理的时候），不然读者翻过去再翻回来的这段时间里思维就断了。读者思维的连续性也是可读性的一部分，毕竟论文是线性叙事。这也是孙剑老师教我的最后一点。</p> <h3 id="信息密度">信息密度</h3> <p>信息密度就不是什么新的概念了，指的是读者能从单位长度的文字中提取到的有效信息量。信息密度过低的文章会让人走神并怀疑作者的专业性。 例10：气氛组语句不应过于冗长。 我们都知道每篇论文中总有一些不会有人认真看的句子，这些句子一般位于各章开头，且其中“recent years”含量极高。这些句子一般还是要写几句的，但建议注意以下几点。</p> <ul> <li>不要太长，写长了没人会看的。我曾经审过一篇做模型压缩的文章，开头从LeNet唠到ViT，直到第二页右半栏才提出“model compression”的定义。</li> <li>不相关的不要写。如果你这篇文章是做ViT的且不涉及底层算子，就不要提卷积网络是如何滑动窗口的了。</li> <li>不要写成历史书。审了这么多稿，我现在对从人类发现动物视皮质原理到LeNet再到AlexNet再到ResNet这段历史已经完全PTSD了。</li> <li>写都写了，尽量跟主旨有点关系，尽快引出正题。例如，如果你提出的是一种新的hierarchical ViT，那么就可以在正文第一句里就把ViT按是否hierarchical分成两类（最近ViT们繁荣发展，包括两类……），第二句就进入主题。 例11：精炼语言。 非英语母语者写出来的英语一般不如母语者精炼，初学者更是经常因为害怕语言不够准确而越写越长。例如： The image classification performance on ImageNet is 79.99% 改为 The ImageNet top-1 accuracy is 79.99%.</li> </ul> <p>As can be observed in Table 1, A outperforms B. 改为 Table 1 shows that A outperforms B.</p> <p>Table 1 shows that the accuracy of model A is 81.0% and the accuracy of model B is 80.0%, so we conclude that model A outperforms model B. 改为 Table 1 shows that model A outperforms model B by 1.0% in the accuracy (81.0% v.s. 80.0%). 用简练的语言准确表达意思是一门技术活，具有本质的困难性。建议多看英语母语者写的论文和其他文字内容，特别是那些有丰富教学经验的年轻选手，因为写教案是最锻炼语言组织能力的（对的，我说的就是当年斯坦福CS231N的主讲Andrej Karpathy）。 例12：图表附近应是全文中信息密度最高的地方，重要的解释和阐述距离图表越近越好。</p> <ul> <li>如果图表中有缩写，那么标题里最好就有解释。</li> <li>如果希望强调Table 5中的某个结果，那么分析这一结果的语句最好跟Table 5在同一页上，而且那句话前后最好就有“Table 5”这几个字。这是因为读者可能根本不会仔细看你写的文字，而是先看图表再去找跟图表中的内容关联的文字。一眼看到Table 5中某个亮眼的结果并感到好奇时，他很可能用pdf阅读器的搜索功能来搜“Table 5”。</li> <li>不要指望读者自己从复杂的表格中自己想明白应该拿谁去跟谁对比以得出结论，我们应该把希望形成对比的内容放在一起。如果这样的表格很难设计的话，哪怕为此必须得把某个结果（一般是需要跟若干组结果全对比一遍的baseline）重复几行也在所不惜。没有人会因为表格设计不够优雅而拒你的论文，但看不明白表格进而血压升高的审稿人是真的会。</li> </ul>]]></content><author><name></name></author></entry><entry><title type="html">李飞飞:从文字到世界,空间智能是AI的下一个前沿</title><link href="https://emigmo.github.io/blog/2025/drfeifei-spatial-intelligence/" rel="alternate" type="text/html" title="李飞飞:从文字到世界,空间智能是AI的下一个前沿"/><published>2025-11-10T00:00:00+00:00</published><updated>2025-11-10T00:00:00+00:00</updated><id>https://emigmo.github.io/blog/2025/drfeifei-spatial-intelligence</id><content type="html" xml:base="https://emigmo.github.io/blog/2025/drfeifei-spatial-intelligence/"><![CDATA[<h1 id="李飞飞从文字到世界空间智能是ai的下一个前沿">李飞飞:从文字到世界,空间智能是AI的下一个前沿</h1> <p><em>作者:李飞飞 (Fei-Fei Li)</em> <em>职位:斯坦福大学教授、World Labs 联合创始人</em> <em>发布时间:2025年11月</em> <em>来源:World Labs 官方博客</em></p> <hr/> <h2 id="前言">前言</h2> <blockquote> <p><strong>“空间智能将改变我们创造和交互现实与虚拟世界的方式——彻底革新叙事、创造力、机器人学、科学发现,以及更多领域。这,正是AI的下一个前沿。”</strong></p> <p><strong>“今天的AI是’黑暗中的文字匠’:能言善辩,却无经验;知识丰富,却缺乏根基。”</strong></p> </blockquote> <p>1950年,当计算机还只是自动化算术和简单逻辑时,艾伦·图灵提出了一个至今仍回荡的问题:机器能思考吗?</p> <p>他能看到别人尚未看到的未来,需要非凡的想象力——那就是:智能或许有一天可以被”构建”,而非”诞生”。</p> <p>今天,以大语言模型(LLM)为代表的前沿AI技术,已经开始改变人类获取与处理抽象知识的方式。然而,它们仍然是”黑暗中的文字匠”:能言善辩,却无经验;知识丰富,却缺乏根基。</p> <p>李飞飞教授在这篇文章中,系统阐述了空间智能的重要性、世界模型的构建原则,以及这项技术将如何深刻重塑创造力、具身智能与人类进步。</p> <hr/> <h2 id="目录">目录</h2> <ul> <li><a href="#一引言从图灵之问到空间智能">一、引言:从图灵之问到空间智能</a></li> <li><a href="#二空间智能人类认知的脚手架">二、空间智能:人类认知的脚手架</a> <ul> <li><a href="#21-进化的基石感知-行动循环">2.1 进化的基石:感知-行动循环</a></li> <li><a href="#22-日常生活中的空间智能">2.2 日常生活中的空间智能</a></li> <li><a href="#23-人类创造力的根基">2.3 人类创造力的根基</a></li> <li><a href="#24-推动文明进步的力量">2.4 推动文明进步的力量</a></li> <li><a href="#25-当前ai的空间智能缺陷">2.5 当前AI的空间智能缺陷</a></li> </ul> </li> <li><a href="#三构建世界模型ai的下一个十年">三、构建世界模型:AI的下一个十年</a> <ul> <li><a href="#31-什么是世界模型">3.1 什么是世界模型</a></li> <li><a href="#32-世界模型的三大核心能力">3.2 世界模型的三大核心能力</a></li> <li><a href="#33-技术挑战与研究方向">3.3 技术挑战与研究方向</a></li> <li><a href="#34-world-labs的研究进展">3.4 World Labs的研究进展</a></li> </ul> </li> <li><a href="#四用世界模型构建更美好的世界">四、用世界模型构建更美好的世界</a> <ul> <li><a href="#41-创造力为叙事注入超能力">4.1 创造力:为叙事注入超能力</a></li> <li><a href="#42-机器人具身智能的实践">4.2 机器人:具身智能的实践</a></li> <li><a href="#43-更长远的地平线科学医疗与教育">4.3 更长远的地平线:科学、医疗与教育</a></li> </ul> </li> <li><a href="#五结语构建与世界契合的智能">五、结语:构建与世界契合的智能</a></li> </ul> <hr/> <h2 id="一引言从图灵之问到空间智能">一、引言:从图灵之问到空间智能</h2> <h3 id="11-图灵的愿景与ai的征程">1.1 图灵的愿景与AI的征程</h3> <p>1950年,当计算机还只是自动化算术和简单逻辑时,艾伦·图灵提出了一个至今仍回荡的问题:<strong>机器能思考吗?</strong></p> <p>他能看到别人尚未看到的未来,需要非凡的想象力——那就是:智能或许有一天可以被”构建”,而非”诞生”。</p> <p>这一洞见催生了一场持续至今的科学征程——人工智能(AI)。在我投身AI研究的25年中,图灵的愿景依然不断启发着我。但我们距离那一愿景有多近?答案并不简单。</p> <h3 id="12-当前ai的成就与局限">1.2 当前AI的成就与局限</h3> <p>今天,以大语言模型(LLM)为代表的前沿AI技术,已经开始改变人类获取与处理抽象知识的方式。</p> <p>它们展示了曾被认为不可能的能力:生成连贯的文本、成山的代码、逼真的图像,甚至短视频。AI是否会改变世界?——从任何合理的定义来看,它已经做到了。</p> <p><strong>然而,它们仍然是”黑暗中的文字匠”</strong>:</p> <ul> <li>能言善辩,却无经验</li> <li>知识丰富,却缺乏根基</li> <li>无法真正理解物理世界</li> </ul> <h3 id="13-为什么空间智能是下一个前沿">1.3 为什么空间智能是下一个前沿</h3> <p><strong>仍有大量潜能未被触及:</strong></p> <ul> <li>自动化机器人的愿景依然诱人却遥远</li> <li>疾病治疗、新材料发现、粒子物理等领域的研究加速梦仍未实现</li> <li>真正能够理解并赋能人类创作者的AI仍未到来</li> </ul> <p><strong>空间智能将改变一切:</strong></p> <p>空间智能(spatial intelligence)将改变我们创造和交互现实与虚拟世界的方式——彻底革新叙事、创造力、机器人学、科学发现,以及更多领域。这,正是AI的下一个前沿。</p> <h3 id="14-我的北极星">1.4 我的”北极星”</h3> <p>自我进入这一领域以来,对视觉与空间智能的探索就一直是我的”北极星”:</p> <ul> <li>构建了 <strong>ImageNet</strong>——首个大规模视觉学习与评测数据集</li> <li>与神经网络算法、现代算力(如GPU)一道,成为孕育现代AI的三大关键要素</li> <li>在斯坦福实验室将计算机视觉与机器人学习相结合</li> <li>与联合创始人创建 <strong>World Labs</strong>,第一次真正实现这一可能性</li> </ul> <p>在这篇文章中,我将解释:</p> <ol> <li>什么是空间智能</li> <li>为什么它重要</li> <li>如何构建能够解锁它的”世界模型”</li> </ol> <hr/> <h2 id="二空间智能人类认知的脚手架">二、空间智能:人类认知的脚手架</h2> <h3 id="21-进化的基石感知-行动循环">2.1 进化的基石:感知-行动循环</h3> <p>视觉长期以来是人类智能的基石,但它的力量源自更为根本的东西。</p> <p><strong>进化的起点:</strong></p> <p>早在动物能筑巢、抚育后代、用语言交流或建立文明之前,那看似简单的”感知行为”:</p> <ul> <li>感受到一缕光</li> <li>触到一种质感</li> </ul> <p>就已经悄然点燃了通向智能的进化旅程。</p> <p><strong>从感知到智能的桥梁:</strong></p> <p>这种从外部世界汲取信息的能力,在感知与生存之间搭建起一座桥梁,而这一桥梁在漫长的进化中变得愈发复杂。</p> <p>神经元层层叠加,形成能解释世界、协调生物与环境互动的神经系统。因此,许多科学家认为,<strong>“感知—行动”循环成为了智能进化的核心机制</strong>,也是自然孕育出我们这个物种的根基——一个能感知、学习、思考与行动的终极存在。</p> <h3 id="22-日常生活中的空间智能">2.2 日常生活中的空间智能</h3> <p>空间智能在我们与物理世界的互动中扮演着基础性的角色。每天,我们都在依赖它完成最平常的动作:</p> <p><strong>日常场景示例:</strong></p> <ul> <li>停车时想象车尾与路缘的距离</li> <li>接住被抛来的钥匙</li> <li>在人群中穿行而不碰撞</li> <li>半睡半醒间准确地将咖啡倒进杯中</li> </ul> <p><strong>极端情况:</strong></p> <ul> <li>消防员穿行于坍塌建筑与浓烟之中,瞬间判断稳定性与生死抉择</li> <li>通过肢体语言和本能默契沟通——这些都无可言传</li> <li>婴儿则在学会语言前的漫长时光里,通过玩耍与环境互动来认识世界</li> </ul> <blockquote> <p><strong>这一切都在直觉中、自然而然地发生——一种机器至今未能获得的流畅能力。</strong></p> </blockquote> <h3 id="23-人类创造力的根基">2.3 人类创造力的根基</h3> <p>空间智能同样是我们想象力与创造力的基石。</p> <p><strong>从古至今的视觉媒介:</strong></p> <p>讲故事的人在脑中构建出丰富的世界,并用各种视觉媒介将之传达给他人:</p> <ul> <li>原始洞穴壁画</li> <li>现代电影</li> <li>沉浸式电子游戏</li> </ul> <p><strong>虚拟世界的构建:</strong></p> <p>无论是孩子在沙滩上筑城堡,还是在电脑上玩《我的世界》,这种以空间为根基的想象构成了人与虚拟世界交互体验的基础。</p> <p><strong>工业应用:</strong></p> <p>在工业应用中,对物体、场景与动态交互环境的模拟则支撑着:</p> <ul> <li>工业设计</li> <li>数字孪生</li> <li>机器人训练</li> </ul> <p>等无数关键场景。</p> <h3 id="24-推动文明进步的力量">2.4 推动文明进步的力量</h3> <p>历史上那些塑造文明的关键时刻中,空间智能往往扮演着核心角色。</p> <p><strong>埃拉托色尼测量地球周长(古希腊):</strong></p> <p>通过对阴影的几何化思考完成了惊人的壮举:</p> <ul> <li>在亚历山大测得太阳影子形成的7度角</li> <li>与赛恩(Syene)”正午无影”的现象进行对比</li> <li>从而计算出了地球的周长</li> </ul> <p><strong>哈格里夫斯的”珍妮纺纱机”:</strong></p> <p>源于空间洞察:</p> <ul> <li>意识到只需将多个纺锤并列安装在一个机架上</li> <li>一个工人就能同时纺出多股线</li> <li>生产效率因此提高了八倍</li> </ul> <p><strong>沃森与克里克揭示DNA结构:</strong></p> <p>依赖于他们亲手搭建的三维分子模型:</p> <ul> <li>用金属板与铁丝不断调整、拼接</li> <li>直到碱基对的空间排布完美契合</li> </ul> <blockquote> <p><strong>在这些案例中,空间智能都推动了文明的进步——当科学家与发明家需要操纵物体、想象结构、在物理空间中推理时,这些能力是纯文字永远无法承载的。</strong></p> </blockquote> <h3 id="25-当前ai的空间智能缺陷">2.5 当前AI的空间智能缺陷</h3> <p>虽然我们大多数人并不会每天像埃拉托色尼那样发现新的真理,但我们几乎时时刻刻都以同样的方式在思考:</p> <ul> <li>通过感官去理解这个复杂世界</li> <li>依托对物理与空间规律的直觉认知,使其变得可理解</li> </ul> <p><strong>遗憾的是,当今的AI还无法以这样的方式思考。</strong></p> <h4 id="多模态大语言模型的进展">多模态大语言模型的进展</h4> <p>过去几年确实取得了巨大进步。多模态大语言模型(MLLMs),在文本之外又引入了大量多媒体数据进行训练,初步具备了空间感知能力:</p> <ul> <li>可以分析图像、回答与之相关的问题</li> <li>甚至生成超写实的图像与短视频</li> </ul> <p>同时,借助传感器与触觉技术的突破,最先进的机器人已经能在严格受限的环境中开始操控物体与工具。</p> <h4 id="根本性局限">根本性局限</h4> <p>然而,坦率地说,AI的空间能力依然远未接近人类水平。其局限也显而易见:</p> <p><strong>基本空间理解的失败:</strong></p> <ul> <li>最先进的MLLM在估计距离、方向、大小等任务上,表现往往不比随机猜测好多少</li> <li>无法”心智旋转”物体——即从新角度再现同一对象的形状</li> <li>不会在迷宫中导航、识别捷径,或预测基本的物理规律</li> </ul> <p><strong>视频生成的连贯性问题:</strong></p> <ul> <li>生成的视频虽然新奇炫目,却常在几秒钟后失去连贯性</li> </ul> <p><strong>根本性的脱节:</strong></p> <p>如今的顶级AI擅长阅读、写作、检索与模式识别,但当涉及对物理世界的表征或交互时,却存在根本性局限。</p> <p>我们人类理解世界的方式是整体性的:</p> <ul> <li>不仅仅看到”眼前的东西”</li> <li>还理解它们在空间上的关系</li> <li>在语义上的意义</li> <li>以及在现实中的重要性</li> </ul> <blockquote> <p><strong>而这种通过想象、推理、创造与交互来理解世界的能力,正是空间智能的力量。</strong></p> </blockquote> <h4 id="缺乏空间智能的后果">缺乏空间智能的后果</h4> <p>缺乏它,AI就与它所试图理解的物理现实脱节。它将:</p> <ul> <li>无法真正安全地驾驶汽车</li> <li>无法在家庭与医院中引导机器人</li> <li>无法创造全新的沉浸式学习与娱乐体验</li> <li>也无法加速材料科学与医学的发现</li> </ul> <h4 id="超越语言的前沿">超越语言的前沿</h4> <p>哲学家维特根斯坦曾写道:<strong>“语言的边界就是我世界的边界”</strong>。</p> <p>我不是哲学家,但我知道,对AI而言,世界不止于语言。空间智能代表着超越语言的前沿。</p> <p>它连接想象、感知与行动,为机器真正提升人类生活打开了新的可能:</p> <ul> <li>从医疗到创造力</li> <li>从科学发现到日常辅助</li> </ul> <hr/> <h2 id="三构建世界模型ai的下一个十年">三、构建世界模型:AI的下一个十年</h2> <h3 id="31-什么是世界模型">3.1 什么是世界模型</h3> <p>那么,我们该如何打造拥有空间智能的AI?</p> <p>如何让模型具备:</p> <ul> <li>像埃拉托色尼那样的空间推理能力</li> <li>像工业设计师那样的工程精度</li> <li>像讲故事的人那样的创造性想象力</li> <li>以及像应急救援人员那样与环境流畅互动的能力?</li> </ul> <p><strong>答案:世界模型(World Models)</strong></p> <p>要实现这样的AI,我们需要比LLM更具雄心的体系:世界模型(World Models)。</p> <p>这是一种全新的生成式模型,其在理解、推理、生成与交互方面的能力,将超越当今LLM所能触及的极限。它能够在语义、物理、几何与动态层面上,理解并生成复杂的虚拟或真实世界。</p> <p><strong>领域现状:</strong></p> <p>这一领域尚处于萌芽阶段,现有方法从抽象推理模型到视频生成系统不等。</p> <p>World Labs成立于2024年初,正是基于这样一种信念:<strong>基础性方法仍在形成之中,而这将成为未来十年人工智能的决定性挑战。</strong></p> <h3 id="32-世界模型的三大核心能力">3.2 世界模型的三大核心能力</h3> <p>在这个新兴领域中,最重要的是确立指导发展方向的核心原则。对于空间智能而言,我将”世界模型”定义为具备以下三项核心能力的系统:</p> <h4 id="能力1生成性generative">能力1:生成性(Generative)</h4> <p><strong>世界模型能够生成具有感知、几何与物理一致性的世界</strong></p> <p>要实现空间理解与推理,世界模型必须能够生成自身的模拟世界。</p> <p><strong>核心要求:</strong></p> <ul> <li>能在语义或感知指令的引导下,生成无限多样、变化丰富的虚拟世界</li> <li>同时保持几何、物理与动态上的一致性</li> <li>无论这些世界是现实的还是虚拟的</li> </ul> <p><strong>表征形式的探索:</strong></p> <p>研究界目前正在探索,这些世界应当以隐式(implicit)还是显式(explicit)的几何结构形式表示。</p> <p><strong>我的观点:</strong></p> <p>除了强大的潜在表征(latent representations)之外,我认为通用世界模型的输出还应当:</p> <ul> <li>允许生成显式、可观测的世界状态</li> <li>以便适应不同的应用场景</li> </ul> <p><strong>时间连贯性:</strong></p> <p>尤其重要的是,模型对当下世界的理解必须与其过去的状态保持连贯一致——<strong>理解当前,就是理解它是如何演化而来的。</strong></p> <h4 id="能力2多模态multimodal">能力2:多模态(Multimodal)</h4> <p><strong>世界模型在设计上就是多模态的</strong></p> <p>正如人类与动物一样,世界模型应能处理多种形式的输入。在生成式AI领域中,这些输入被称为”提示词(prompts)”。</p> <p><strong>多样化的输入:</strong></p> <p>面对不完整的信息——无论是:</p> <ul> <li>图像</li> <li>视频</li> <li>深度图</li> <li>文本指令</li> <li>手势</li> <li>还是动作</li> </ul> <p>世界模型都应能预测或生成尽可能完整的世界状态。</p> <p><strong>处理要求:</strong></p> <p>这要求模型:</p> <ul> <li>既要以真实视觉的精度处理图像输入</li> <li>又能以同样的灵活性理解语义性指令</li> </ul> <p><strong>交互方式:</strong></p> <p>如此一来,无论是智能体还是人类,都能:</p> <ul> <li>通过多样的输入形式与模型就”世界”进行交流</li> <li>以多样的方式接收输出</li> </ul> <h4 id="能力3交互性interactive">能力3:交互性(Interactive)</h4> <p><strong>世界模型能根据输入动作输出下一个状态</strong></p> <p>最后,当动作(actions)和/或目标(goals)作为输入提示的一部分时,世界模型的输出必须包含世界的下一个状态。</p> <p><strong>状态表征:</strong></p> <p>这一状态可以是隐式的,也可以是显式的。</p> <p><strong>一致性要求:</strong></p> <p>当输入仅包含一个动作(有无目标皆可)时,世界模型应能生成与以下内容相一致的输出:</p> <ul> <li>世界先前状态</li> <li>预期目标状态(如有)</li> <li>其语义意义</li> <li>物理规律</li> <li>动态行为</li> </ul> <p><strong>未来展望:</strong></p> <p>随着空间智能世界模型在推理与生成能力上不断增强,我们可以想象,未来模型不仅能预测世界的下一个状态,还将能够基于该状态预测下一步行动。</p> <h3 id="33-技术挑战与研究方向">3.3 技术挑战与研究方向</h3> <p>这一挑战的规模,超越了AI以往所面临的一切。</p> <h4 id="挑战的复杂性">挑战的复杂性</h4> <p>语言是人类认知中纯粹生成的现象,而”世界”遵循的规则则复杂得多。</p> <p><strong>在地球上,例如:</strong></p> <ul> <li>重力决定运动</li> <li>原子结构决定光的颜色与亮度</li> <li>无数物理定律约束着一切交互</li> </ul> <p><strong>即使是最奇幻、最具创造性的世界:</strong></p> <ul> <li>也由遵守物理与动态规律的空间对象与智能体构成</li> </ul> <p><strong>核心难题:</strong></p> <p>要在模型中一致地协调这些——语义、几何、动力学与物理层面——需要全新的方法论。因为”世界”的维度远比语言这种一维的序列信号复杂得多。</p> <h4 id="world-labs的研究方向">World Labs的研究方向</h4> <p>要实现像人类一样具备普适空间智能的世界模型,必须跨越若干巨大的技术壁垒。</p> <p>在World Labs,我们的研究团队正致力于这一目标的基础性突破。以下是我们当前研究的几个方向示例:</p> <p><strong>方向1:新的通用训练任务函数</strong></p> <p>在世界模型研究中,一个长期目标是定义一种像LLM中”下一个token预测”一样简洁优雅的通用任务函数。</p> <p><strong>挑战:</strong></p> <ul> <li>世界模型输入与输出空间的复杂性使这一函数的设计更加困难</li> </ul> <p><strong>要求:</strong></p> <ul> <li>这一目标函数及其对应表征必须符合几何与物理规律</li> <li>忠实体现世界模型在想象与现实之间的”落地表征”本质</li> </ul> <p><strong>方向2:大规模训练数据</strong></p> <p>训练世界模型所需的数据远比文本复杂。</p> <p><strong>好消息:</strong></p> <ul> <li>我们已经拥有了庞大的数据资源</li> <li>互联网上规模宏大的图像与视频集合为训练提供了丰富的素材</li> </ul> <p><strong>挑战:</strong></p> <ul> <li>如何让算法从二维图像或视频帧(RGB)中提取更深层次的空间信息</li> </ul> <p><strong>关键问题:</strong></p> <ul> <li>过去十年的研究揭示了语言模型中数据量与模型规模的scaling law</li> <li>对于世界模型,关键在于构建能够在相似规模上有效利用视觉数据的架构</li> </ul> <p><strong>补充数据源:</strong></p> <ul> <li>高质量的合成数据</li> <li>额外模态(如深度、触觉)</li> <li>在训练过程的关键阶段起到补充作用</li> </ul> <p><strong>未来发展取决于:</strong></p> <ul> <li>更先进的传感系统</li> <li>更稳健的信号提取算法</li> <li>以及更强大的神经仿真方法</li> </ul> <p><strong>方向3:新的模型架构与表征学习</strong></p> <p>世界模型研究将不可避免地推动模型架构与学习算法的革新,特别是超越当下的多模态LLM与视频扩散模型(video diffusion)。</p> <p><strong>当前模型的局限:</strong></p> <p>这些模型通常将数据编码为一维或二维序列,使得简单的空间任务变得异常困难:</p> <ul> <li>在短视频中数清不同的椅子</li> <li>记住一小时前房间的样子</li> </ul> <p><strong>新的架构思路:</strong></p> <p>或许能改进这一点,例如:</p> <ul> <li>具备3D或4D感知能力的token化</li> <li>上下文与记忆机制</li> </ul> <p><strong>World Labs的RTFM模型:</strong></p> <p>在World Labs,我们最近开发了一种基于帧的实时生成模型——<strong>RTFM(Real-Time Generative Frame-based Model)</strong>。</p> <p>它的特点:</p> <ul> <li>以空间为基础的帧(spatially-grounded frames)作为空间记忆形式</li> <li>实现了高效实时生成的同时</li> <li>保持了生成世界的持续性与一致性</li> </ul> <h3 id="34-world-labs的研究进展">3.4 World Labs的研究进展</h3> <p>显然,在完全释放空间智能的潜力之前,我们仍面临艰巨的挑战。但这项研究不仅仅是理论工作,<strong>它正成为新一代创造性与生产力工具的核心引擎</strong>。</p> <h4 id="marble首个世界模型产品">Marble:首个世界模型产品</h4> <p>在World Labs的进展令人鼓舞。我们最近向部分用户展示了 <strong>Marble</strong> 的早期版本:</p> <p><strong>Marble的特点:</strong></p> <ul> <li>全球首个可通过多模态输入生成并保持一致性3D环境的世界模型</li> <li>让用户与创作者能够探索、交互并在其中继续构建他们的创意世界</li> </ul> <p><strong>当前状态:</strong></p> <ul> <li>我们正全力以赴,努力尽快将其向公众开放</li> </ul> <h4 id="未来展望">未来展望</h4> <p>Marble只是我们的第一步。随着研究的加速,科研人员、工程师、用户与商业领袖们都开始意识到这一方向的巨大潜能。</p> <p><strong>下一代世界模型将:</strong></p> <ul> <li>使机器在空间智能上达到全新的层次</li> <li>开启AI迄今仍普遍缺乏的核心能力</li> <li>真正让人工智能进入理解与创造世界的时代</li> </ul> <hr/> <h2 id="四用世界模型构建更美好的世界">四、用世界模型构建更美好的世界</h2> <h3 id="41-人工智能的发展动机">4.1 人工智能的发展动机</h3> <p>人工智能的发展动机至关重要。作为推动现代AI时代到来的科学家之一,我的动机始终十分明确:<strong>AI应当增强人类的能力,而非取而代之。</strong></p> <p>多年来,我一直致力于让AI的开发、部署与治理与人类需求保持一致。</p> <p><strong>务实的立场:</strong></p> <p>当下关于”技术乌托邦”与”世界末日”的极端叙事比比皆是,但我依然持一种更务实的立场:</p> <ul> <li>AI是由人开发、被人使用、并由人治理的</li> <li>它必须始终尊重人的自主性与尊严</li> <li>它的”魔力”在于拓展我们的能力,让我们变得更具创造力、更紧密相连、更高效并更有成就感</li> </ul> <p><strong>空间智能的愿景:</strong></p> <p>空间智能正体现了这一愿景——一种能赋能人类创造者、照护者、科学家与梦想家的AI,使他们实现曾经不可能的目标。</p> <blockquote> <p><strong>这一信念,正是我将空间智能视为AI下一个伟大前沿领域的根本原因。</strong></p> </blockquote> <h3 id="42-应用的时间尺度">4.2 应用的时间尺度</h3> <p>空间智能的应用横跨不同的时间尺度:</p> <p><strong>当下(短期):</strong></p> <ul> <li>创作工具正在当下出现</li> <li>World Labs的 Marble 已经让创作者与讲故事的人能够亲手掌握这种能力</li> </ul> <p><strong>中期:</strong></p> <ul> <li>机器人领域代表着中期的雄心目标</li> <li>我们正致力于完善感知与行动之间的闭环</li> </ul> <p><strong>长期:</strong></p> <ul> <li>最具变革意义的科学应用可能需要更长时间</li> <li>但它们将深刻地促进人类的福祉</li> </ul> <p><strong>集体努力的需要:</strong></p> <p>在所有时间线中,有几个领域的潜力尤其突出,足以重塑人类的能力。要实现这些潜力,需要集体努力:</p> <ul> <li>远超任何一个团队或公司的能力范围</li> <li>需要整个AI生态系统的参与:研究者、创新者、创业者、企业家,乃至政策制定者</li> <li>共同朝着一个愿景努力</li> </ul> <p>而这个愿景,值得我们追求。以下是未来的图景:</p> <h3 id="43-创造力为叙事注入超能力">4.3 创造力:为叙事注入超能力</h3> <blockquote> <p><strong>“创意,是智慧的乐趣。”</strong> ——爱因斯坦</p> </blockquote> <h4 id="故事的力量">故事的力量</h4> <p>在人类发明文字之前,我们就会讲故事:</p> <ul> <li>把故事画在洞穴壁上</li> <li>代代相传</li> <li>并以共享的叙事建立文化</li> </ul> <p>故事是人类:</p> <ul> <li>理解世界</li> <li>跨越时空连接彼此</li> <li>探索”人之为人”的方式</li> <li>也是我们在生活与爱中寻找意义的途径</li> </ul> <h4 id="彻底变革叙事方式">彻底变革叙事方式</h4> <p>今天,空间智能有潜力彻底变革我们创作与体验叙事的方式,从娱乐到教育,从设计到建造,赋予它们更深远的影响力。</p> <p><strong>Marble平台的能力:</strong></p> <p>World Labs的Marble平台将前所未有的空间表达能力与编辑控制权交到创作者手中:</p> <ul> <li>电影人</li> <li>游戏设计师</li> <li>建筑师</li> <li>及各类讲述者</li> </ul> <p><strong>无需传统3D设计软件的繁复流程:</strong></p> <ul> <li>快速创造、迭代、探索完整的三维世界</li> </ul> <p><strong>人类仍是核心:</strong></p> <ul> <li>创造的行为依然是人类的核心活动</li> <li>AI只是放大并加速创意实现的过程</li> </ul> <h4 id="三大应用方向">三大应用方向</h4> <p><strong>1. 多维叙事体验</strong></p> <p>电影人和游戏设计师可以利用 Marble 构建整个世界:</p> <ul> <li>不受预算或地理限制</li> <li>探索传统制作流程中无法实现的场景与视角</li> </ul> <p><strong>媒介融合:</strong></p> <p>随着媒介与娱乐的界限模糊化,我们正接近一种全新的互动体验形态:</p> <ul> <li>融合艺术、模拟与游戏的个性化世界</li> <li>让任何人(而不仅仅是大型工作室)都能创造并进入自己的故事</li> </ul> <p><strong>2. 以设计讲述空间故事</strong></p> <p>几乎所有被制造的物品或建造的空间,都必须在物理实现之前经过虚拟3D设计——这一过程往往耗费大量时间与成本。</p> <p><strong>空间智能的加速:</strong></p> <ul> <li>建筑师可以在数分钟内可视化并漫游尚不存在的建筑</li> <li>工业或时装设计师可以即时将想象转化为形态</li> <li>探索物体与人体及空间的交互</li> </ul> <p><strong>3. 全新的沉浸与互动体验</strong></p> <p>人类体验的最深层方式之一,就是创造意义的体验本身。</p> <p><strong>历史限制:</strong></p> <p>在整个人类历史上,我们只共享一个三维世界:物理世界。直到近几十年,通过游戏与早期虚拟现实(VR),我们才得以初步窥见”自造世界”的可能。</p> <p><strong>技术融合:</strong></p> <p>如今,空间智能结合VR、XR(扩展现实)头显与沉浸式显示设备,将这种体验提升到前所未有的高度。</p> <p><strong>未来愿景:</strong></p> <ul> <li>人们”走进”多维世界将如同打开一本书般自然</li> <li>空间智能让造世界的权力从专业团队扩展到每一位拥有愿景的创作者、教育者与普通人</li> </ul> <h3 id="44-机器人具身智能的实践">4.4 机器人:具身智能的实践</h3> <p>从昆虫到人类,动物都依赖空间智能来理解、导航并与世界交互。机器人也不会例外。</p> <h4 id="长久以来的梦想">长久以来的梦想</h4> <p>自该领域诞生以来,”具备空间感知的机器”就是人类的梦想,包括我在斯坦福研究实验室与学生、合作者共同进行的研究。</p> <blockquote> <p><strong>正因如此,我对用 World Labs 构建的模型实现这一愿景感到异常兴奋。</strong></p> </blockquote> <h4 id="三大应用方向-1">三大应用方向</h4> <p><strong>1. 通过世界模型扩展机器人学习</strong></p> <p>机器人的学习进步取决于可扩展的训练数据方案。</p> <p><strong>核心需求:</strong></p> <p>要让机器人具备理解、推理、规划与交互的能力,它们需要覆盖极为庞大的状态空间。</p> <p><strong>当前共识:</strong></p> <p>许多研究者认为,三者结合是实现可泛化机器人的关键:</p> <ul> <li>互联网数据</li> <li>合成仿真数据</li> <li>人类演示的真实采集</li> </ul> <p><strong>数据稀缺性:</strong></p> <p>然而,与语言模型不同,如今机器人的训练数据极为稀缺。</p> <p><strong>世界模型的作用:</strong></p> <p>世界模型将在此发挥决定性作用。随着其感知精度与计算效率的提高:</p> <ul> <li>世界模型生成的输出将迅速缩小模拟与现实之间的差距</li> <li>从而让机器人能在数不清的状态、互动与环境中学习</li> </ul> <p><strong>2. 人机协作伙伴</strong></p> <p>无论是:</p> <ul> <li>实验室中协助科学家的研究助理机器人</li> <li>还是陪伴独居老人的家用助理</li> </ul> <p>机器人都可以扩展劳动力并提升社会生产力。</p> <p><strong>核心要求:</strong></p> <p>但要做到这一点,机器人必须具备空间智能:</p> <ul> <li>能感知、推理、规划、行动</li> <li>并且最重要的是:保持对人类目标与行为的同理一致</li> </ul> <p><strong>应用示例:</strong></p> <ul> <li><strong>实验室机器人</strong>:可以替代科学家完成仪器操作,让人专注于需要推理的部分</li> <li><strong>家庭助理机器人</strong>:可以帮助老人做饭,而不剥夺他们的乐趣与自主性</li> </ul> <p><strong>关键能力:</strong></p> <p>真正具备空间智能的世界模型能够:</p> <ul> <li>预测下一个状态</li> <li>甚至推断与之匹配的下一步行动</li> <li>是实现这一愿景的关键</li> </ul> <p><strong>3. 扩展的具身形态</strong></p> <p>人形机器人只是我们为自身世界打造的一个形式。</p> <p><strong>真正的创新红利:</strong></p> <p>将来自更加多样的设计:</p> <ul> <li>输送药物的纳米机器人</li> <li>穿行狭窄空间的软体机器人</li> <li>以及为深海或外太空而造的机器</li> </ul> <p><strong>通用要求:</strong></p> <p>无论形态如何,未来的空间智能模型都必须将环境与机器人自身的感知、运动一体化建模。</p> <p><strong>关键挑战:</strong></p> <p>开发这些机器人面临的关键挑战在于:缺乏多样化形态的训练数据。</p> <p><strong>世界模型的作用:</strong></p> <p>世界模型将在这一过程中发挥关键作用:</p> <ul> <li>为仿真数据提供支持</li> <li>为训练环境提供支持</li> <li>为评测任务提供支持</li> </ul> <h3 id="45-更长远的地平线科学医疗与教育">4.5 更长远的地平线:科学、医疗与教育</h3> <p>除了创造性与机器人应用外,”空间智能”的深远影响还将延伸至更多能够增强人类能力、拯救生命、加速发现的领域。</p> <p>以下我将重点介绍三个具有深刻变革潜力的方向。当然,空间智能的应用远不止于此,它的影响范围几乎遍及所有行业。</p> <h4 id="1-科学研究模拟实验与假设验证">1. 科学研究:模拟实验与假设验证</h4> <p><strong>核心能力:</strong></p> <p>在科学研究中,具备空间智能的系统可以:</p> <ul> <li>模拟实验</li> <li>并行验证假设</li> <li>探索人类无法亲临的环境——从深海到遥远的行星</li> </ul> <p><strong>变革领域:</strong></p> <p>这项技术有望彻底变革:</p> <ul> <li>气候科学</li> <li>材料研究</li> <li>等领域的计算建模方式</li> </ul> <p><strong>关键优势:</strong></p> <p>通过将多维度模拟与真实世界数据采集相结合,这些工具能:</p> <ul> <li>显著降低计算壁垒</li> <li>拓展每一个实验室可观察与理解的边界</li> </ul> <h4 id="2-医疗领域从实验室到病床">2. 医疗领域:从实验室到病床</h4> <p>在医疗领域,空间智能将重塑从实验室到病床的全过程。</p> <p><strong>我的经验:</strong></p> <p>在斯坦福,我与学生及合作者多年来一直与医院、养老机构以及居家患者合作。这些经验让我深信空间智能在医疗领域的变革潜力。</p> <p><strong>三大应用方向:</strong></p> <p><strong>药物研发:</strong></p> <ul> <li>通过多维建模加速药物研发</li> </ul> <p><strong>诊断辅助:</strong></p> <ul> <li>通过辅助放射科医生识别影像中的模式来提升诊断质量</li> </ul> <p><strong>环境感知式监护:</strong></p> <ul> <li>支持环境感知式监护系统</li> <li>在不取代人类关怀的前提下</li> <li>为患者与护理人员提供持续支持</li> </ul> <p><strong>机器人辅助:</strong></p> <ul> <li>更不用说机器人在不同场景中帮助医护人员和患者的巨大潜力</li> </ul> <h4 id="3-教育领域沉浸式学习体验">3. 教育领域:沉浸式学习体验</h4> <p>空间智能能够实现沉浸式学习:</p> <ul> <li>让抽象或复杂的概念变得可感知</li> <li>创造出符合人类大脑与身体学习方式的迭代体验</li> </ul> <p><strong>AI时代的学习需求:</strong></p> <p>在AI时代,更快速、更高效的学习与技能重塑对于儿童与成人都至关重要。</p> <p><strong>三大应用场景:</strong></p> <p><strong>学生:</strong></p> <ul> <li>可以以多维方式探索细胞机器</li> <li>或”亲历”历史事件</li> </ul> <p><strong>教师:</strong></p> <ul> <li>可借助互动环境进行个性化教学</li> </ul> <p><strong>专业人士:</strong></p> <ul> <li>外科医生、工程师等专业人士则能在高度逼真的仿真环境中安全地练习复杂技能</li> </ul> <h4 id="统一的目标">统一的目标</h4> <p>跨越这些领域,可能性是无限的,但目标始终如一:</p> <blockquote> <p><strong>让AI成为增强人类专长、加速人类发现、放大人类关怀的力量——而不是取代那份属于人的判断力、创造力与共情力。</strong></p> </blockquote> <hr/> <h2 id="五结语构建与世界契合的智能">五、结语:构建与世界契合的智能</h2> <h3 id="51-ai成为全球现象">5.1 AI成为全球现象</h3> <p>过去十年间,人工智能已成为全球现象,在科技、经济乃至地缘政治层面都带来了转折。</p> <h3 id="52-图灵精神的延续">5.2 图灵精神的延续</h3> <p>然而,作为一名研究者、教育者和创业者,最令我振奋的仍是图灵七十五年前那道问题背后的精神。</p> <blockquote> <p><strong>我依然与他共享那份好奇与惊叹——正是这份好奇,让我每天都为探索空间智能的挑战而充满动力。</strong></p> </blockquote> <h3 id="53-历史性的时刻">5.3 历史性的时刻</h3> <p>人类历史上第一次,我们正站在这样一个时刻:<strong>有望构建出与物理世界高度契合的机器,让它们成为我们应对重大挑战的真正伙伴。</strong></p> <p><strong>应用前景:</strong></p> <p>无论是:</p> <ul> <li>加速疾病研究</li> <li>革新故事叙述方式</li> <li>还是在病痛、受伤或衰老的脆弱时刻给予支持</li> </ul> <p>我们都正处于一场技术变革的门槛上,它将提升我们最珍视的生命价值。</p> <h3 id="54-关于生活的愿景">5.4 关于生活的愿景</h3> <blockquote> <p><strong>这是一个关于更深刻、更丰富、更有力量的生活的愿景。</strong></p> </blockquote> <p>距自然在原始动物中首次显现空间智能的曙光已近五亿年,而我们有幸成为这一代技术创造者:</p> <ul> <li>可能即将赋予机器同样能力的人类</li> <li>也有幸能将此能力用于全人类的福祉</li> </ul> <h3 id="55-我的北极星">5.5 我的”北极星”</h3> <p>若没有空间智能,我们关于”真正智能机器”的梦想将永远不完整。</p> <blockquote> <p><strong>这场探索,是我的”北极星”。邀请你一同追寻它。</strong></p> </blockquote> <hr/> <p><strong>作者简介:</strong> 李飞飞(Fei-Fei Li)是斯坦福大学教授、ImageNet创始人、World Labs联合创始人。她是计算机视觉和人工智能领域的先驱,致力于构建具备空间智能的AI系统。</p> <p><strong>来源:</strong> World Labs 官方博客 <strong>整理时间:</strong> 2025年11月10日</p>]]></content><author><name></name></author><category term="blog"/><summary type="html"><![CDATA[李飞飞:从文字到世界,空间智能是AI的下一个前沿]]></summary></entry><entry><title type="html">Anthropic 研究员详解：构建高效 Claude 智能体的完整方法论</title><link href="https://emigmo.github.io/blog/2025/anthropic-claude-agent-methodology/" rel="alternate" type="text/html" title="Anthropic 研究员详解：构建高效 Claude 智能体的完整方法论"/><published>2025-11-06T00:00:00+00:00</published><updated>2025-11-06T00:00:00+00:00</updated><id>https://emigmo.github.io/blog/2025/anthropic-claude-agent-methodology</id><content type="html" xml:base="https://emigmo.github.io/blog/2025/anthropic-claude-agent-methodology/"><![CDATA[<h1 id="anthropic-研究员详解构建高效-claude-智能体的完整方法论">Anthropic 研究员详解：构建高效 Claude 智能体的完整方法论</h1> <p><em>访谈对象：Alex Albert (Claude 关系负责人)、Erik Schluntz (多智能体研究员)</em><br/> <em>时间：2025年11月</em><br/> <em>来源：Anthropic 官方播客</em></p> <hr/> <h2 id="前言">前言</h2> <blockquote> <p><strong>“编码是智能体最基本、最核心的技能。一旦拥有了一个出色的编码智能体，这个智能体几乎可以完成任何其他类型的工作。”</strong></p> <p><strong>“工具应该映射 UI，而非 API——这是构建智能体工具最常见也最严重的错误观念。”</strong></p> </blockquote> <p>最近，来自 Anthropic 的两位核心成员——Claude 关系负责人 Alex Albert 与多智能体研究员 Erik Schluntz，深入探讨了 AI 智能体在过去数月中的快速演进。他们分享了从简单的”工作流”过渡到复杂的”多智能体系统”的实践经验，并详细阐述了如何通过代码、Claude Skills、MCP 和工具的最佳实践来构建更高效、更自主的 Claude 智能体。</p> <p><strong>三个核心洞察：</strong></p> <ol> <li><strong>编码能力是一切的基础</strong>：强大的编码智能体可以泛化到任何领域，这种”溢出效应”是 Claude 在所有任务上表现出色的关键</li> <li><strong>架构演进路径清晰</strong>：从静态工作流 → 单一智能体循环 → 智能体工作流 → 多智能体系统，复杂度逐级递增</li> <li><strong>UI映射原则至关重要</strong>：工具设计应模拟用户界面而非后端API，这能显著提升智能体效率</li> </ol> <hr/> <h2 id="目录">目录</h2> <ul> <li><a href="#一claude-作为智能体的基础编码能力的溢出效应">一、Claude 作为智能体的基础：编码能力的”溢出效应”</a></li> <li><a href="#二开发者工具的演进从-sdk-到-skills">二、开发者工具的演进：从 SDK 到 Skills</a></li> <li><a href="#三智能体系统的架构演进">三、智能体系统的架构演进</a></li> <li><a href="#四智能体开发者的核心最佳实践">四、智能体开发者的核心最佳实践</a></li> <li><a href="#五未来展望长程任务的自动交付">五、未来展望：长程任务的自动交付</a></li> <li><a href="#结语从工具到伙伴的跃迁">结语：从工具到伙伴的跃迁</a></li> </ul> <hr/> <h2 id="一claude-作为智能体的基础编码能力的溢出效应">一、Claude 作为智能体的基础：编码能力的”溢出效应”</h2> <h3 id="11-智能体能力的训练根源">1.1 智能体能力的训练根源</h3> <p>要理解如何构建高效的智能体，首先要明白 Claude 为何擅长执行智能体任务。Erik 指出，核心在于<strong>大量的刻意练习</strong>。</p> <p><strong>训练策略：</strong></p> <ul> <li>在训练过程中，Claude 被要求处理许多开放式问题</li> <li>这些任务要求采取多个步骤、使用工具、探索环境</li> <li>通过强化学习对编码、搜索等不同场景进行大量练习</li> </ul> <p>这种训练方式让 Claude 积累了丰富的”作为智能体”的经验，因此在智能体任务上表现出色。</p> <h3 id="12-为什么编码是最重要的技能">1.2 为什么编码是最重要的技能</h3> <p>外界普遍认为 Claude 在编码方面异常强大，但常误以为这种能力仅限于技术领域。Erik 提出了不同的看法：</p> <blockquote> <p><strong>编码是智能体最基本、最核心的技能。</strong></p> </blockquote> <p>Anthropic 的理念是<strong>“先训练最难的东西”</strong>——即编码，那么其他一切都会变得更容易。</p> <p><strong>编码能力的泛化场景：</strong></p> <ul> <li><strong>搜索任务</strong>：编写代码调用 Web 搜索 API</li> <li><strong>行程规划</strong>：编写代码创建日程表或数据结构</li> <li><strong>数据分析</strong>：编写脚本处理和可视化数据</li> </ul> <p>编码能力的”溢出效应”极其显著，它是使 Claude 在所有领域都表现出色的基石。</p> <h3 id="13-从直接生成到代码生成的效率革命">1.3 从直接生成到代码生成的效率革命</h3> <p>这种以编码为核心的理念，已经体现在 Claude.ai 网页版的功能中：Claude 能通过编写代码来创建实际的文件。</p> <p><strong>典型案例：</strong></p> <p>Erik 分享了一个亲身经历。他让 Claude 帮他为演示文稿制作图表：</p> <ol> <li><strong>简单图表</strong>：Claude 直接编写 SVG 代码生成</li> <li><strong>复杂图表</strong>：当需要大量重复性细节时，Claude 改变策略——编写一段脚本来生成 SVG 文件</li> </ol> <blockquote> <p><strong>效率对比：脚本运行速度远远快于 Claude 逐字生成图像文件的速度。</strong></p> </blockquote> <p><strong>核心原则：</strong> 对于许多复杂或重复性的任务，让智能体编写代码来生产某个”人工产物”，比让它直接创建这个产物要高效得多。</p> <hr/> <h2 id="二开发者工具的演进从-sdk-到-skills">二、开发者工具的演进：从 SDK 到 Skills</h2> <h3 id="21-claude-code-sdk通用智能体框架">2.1 Claude Code SDK：通用智能体框架</h3> <p>当开发者真正开始构建自己的智能体时，<strong>Claude Code SDK</strong> 正变得越来越受欢迎。</p> <p><strong>SDK 的核心价值：</strong></p> <ul> <li>解决了”重复造轮子”问题</li> <li>内置了所有基础工作：循环、工具构建、工具执行、文件系统交互、MCP 处理</li> <li>虽然名字里有”Code”，但本质上是一个<strong>通用智能体框架</strong></li> </ul> <p><strong>使用建议：</strong></p> <p>Erik 强烈建议开发者将这个 SDK 作为智能体循环的核心。这样开发者可以把时间花在真正有价值的地方：</p> <ul> <li>通过 MCP 添加独特的工具</li> <li>定制业务逻辑</li> <li>实现特定功能</li> </ul> <p><strong>高度可定制性：</strong></p> <p>开发者可以移除编码相关部分，然后填入自己需要的任何提示或工具。Erik 甚至用它规划过约会——通过集成网络搜索工具，这个”编码 SDK”帮他搜索了地区活动和餐馆，推荐了长木花园和附近的中餐馆。</p> <h3 id="22-claude-skills从指令到资源的跃迁">2.2 Claude Skills：从指令到资源的跃迁</h3> <p><strong>技能的起源：Claude.md 文件</strong></p> <p>开发者可以在项目根目录放置 <code class="language-plaintext highlighter-rouge">Claude.md</code> 文件，向 Claude 提供项目背景信息：</p> <ul> <li>编程风格偏好</li> <li>项目目录结构</li> <li>技术栈说明</li> </ul> <p><strong>Skills 的革命性扩展：</strong></p> <p>Skills 不再局限于提供纯文本”指令”，而是允许开发者为 Claude 提供<strong>任何类型的文件作为”资源”</strong>。</p> <p><strong>资源类型示例：</strong></p> <ol> <li><strong>模板文件</strong>：公司官方 PowerPoint 模板</li> <li><strong>辅助脚本</strong>：Claude 可调用的现成代码</li> <li><strong>资产文件</strong>：图像、Logo、高管照片等</li> </ol> <blockquote> <p><strong>从”给指令”到”给资源”</strong>——这标志着智能体工具的重大转变。</p> </blockquote> <p><strong>“黑客帝国”比喻：</strong></p> <p>Alex 用《黑客帝国》中 Neo 学习功夫的场景作比喻：当”功夫”程序被注入大脑后，他瞬间掌握了技能。给 Claude 一项”技能”的感觉非常相似——比如给它一个”如何创建电子表格”的技能包，Claude 就像变成了专业的”银行家”，能够构建复杂的财务模型。</p> <hr/> <h2 id="三智能体系统的架构演进">三、智能体系统的架构演进</h2> <h3 id="31-从工作流到智能体循环">3.1 从工作流到智能体循环</h3> <p>几个月前，智能体领域正处于过渡期：从”工作流”向”单一智能体系统”转变。</p> <p><strong>工作流 vs 智能体循环：</strong></p> <table> <thead> <tr> <th>类型</th> <th>特点</th> <th>适用场景</th> </tr> </thead> <tbody> <tr> <td>工作流</td> <td>链接的提示词序列，每步单次执行</td> <td>需要极低延迟的简单任务</td> </tr> <tr> <td>智能体循环</td> <td>模型在循环中运行，可反馈和纠正</td> <td>追求绝对质量的复杂任务</td> </tr> </tbody> </table> <p><strong>为什么智能体循环胜出：</strong></p> <p>Claude 在”响应反馈”和”纠正自身工作”方面的能力已经非常出色，因此智能体循环在追求质量的任务上表现远超工作流。</p> <h3 id="32-智能体工作流串行的智能体链">3.2 智能体工作流：串行的智能体链</h3> <p>Erik 观察到的最新趋势：<strong>“智能体工作流”(Workflows of Agents)</strong>。</p> <p><strong>案例对比：数据查询与图表绘制</strong></p> <p><strong>旧的工作流（Workflow）：</strong></p> <ol> <li>步骤一（单次尝试）：Claude 编写 SQL 命令加载数据</li> <li>步骤二（单次尝试）：基于数据绘制图表</li> <li><strong>失败点</strong>：如果步骤一的 SQL 失败，步骤二对此一无所知，基于错误数据继续执行</li> </ol> <p><strong>新的智能体工作流（Workflow of Agents）：</strong></p> <ol> <li>步骤一（完整智能体）： <ul> <li>尝试编写 SQL 查询</li> <li>运行并查看输出</li> <li>如果失败，迭代重试直到获得正确数据</li> </ul> </li> <li>步骤二：当且仅当步骤一确认成功后，才移交给下一个智能体</li> </ol> <blockquote> <p><strong>从”链接提示”演进到”链接智能体”</strong>——这是智能体架构的重要里程碑。</p> </blockquote> <h3 id="33-可观测性挑战与简单性原则">3.3 可观测性挑战与简单性原则</h3> <p><strong>复杂性带来的难题：</strong></p> <p>随着系统变得越来越复杂，<strong>可观测性</strong>会变得”非常困难”。</p> <p><strong>Erik 的核心建议：</strong></p> <blockquote> <p><strong>永远从最简单的方法开始，只有在绝对必要时才增加复杂性。</strong></p> </blockquote> <p><strong>推荐的渐进路径：</strong></p> <ol> <li><strong>第一步</strong>：尝试单次调用能否解决问题</li> <li><strong>第二步</strong>：使用 Claude Code SDK 等简单智能体循环</li> <li><strong>第三步</strong>：只有在简单方法无法满足需求时，才构建复杂的多层系统</li> </ol> <p>每增加一层复杂性，系统的可观测性就会变得更难。</p> <h3 id="34-多智能体系统并行的协作架构">3.4 多智能体系统：并行的协作架构</h3> <p><strong>智能体工作流 vs 多智能体：</strong></p> <table> <thead> <tr> <th>类型</th> <th>执行方式</th> <th>特点</th> </tr> </thead> <tbody> <tr> <td>智能体工作流</td> <td>串行（Sequential）</td> <td>一个智能体完成后传递给下一个</td> </tr> <tr> <td>多智能体</td> <td>并行（Parallel）</td> <td>多个智能体同时工作</td> </tr> </tbody> </table> <p><strong>多智能体的典型应用场景：</strong></p> <p><strong>场景一：并行委托</strong></p> <p>一个”父智能体”将任务委托给多个”子智能体”并行工作。</p> <p><strong>示例：Anthropic 的深度研究搜索产品</strong></p> <ul> <li>主”协调器”智能体决定创建几个子智能体</li> <li>子智能体同时执行大量搜索任务</li> <li>用户更快获得最终答案</li> </ul> <p><strong>场景二：上下文保护</strong></p> <p>主智能体将繁重的子任务外包给子智能体。</p> <p><strong>示例：代码库搜索</strong></p> <ul> <li>任务可能需要消耗数万个 token（在庞大代码库中查找）</li> <li>最终答案却很简短（文件名和行号）</li> <li>子智能体在自己的上下文中处理，只返回简短答案</li> <li>保护主智能体的上下文窗口</li> </ul> <h3 id="35-claude-学习成为管理者">3.5 Claude 学习成为”管理者”</h3> <p><strong>实现机制：</strong></p> <p>多智能体通过<strong>工具调用框架</strong>实现。对主智能体来说，子智能体就像一个可调用的”工具”。</p> <p><strong>Claude 的”管理挑战”：</strong></p> <p>Erik 目前的研究重点之一，是训练 Claude 成为更好的”管理者”。</p> <blockquote> <p><strong>Claude 会犯和人类”新手管理者”一样的错误。</strong></p> </blockquote> <p><strong>常见错误：</strong></p> <ul> <li>向子智能体提供不完整或含糊的指令</li> <li>错误地期望子智能体拥有和它一样的上下文背景</li> </ul> <p><strong>改进方向：</strong></p> <p>通过训练，Claude 开始：</p> <ul> <li>变得更啰嗦、更详细</li> <li>有意识地向子智能体提供任务的”整体背景”</li> <li>学习如何成为更称职的管理者</li> </ul> <hr/> <h2 id="四智能体开发者的核心最佳实践">四、智能体开发者的核心最佳实践</h2> <h3 id="41-保持简单按需增加复杂性">4.1 保持简单，按需增加复杂性</h3> <p><strong>首要原则：</strong></p> <blockquote> <p><strong>Start simple and make sure you only add complexity as you need.</strong></p> </blockquote> <p><strong>推荐路径：</strong></p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>单次调用 → 简单智能体循环（如 SDK） → 复杂多层系统
</code></pre></div></div> <p>智能体系统的可观测性非常困难，复杂架构会加剧这一难题。</p> <h3 id="42-采用智能体的视角换位思考">4.2 采用智能体的视角（换位思考）</h3> <p><strong>核心思维：</strong></p> <blockquote> <p><strong>从智能体的角度去思考，设身处地站在 Claude 的立场上。</strong></p> </blockquote> <p><strong>最有效的实践方法：</strong></p> <ol> <li>阅读智能体看到的原始日志</li> <li>查看它在工具调用中实际看到的信息</li> <li>问自己：”如果我是智能体，只看到这些信息，我真的有足够信息解决这个问题吗？”</li> </ol> <p><strong>关键认知：</strong></p> <p>开发者容易忘记——我们（人类）能看到一切，而模型”只看得到我们展示给它的东西”。</p> <h3 id="43-工具应映射-ui而非-api最重要">4.3 工具应映射 UI，而非 API（最重要）</h3> <p>这是 Erik 强调的<strong>最常见且最严重的错误观念</strong>。</p> <p><strong>错误观念 vs 正确心智：</strong></p> <table> <thead> <tr> <th>错误观念</th> <th>正确心智</th> </tr> </thead> <tbody> <tr> <td>工具应与后端 API 一一对应</td> <td>工具应与用户界面（UI）一一对应</td> </tr> </tbody> </table> <p><strong>核心原因：</strong></p> <p>模型（Claude）是工具的”用户”，它不像”传统程序”那样工作。</p> <p><strong>经典案例：Slack 对话理解</strong></p> <p><strong>错误方式：API 映射</strong></p> <p>后端有三个独立端点：</p> <ol> <li><code class="language-plaintext highlighter-rouge">load_slack_conversation()</code>：返回 user ID 和 channel ID</li> <li><code class="language-plaintext highlighter-rouge">turn_user_id_into_username()</code>：ID 转用户名</li> <li><code class="language-plaintext highlighter-rouge">turn_channel_id_into_channel_name()</code>：ID 转频道名</li> </ol> <p>如果提供这三个独立工具，智能体必须连续进行三次工具调用才能理解任何事情。<strong>极其低效。</strong></p> <p><strong>正确方式：UI 映射</strong></p> <p>反问：人类用户如何看待 Slack？</p> <p>我们看到的是”所有内容都已完美渲染好”的界面，不需要”点击用户 ID 来看他的名字”。</p> <p><strong>解决方案：</strong></p> <ul> <li>创建一个工具，一次性呈现所有信息</li> <li>需要尽可能少的交互</li> <li>在后台自己完成那三次 API 调用</li> <li>返回已经”渲染”好的、包含用户名和频道名的完整对话文本</li> </ul> <p><strong>核心思想：</strong></p> <blockquote> <p><strong>不要让智能体去做那些连你作为用户都会觉得”糟糕透顶”的、繁琐的交互操作。</strong></p> </blockquote> <hr/> <h2 id="五未来展望长程任务的自动交付">五、未来展望：长程任务的自动交付</h2> <h3 id="51-自我验证的闭环系统">5.1 自我验证的闭环系统</h3> <p>Erik 预测，智能体将变得更加普及，首先从”可验证”领域开始，比如软件工程。</p> <p><strong>当前状态：</strong></p> <ul> <li>开发者在智能体写完代码后，必须自己充当”QA 工程师”测试</li> </ul> <p><strong>未来突破：</strong></p> <ul> <li>智能体能够自己”封闭测试循环”</li> <li>不仅编写网络应用，还能自己打开、测试、找到自己的 Bug</li> <li>不再等待人类发现问题</li> </ul> <h3 id="52-计算机使用能力的革命性影响">5.2 计算机使用能力的革命性影响</h3> <p><strong>关键能力融合：</strong></p> <p>将”软件工程能力”与”计算机使用”(Computer Use) 能力相结合。</p> <p><strong>计算机使用的含义：</strong></p> <ul> <li>像人一样操作计算机</li> <li>滚动、点击、编辑文本</li> </ul> <p><strong>解锁的新场景：</strong></p> <p>一旦智能体掌握了这种能力，将解锁大量目前被”拒之门外”的领域。</p> <p><strong>具体案例：Google Doc 编辑</strong></p> <p><strong>现状：</strong></p> <ul> <li>在 Claude 界面和文档之间来回复制粘贴</li> </ul> <p><strong>未来：</strong></p> <ul> <li>直接说：”嘿 Claude，帮我清理一下这篇 Google Doc”</li> <li>Claude 直接在文档中操作：滚动、点击、编辑文本</li> </ul> <blockquote> <p><strong>“无论你在哪里，Claude 都能与你同在”</strong>——这将是截然不同的、更高效的交互体验。</p> </blockquote> <h3 id="53-从编码智能体到通用智能体">5.3 从编码智能体到通用智能体</h3> <p><strong>演进路径：</strong></p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>编码智能体 → 自我测试编码智能体 → 计算机使用智能体 → 通用自主智能体
</code></pre></div></div> <p>当智能体能够：</p> <ol> <li>理解任务需求</li> <li>编写代码实现</li> <li>自我测试验证</li> <li>操作任何软件界面</li> </ol> <p>它就真正成为了可以自主完成长程任务的通用智能体。</p> <hr/> <h2 id="结语从工具到伙伴的跃迁">结语：从工具到伙伴的跃迁</h2> <h3 id="核心要点回顾">核心要点回顾</h3> <p><strong>1. 编码能力是基础</strong></p> <ul> <li>强大的编码能力可以泛化到所有领域</li> <li>“先训练最难的”策略证明有效</li> </ul> <p><strong>2. 工具演进路径清晰</strong></p> <ul> <li>SDK 解决了基础架构问题</li> <li>Skills 提供了从指令到资源的跃迁</li> </ul> <p><strong>3. 架构复杂度需谨慎</strong></p> <ul> <li>从简单开始，按需增加复杂性</li> <li>可观测性随复杂度指数级下降</li> </ul> <p><strong>4. UI 映射原则至关重要</strong></p> <ul> <li>工具设计应模拟用户界面</li> <li>最小化智能体的交互次数</li> </ul> <h3 id="对开发者的启示">对开发者的启示</h3> <p><strong>构建智能体时的三个关键转变：</strong></p> <ol> <li><strong>思维转变</strong>：从”调用 API”到”模拟 UI”</li> <li><strong>架构转变</strong>：从”链接提示”到”链接智能体”</li> <li><strong>角色转变</strong>：从”编写代码”到”管理智能体”</li> </ol> <h3 id="通往未来的路径">通往未来的路径</h3> <p>当前的智能体开发仍处于早期阶段，但演进路径已经清晰：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>单一智能体 → 智能体工作流 → 多智能体系统 → 自主长程任务执行
</code></pre></div></div> <blockquote> <p><strong>最终目标不是替代人类开发者，而是让 AI 成为真正的协作伙伴。</strong></p> </blockquote> <p>当智能体能够理解你的意图、自主规划任务、执行并验证结果，我们就进入了一个全新的人机协作时代。这不是科幻，而是正在发生的现实。</p> <hr/> <p><strong>来源：</strong> Anthropic 官方播客<br/> <strong>整理：</strong> Anthropic 研究员深度解析 Claude 智能体构建方法论<br/> <strong>整理时间：</strong> 2025年11月6日</p>]]></content><author><name></name></author><category term="blog"/><summary type="html"><![CDATA[Anthropic 研究员详解：构建高效 Claude 智能体的完整方法论]]></summary></entry><entry><title type="html">Claude Code自定义命令在知识管理与内容创作中的系统化应用研究</title><link href="https://emigmo.github.io/blog/2025/claude-code-knowledge-management/" rel="alternate" type="text/html" title="Claude Code自定义命令在知识管理与内容创作中的系统化应用研究"/><published>2025-11-05T00:00:00+00:00</published><updated>2025-11-05T00:00:00+00:00</updated><id>https://emigmo.github.io/blog/2025/claude-code-knowledge-management</id><content type="html" xml:base="https://emigmo.github.io/blog/2025/claude-code-knowledge-management/"><![CDATA[<h1 id="claude-code自定义命令在知识管理与内容创作中的系统化应用研究">Claude Code自定义命令在知识管理与内容创作中的系统化应用研究</h1> <p><em>来源：知乎专栏</em><br/> <em>作者：郑二八斤</em><br/> <em>发布时间：2025-11-05</em><br/> <em>原文链接：https://zhuanlan.zhihu.com/p/1969435547006133543</em></p> <hr/> <h2 id="概述">概述</h2> <p>本文介绍了如何利用 Claude Code 的自定义命令能力，构建一个模块化、可迭代、数据驱动的知识管理与内容创作自动化系统。通过四周的实践，整体工作效率提升了 <strong>65%</strong>，从原来的 280 分钟缩短到 98 分钟。</p> <h2 id="核心问题">核心问题</h2> <p>在信息过载的时代，知识工作者面临的主要困境：</p> <ol> <li><strong>收集入口分散</strong>：灵感、会议纪要、阅读笔记散落在不同工具和格式中</li> <li><strong>整理规则不一致</strong>：标签体系混乱，笔记之间缺乏有效链接</li> <li><strong>创作流程重复</strong>：每次写作都要重复全流程，缺乏模板化和自动化</li> <li><strong>互动响应滞后</strong>：读者留言和私信堆积，响应不及时</li> <li><strong>迭代缺乏依据</strong>：缺少量化指标，无法评估工作流程的效率瓶颈</li> </ol> <h2 id="系统设计原则">系统设计原则</h2> <h3 id="1-单一职责原则">1. 单一职责原则</h3> <p>每个命令只负责一个具体任务，避免功能耦合</p> <h3 id="2-可组合性">2. 可组合性</h3> <p>命令之间可以串联组合，形成完整工作流（类似 Unix 管道）</p> <h3 id="3-数据驱动迭代">3. 数据驱动迭代</h3> <p>为每个命令建立量化评估指标，通过持续监测识别瓶颈并优化</p> <h2 id="系统架构">系统架构</h2> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>输入层：语音、文本、截图、链接
    ↓
  /daylog
    ↓
处理层：
  ├─ 调研层：/research-snap
  ├─ 规划层：/topic-outline
  └─ 生成层：/content-draft
    ↓
输出层：/reply-kit
    ↓
存储层：Daily/、Topics/、Projects/
    ↓
反馈层：数据统计、命令优化
</code></pre></div></div> <h2 id="核心命令详解">核心命令详解</h2> <h3 id="1-daylog---知识捕获">1. /daylog - 知识捕获</h3> <p><strong>理论基础</strong>：Zettelkasten（卡片盒）方法<br/> <strong>功能</strong>：将日常笔记、灵感自动整理为结构化笔记，建立知识网络<br/> <strong>效果</strong>：</p> <ul> <li>知识捕获时间：20分钟 → 2分钟（-90%）</li> <li>笔记交叉链接：1.2个 → 4.8个（+300%）</li> </ul> <p>配置文件：<a href="./commands/daylog.md">daylog.md</a></p> <h3 id="2-research-snap---知识综合">2. /research-snap - 知识综合</h3> <p><strong>理论基础</strong>：循证决策（Evidence-Based Decision Making）<br/> <strong>功能</strong>：快速收集和整理研究材料，结构化引用<br/> <strong>效果</strong>：</p> <ul> <li>调研时间：30分钟 → 5分钟（-83%）</li> <li>引用数量：2-3个 → 8-12个（+300%）</li> <li>引用完整度：50% → 100%</li> </ul> <p>配置文件：<a href="./commands/research-snap.md">research-snap.md</a></p> <h3 id="3-topic-outline---结构设计">3. /topic-outline - 结构设计</h3> <p><strong>理论基础</strong>：认知负荷理论（Cognitive Load Theory）<br/> <strong>功能</strong>：根据不同平台（微信、小红书、知乎）生成优化的内容大纲<br/> <strong>效果</strong>：</p> <ul> <li>大纲规划时间：40分钟 → 5分钟（-87%）</li> <li>文章完读率：42% → 53%（+26%）</li> <li>互动率：3.2% → 4.8%（+50%）</li> </ul> <p>配置文件：<a href="./commands/topic-outline.md">topic-outline.md</a></p> <h3 id="4-content-draft---内容生成">4. /content-draft - 内容生成</h3> <p><strong>理论基础</strong>：Flower &amp; Hayes 写作认知过程模型<br/> <strong>功能</strong>：将大纲和调研材料转化为完整初稿<br/> <strong>效果</strong>：</p> <ul> <li>初稿撰写时间：120分钟 → 60分钟（-50%）</li> <li>引用遗漏率：20% → 5%（-75%）</li> </ul> <p>配置文件：<a href="./commands/content-draft.md">content-draft.md</a></p> <h3 id="5-reply-kit---互动管理">5. /reply-kit - 互动管理</h3> <p><strong>理论基础</strong>：共情沟通（Empathetic Communication）<br/> <strong>功能</strong>：快速生成高质量的读者回复<br/> <strong>效果</strong>：</p> <ul> <li>回复时间（10条）：30分钟 → 6分钟（-80%）</li> <li>二次互动率：12% → 28%（+133%）</li> </ul> <p>配置文件：<a href="./commands/reply-kit.md">reply-kit.md</a></p> <h2 id="工作流程示例">工作流程示例</h2> <h3 id="完整创作流程">完整创作流程</h3> <pre><code class="language-mermaid">graph TB
    A[灵感/素材收集] --&gt;|/daylog| B[结构化日记]
    B --&gt; C[选题确认]
    C --&gt;|/research-snap| D[调研报告]
    D --&gt;|/topic-outline| E[内容大纲]
    E --&gt;|/content-draft| F[初稿]
    F --&gt; G[人工审阅优化]
    G --&gt; H[发布]
    H --&gt; I[读者反馈]
    I --&gt;|/reply-kit| J[互动回复]
    J --&gt; K[数据复盘]
    K --&gt; A
</code></pre> <h3 id="效率对比">效率对比</h3> <table> <thead> <tr> <th>工作环节</th> <th>优化前</th> <th>优化后</th> <th>提升幅度</th> </tr> </thead> <tbody> <tr> <td>灵感捕获与整理</td> <td>20分钟</td> <td>2分钟</td> <td>-90%</td> </tr> <tr> <td>调研资料整合</td> <td>30分钟</td> <td>5分钟</td> <td>-83%</td> </tr> <tr> <td>大纲规划</td> <td>40分钟</td> <td>5分钟</td> <td>-87%</td> </tr> <tr> <td>初稿撰写</td> <td>120分钟</td> <td>60分钟</td> <td>-50%</td> </tr> <tr> <td>审阅修改</td> <td>40分钟</td> <td>20分钟</td> <td>-50%</td> </tr> <tr> <td>留言回复(10条)</td> <td>30分钟</td> <td>6分钟</td> <td>-80%</td> </tr> <tr> <td><strong>总计</strong></td> <td><strong>280分钟</strong></td> <td><strong>98分钟</strong></td> <td><strong>-65%</strong></td> </tr> </tbody> </table> <h2 id="roi-分析">ROI 分析</h2> <p><strong>初始投入</strong>：16小时（学习2h + 设计8h + 测试6h）<br/> <strong>每周收益</strong>：3小时<br/> <strong>回本周期</strong>：约5.3周<br/> <strong>年收益</strong>：156小时（约15,600元，按时薪100元计算）<br/> <strong>ROI</strong>：875%</p> <h2 id="适用场景">适用场景</h2> <h3 id="高度适用-">高度适用 ⭐⭐⭐⭐⭐</h3> <ul> <li>内容创作者（公众号运营、博主、自媒体）</li> <li>知识工作者（研究员、咨询顾问、产品经理）</li> <li>个人知识管理需求者</li> </ul> <h3 id="适度适用-">适度适用 ⭐⭐⭐</h3> <ul> <li>团队协作（需要统一输出标准）</li> <li>教育场景（教学素材整理、学习笔记）</li> </ul> <h3 id="不适用-">不适用 ⭐</h3> <ul> <li>高度创意性工作（纯艺术创作、原创性学术研究）</li> <li>实时性要求极高的场景（新闻报道）</li> <li>需要深度人际互动的场景（心理咨询）</li> </ul> <h2 id="系统局限性">系统局限性</h2> <ol> <li><strong>依赖明确的规则</strong>：任务缺乏明确标准时，输出质量下降</li> <li><strong>初期学习成本</strong>：前两周需要频繁调整，学习曲线较陡</li> <li><strong>创造性天花板</strong>：AI倾向于生成”安全”但平庸的内容</li> <li><strong>上下文窗口限制</strong>：超长内容可能遗漏部分信息</li> <li><strong>成本考量</strong>：频繁调用API会产生费用</li> </ol> <h2 id="快速开始">快速开始</h2> <h3 id="1-创建命令目录">1. 创建命令目录</h3> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">mkdir</span> <span class="nt">-p</span> .claude/commands
</code></pre></div></div> <h3 id="2-配置命令文件">2. 配置命令文件</h3> <p>将本目录下 <code class="language-plaintext highlighter-rouge">commands/</code> 中的5个命令文件复制到项目的 <code class="language-plaintext highlighter-rouge">.claude/commands/</code> 目录</p> <h3 id="3-验证配置">3. 验证配置</h3> <ul> <li>打开 Cursor</li> <li>在聊天框输入 <code class="language-plaintext highlighter-rouge">/</code></li> <li>查看是否显示自定义命令</li> <li>测试运行</li> </ul> <h2 id="进阶优化">进阶优化</h2> <h3 id="数据追踪表格示例">数据追踪表格示例</h3> <table> <thead> <tr> <th>日期</th> <th>命令</th> <th>耗时</th> <th>质量</th> <th>需优化点</th> <th>优化措施</th> </tr> </thead> <tbody> <tr> <td>11-05</td> <td>/daylog</td> <td>2min</td> <td>4.5/5</td> <td>链接推荐精准度</td> <td>增加语义相似度阈值</td> </tr> <tr> <td>11-05</td> <td>/research-snap</td> <td>5min</td> <td>5/5</td> <td>完美</td> <td>-</td> </tr> </tbody> </table> <h3 id="扩展命令建议">扩展命令建议</h3> <p><strong>垂直领域定制</strong>：</p> <ul> <li><code class="language-plaintext highlighter-rouge">/legal-research</code>：法律领域调研</li> <li><code class="language-plaintext highlighter-rouge">/academic-paper</code>：学术论文生成</li> <li><code class="language-plaintext highlighter-rouge">/product-spec</code>：产品需求文档</li> </ul> <p><strong>工作流程深化</strong>：</p> <ul> <li><code class="language-plaintext highlighter-rouge">/taxonomy-audit</code>：标签一致性检查</li> <li><code class="language-plaintext highlighter-rouge">/content-repurpose</code>：多平台改写</li> <li><code class="language-plaintext highlighter-rouge">/seo-optimizer</code>：SEO优化建议</li> </ul> <h2 id="核心发现总结">核心发现总结</h2> <ol> <li><strong>自动化收益与任务重复性正相关</strong>：重复性高的任务自动化收益最大（80-90%）</li> <li><strong>质量提升与标准化程度正相关</strong>：有明确标准的任务质量提升显著（30-40%）</li> <li><strong>系统价值呈现网络效应</strong>：多个命令组合形成工作流网络时，价值呈指数级增长</li> <li><strong>人机协作优于纯AI或纯人工</strong>：”AI生成初稿+人工审阅优化”的模式最优</li> </ol> <h2 id="参考资料">参考资料</h2> <ul> <li>Zettelkasten方法：Niklas Luhmann的卡片盒笔记法</li> <li>认知负荷理论：Sweller, 1988</li> <li>写作认知过程模型：Flower &amp; Hayes, 1981</li> <li>循证决策理论：Evidence-Based Decision Making</li> </ul> <h2 id="讨论话题">讨论话题</h2> <ol> <li>当AI接管重复性任务后，如何避免创造性思考能力的退化？</li> <li>在追求效率和标准化的过程中，如何保持内容的个性和独特性？</li> <li>在知识管理中，工具选择重要还是系统设计重要？</li> <li>如何评估自动化系统的长期价值？</li> <li>这套系统在团队协作场景中的应用有哪些挑战和机遇？</li> </ol> <hr/> <h2 id="文件结构">文件结构</h2> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>2025-11-05-claude-code-knowledge-management/
├── README.md                    # 本文档
└── commands/                    # 命令配置文件
    ├── daylog.md               # 知识捕获命令
    ├── research-snap.md        # 知识综合命令
    ├── topic-outline.md        # 结构设计命令
    ├── content-draft.md        # 内容生成命令
    └── reply-kit.md            # 互动管理命令
</code></pre></div></div>]]></content><author><name></name></author><category term="blog"/><summary type="html"><![CDATA[Claude Code自定义命令在知识管理与内容创作中的系统化应用研究]]></summary></entry><entry><title type="html">18个改变人生的习惯：科学证据支持的长期主义指南</title><link href="https://emigmo.github.io/blog/2025/habit/" rel="alternate" type="text/html" title="18个改变人生的习惯：科学证据支持的长期主义指南"/><published>2025-11-01T00:00:00+00:00</published><updated>2025-11-01T00:00:00+00:00</updated><id>https://emigmo.github.io/blog/2025/habit</id><content type="html" xml:base="https://emigmo.github.io/blog/2025/habit/"><![CDATA[<h1 id="18个改变人生的习惯科学证据支持的长期主义指南">18个改变人生的习惯：科学证据支持的长期主义指南</h1> <p><em>整理时间：2025年11月1日</em> <em>内容来源：综合研究整理</em></p> <hr/> <h2 id="前言">前言</h2> <blockquote> <p><strong>「复利效应在人生各个维度都存在，但只有极少数人能坚持足够久。」</strong></p> </blockquote> <p>本文汇总了18个经过科学验证、能够显著提升生活质量的长期习惯。这些习惯涵盖健康、学习、财富、人际关系四个核心维度，每一个都有权威研究支持，且具备可操作性。</p> <p>真正的改变不在于某一天的大动作，而在于每一天的微小坚持。</p> <hr/> <h2 id="一健康基石身心健康是一切的根基">一、健康基石：身心健康是一切的根基</h2> <h3 id="1-每天运动30分钟--exercise-for-30-minutes-every-day">1. 每天运动30分钟 | Exercise for 30 minutes every day</h3> <p>《柳叶刀》研究显示，每天30分钟中等强度运动可降低27%全因死亡率，相当于每运动1分钟延长寿命7分钟。</p> <p><strong>科学机制</strong>：运动时身体会分泌脑源性神经营养因子（BDNF），促进大脑神经元生长，提高记忆力和专注力。</p> <p><strong>实践建议</strong>：</p> <ul> <li>选择快走、游泳等可持续性运动</li> <li>配合2-3次/周的力量训练效果更佳</li> </ul> <h3 id="2-保证7小时睡眠--ensure-7-hours-of-sleep">2. 保证7小时睡眠 | Ensure 7 hours of sleep</h3> <p>哈佛医学院研究发现，持续睡眠不足6小时的人群，肥胖风险增加30%，记忆力下降40%。</p> <p><strong>科学机制</strong>：深度睡眠阶段大脑会进行”记忆整理”，清除β淀粉样蛋白（阿尔茨海默病的致病蛋白）。</p> <p><strong>实践建议</strong>：</p> <ul> <li>设置固定作息时间</li> <li>睡前1小时避免蓝光刺激</li> <li>室温控制在18-22℃最佳</li> </ul> <h3 id="3-定期口腔护理--regular-oral-care">3. 定期口腔护理 | Regular oral care</h3> <p>WHO数据显示，牙周病患者心脏病风险是普通人的2倍，糖尿病风险增加3倍。每年洗牙可预防牙龈萎缩，节省后续数万元的种植牙费用。</p> <p><strong>实践建议</strong>：</p> <ul> <li>使用含氟牙膏+巴氏刷牙法</li> <li>配合冲牙器清理牙缝</li> <li>每半年进行一次专业洁治</li> </ul> <h3 id="4-冥想训练--meditation-training">4. 冥想训练 | Meditation Training</h3> <p>哈佛医学院脑扫描显示，每日冥想10分钟，8周后杏仁核（焦虑中枢）缩小19%。</p> <p><strong>实践建议</strong>：</p> <ul> <li>从呼吸冥想入门，逐步练习身体扫描等技巧</li> <li>使用潮汐APP引导</li> <li>选择固定时段练习效果更佳</li> </ul> <hr/> <h2 id="二持续学习终身学习是核心竞争力">二、持续学习：终身学习是核心竞争力</h2> <h3 id="5-每周深度阅读10小时--10-hours-of-in-depth-reading">5. 每周深度阅读10小时 | 10 hours of in-depth reading</h3> <p>耶鲁大学长达12年的追踪研究表明，每周阅读3.5小时书籍的人群平均寿命延长23个月。</p> <p><strong>科学机制</strong>：深度阅读时大脑的默认模式网络(DMN)会被激活，提升同理心和决策能力。</p> <p><strong>实践建议</strong>：</p> <ul> <li>选择纸质书减少干扰</li> <li>配合康奈尔笔记法记录重点</li> </ul> <h3 id="6-掌握第二语言--mastering-a-second-language">6. 掌握第二语言 | Mastering a second language</h3> <p>《神经科学》期刊研究发现，双语使用者老年痴呆症发病时间平均延迟4.5年。</p> <p><strong>科学机制</strong>：语言学习能增加大脑灰质密度，LinkedIn数据显示掌握双语者薪资溢价达15-20%。</p> <p><strong>实践建议</strong>：</p> <ul> <li>使用沉浸式学习法</li> <li>每天30分钟结合影视剧/播客输入</li> </ul> <h3 id="7-刻意练习写作--deliberately-practicing-writing">7. 刻意练习写作 | Deliberately practicing writing</h3> <p>斯坦福大学写作项目显示，定期写作的人职业晋升速度快37%。</p> <p><strong>核心价值</strong>：写作能梳理思维盲点，自媒体时代更是个人品牌放大器。</p> <p><strong>实践建议</strong>：</p> <ul> <li>从每天300字日记开始</li> <li>逐步尝试观点文、产品文案等不同体裁</li> </ul> <h3 id="8-建立错题本--establish-a-mistake-book">8. 建立错题本 | Establish a mistake book</h3> <p>剑桥大学研究证实，定期复盘错误的学习者，知识保留率比普通学习者高65%。</p> <p><strong>实践建议</strong>：</p> <ul> <li>用电子笔记记录职场/生活中的重大失误</li> <li>每月分析1次共同模式，制定改进方案</li> </ul> <h3 id="9-掌握ai工具链--master-the-ai-toolchain">9. 掌握AI工具链 | Master the AI toolchain</h3> <p>麦肯锡最新报告指出，熟练使用AI工具的职场人生产效率提升40%，被自动化取代风险降低73%。</p> <p><strong>实践建议</strong>：</p> <ul> <li>每月掌握1个新工具</li> <li>如ChatGPT提示词工程、Midjourney视觉生成、Notion AI知识管理等</li> </ul> <hr/> <h2 id="三财富积累理性规划与长期投资">三、财富积累：理性规划与长期投资</h2> <h3 id="10-系统学习理财--systematic-learning-of-financial-management">10. 系统学习理财 | Systematic learning of financial management</h3> <p>诺贝尔经济学奖得主马科维茨证实，合理资产配置可降低30%风险并提高15%收益。</p> <p><strong>实践建议</strong>：</p> <ul> <li>按”4321法则”分配资金：40%投资+30%生活+20%储蓄+10%保险</li> <li>从指数基金定投开始，逐步学习企业财报分析等技能</li> </ul> <h3 id="11-每月定投指数基金--monthly-fixed-investment-index-fund">11. 每月定投指数基金 | Monthly fixed investment index fund</h3> <p>沃顿商学院研究显示，定投标普500指数20年以上的投资者，93%跑赢主动管理基金。</p> <p><strong>核心优势</strong>：指数基金费率仅0.03%-0.15%，避免了个股暴雷风险。</p> <p><strong>实践建议</strong>：</p> <ul> <li>设置工资到账自动扣款</li> <li>采用”低估多买、高估持有”策略</li> </ul> <h3 id="12-购置核心资产--purchase-core-assets">12. 购置核心资产 | Purchase core assets</h3> <p>诺贝尔经济学奖得主席勒研究表明，核心地段房产长期回报率跑赢通胀3-5%。</p> <p><strong>实践建议</strong>：</p> <ul> <li>首套房建议选择”交通+学区+商业”至少占两项的物业</li> <li>面积控制在90-120㎡流动性最佳</li> <li>避免过度装修，硬装预算控制在2000元/㎡以内</li> </ul> <h3 id="13-发展副业收入--developing-sideline-income">13. 发展副业收入 | Developing sideline income</h3> <p>Upwork调研显示，拥有多重收入的职场人抗风险能力提高5倍。</p> <p><strong>实践建议</strong>：</p> <ul> <li>在保持主业的同时，从技能型副业起步（咨询/设计/写作）</li> <li>逐步建立”睡后收入”系统</li> <li>副业收入达到主业30%时再考虑辞职</li> </ul> <hr/> <h2 id="四人际关系与心理建设软实力决定上限">四、人际关系与心理建设：软实力决定上限</h2> <h3 id="14-维护关键人脉--maintain-key-networks">14. 维护关键人脉 | Maintain key networks</h3> <p>LinkedIn数据显示，85%的高薪职位通过弱关系（朋友的朋友）获得。</p> <p><strong>实践建议</strong>：</p> <ul> <li>每月至少联系1位优质人脉</li> <li>采用”价值分享+适度求助”的维护策略</li> <li>见面时准备3个有深度的话题，避免单纯的寒暄</li> </ul> <h3 id="15-学习非暴力沟通--learning-nonviolent-communication">15. 学习非暴力沟通 | Learning Nonviolent Communication</h3> <p>心理学家马歇尔研究发现，采用”观察-感受-需要-请求”沟通模式，能提升83%的矛盾解决率。</p> <p><strong>关键技巧</strong>：</p> <ul> <li>用”我注意到”代替”你总是”</li> <li>提出具体请求而非模糊要求</li> </ul> <h3 id="16-培养感恩心态--cultivate-a-grateful-mindset">16. 培养感恩心态 | Cultivate a grateful mindset</h3> <p>《积极心理学杂志》实验显示，持续6周感恩练习可使抑郁症状减少28%。</p> <p><strong>实践建议</strong>：</p> <ul> <li>每晚记录3件值得感恩的小事</li> <li>定期向帮助过自己的人表达感谢</li> <li>感恩日记最好手写，激活大脑情感中枢更充分</li> </ul> <h3 id="17-培养幽默感--cultivate-a-sense-of-humor">17. 培养幽默感 | Cultivate a sense of humor</h3> <p>《人格与社会心理学》杂志指出，幽默感强的人抗压能力提升40%，人际关系质量提高58%。</p> <p><strong>实践建议</strong>：</p> <ul> <li>每天收集3个幽默素材（段子/趣图）</li> <li>在社交场合适时���用</li> </ul> <hr/> <h2 id="五人生哲学建立可持续的行动框架">五、人生哲学：建立可持续的行动框架</h2> <h3 id="18-设置人生基准线--set-a-life-baseline">18. 设置人生基准线 | Set a life baseline</h3> <p>斯坦福大学建议设立不可妥协的底线标准（如每日阅读30分钟/每周运动3次）。</p> <p><strong>核心理念</strong>：当状态低迷时，优先完成基准线任务即可，避免陷入”全有或全无”的极端思维。</p> <p><strong>实践价值</strong>：基准线思维能帮助我们在低谷期维持最小化进展，避免彻底放弃导致的习惯断裂。</p> <hr/> <h2 id="结语">结语</h2> <p>这18个习惯不是要求你立刻全部开始，而是提供一个可选择的清单。建议：</p> <ol> <li><strong>先选择3个最适合当前阶段的习惯</strong></li> <li><strong>用21天建立初步习惯，90天固化为自然行为</strong></li> <li><strong>每季度复盘一次，逐步增加新习惯</strong></li> </ol> <p>记住：<strong>真正的成长，是在时间的复利下，一点点积累出来的。</strong></p>]]></content><author><name></name></author><category term="blog"/><summary type="html"><![CDATA[18个改变人生的习惯：科学证据支持的长期主义指南]]></summary></entry><entry><title type="html">KIMI创始人杨植麟深度访谈：攀登无限之山</title><link href="https://emigmo.github.io/blog/2025/kimi-yang-dialogue/" rel="alternate" type="text/html" title="KIMI创始人杨植麟深度访谈：攀登无限之山"/><published>2025-10-23T00:00:00+00:00</published><updated>2025-10-23T00:00:00+00:00</updated><id>https://emigmo.github.io/blog/2025/kimi-yang-dialogue</id><content type="html" xml:base="https://emigmo.github.io/blog/2025/kimi-yang-dialogue/"><![CDATA[<h1 id="kimi创始人杨植麟深度访谈攀登无限之山">KIMI创始人杨植麟深度访谈：攀登无限之山</h1> <p><em>主持人：张小珺</em><br/> <em>时间：2025年7月</em><br/> <em>地点：北京知春路京东科技大厦13层</em></p> <hr/> <h2 id="目录">目录</h2> <h3 id="第一章-一座无限的山">第一章 一座无限的山</h3> <ul> <li><a href="#01-the-beginning-of-infinity">01 The Beginning of Infinity - 无穷的开始</a></li> <li><a href="#02-它还是一个缸中之脑">02 它还是一个”缸中之脑”</a></li> <li><a href="#03-l1到l5不一定是串行关系">03 L1到L5不一定是串行关系</a></li> </ul> <h3 id="第二章-k2是乔戈里峰">第二章 K2是乔戈里峰</h3> <ul> <li><a href="#04-喂一样多的数据脑子长得更多">04 喂一样多的数据，”脑子”长得更多</a></li> <li><a href="#05-muon你去训的时候它会炸">05 Muon你去训的时候，它会炸</a></li> <li><a href="#06-当从缸中之脑变成跟世界交互的系统">06 当从”缸中之脑”变成跟世界交互的系统</a></li> </ul> <h3 id="第三章-既简单又复杂的系统">第三章 既简单又复杂的系统</h3> <ul> <li><a href="#07-开源-vs-闭源">07 开源 vs 闭源</a></li> <li><a href="#08-多模态不损伤脑子已经很好了">08 多模态不损伤”脑子”已经很好了</a></li> <li><a href="#09-当你通过新的交互收集的信号噪声减少">09 当你通过新的交互，收集的信号噪声减少</a></li> <li><a href="#10-long-context架构会影响智商">10 Long Context架构会影响”智商”</a></li> <li><a href="#11-边界与现实">11 边界与现实</a></li> </ul> <h3 id="第四章-在自己的故事里面">第四章 在自己的故事里面</h3> <ul> <li><a href="#12-用rl的方式去管理而不是用sft">12 用RL的方式去管理，而不是用SFT</a></li> <li><a href="#13-ai是人类文明的放大器">13 AI是人类文明的放大器</a></li> <li><a href="#14-任何中间状态都有可能成为被批评的对象">14 任何中间状态都有可能成为被批评的对象</a></li> </ul> <hr/> <h2 id="第一章-一座无限的山-1">第一章 一座无限的山</h2> <h3 id="01-the-beginning-of-infinity">01 The Beginning of Infinity</h3> <p>张小珺：在你创业第一年结束的时候，2024年我们访谈标题是《向延绵而未知的雪山前进》。现在又过了一年，站在此刻，2025年7月，你最新的感受是怎样的？</p> <p>杨植麟：你刚刚提到这个词，我感觉好像过了很久……AI一天，人间一年。AI的一年我不知道是人间多少天。确实很多东西发生了变化，但你说的”雪山的感觉”，倒是差不太多。</p> <p>往山顶方向，我们又走了一段距离。</p> <p>张小珺：现在行进到哪里了？</p> <p>杨植麟：站在现在看，模型的进步挺大——两年前写一篇文章都写不太明白，现在不光可以写很好的文章，还能连续工作几小时，帮你完成一个很复杂的代码任务。这在两年前很难想象。</p> <p>在爬雪山的过程中，解锁了一些新的场景，大概知道中间这条路是什么样的；但同时，在往上的过程中，你还是观察到类似的景象——接下来，仍然会有很多未知的技术问题要去解决。</p> <p>张小珺：在四下都是大雪的山峰上，你是更清晰了，还是更迷惘了？</p> <p>杨植麟：肯定会有很多东西变得更清楚。两年前各种强化学习（RL，Reinforcement Learning）的范式该怎么做，怎么让模型有更强的推理能力，或更强的Agentic（智能体式）能力，当时都没那么清楚。那时更多关注模型的预训练（Pre-Training）怎么做得更好，怎么用RLHF（Reinforcement Learning from Human Feedback，人类反馈强化学习）提升对话体验。</p> <p>但现在有一些问题得到了答案，同时这些答案又展开，带来了新的其他问题。</p> <p>现在虽然可以做强化学习，但它最终还是依赖一个很好的评估或验证机制。你让模型去做一道数学题，或者做一些有test case（测试样例）的编程任务，可能做得比较好。但如果让它去做一个更复杂的端到端任务，有时很难找到一个合适的评估或衡量方式。所以，这个系统又会产生新的问题。</p> <p>这有点像我最近在看的一本书，叫The Beginning of Infinity（无穷的开始），我看了好几遍。书中说，有两句话可以刻在石头上：一句是”问题是不可避免的”，另一句是”问题是可以解决的”。</p> <p>《无穷的开始》（The Beginning of Infinity）是物理学家David Deutsch撰写的一本科普哲学著作。</p> <p><strong>书中观点</strong>：科学知识和理性探究能带来无限的进步和理解，世界上的问题无穷无尽，但绝大多数问题都可以通过理性思考和科学方法得到解决。知识的增长无界限，科学探索是一个不断解决问题、产生新问题的过程，这是人类文明不断前进的动力。</p> <p>你可以认为，启蒙运动前，这个社会是静态的。大家不追求创新，会用很多神秘主义来解释所看到的现象，但这些解释并不是好的解释。比如，你看到天上打雷，会觉得雷公在发怒；你看到冬天下雪，会说某个神心情不好——整个社会结构是静态的，只有极少数人在真正做科学研究或知识创造。</p> <p>但启蒙运动之后，社会变成了动态的，新的知识不断被创造。每当你解决一个问题，就会带来新的问题。问题是源源不断的，因为你的知识边界在拓展，你就会遇到新的问题。</p> <p>现在做AI研发也恰好处于这样的状态。你解决了强化学习的一些问题，接下来就遇到评估、衡量、验证这些问题，又需要我们寻找新的答案。</p> <p>但这也正是它有意思的地方——你总是会有新的问题去解决，而每当你解决一个问题，技术就能再往上攀登几百米。</p> <p>也许有一天会发现，这座雪山没有尽头——我不知道——我希望它一直没有尽头。</p> <p>The Beginning of Infinity的意思就是这样：</p> <p>它是一座无限的山。</p> <h3 id="02-它还是一个缸中之脑">02 它还是一个”缸中之脑”</h3> <p>张小珺：我们回望一下，过去一年全球大模型在你脑海中最重要的几件事是什么？有哪些是人工智能范式级的变化？</p> <p>杨植麟：一个是长思考的推理模型（Reasoning Model），以o1作为第一个做出来的代表。本质上，它通过让模型在过程中做很多尝试和反思，反思是其中的重点。</p> <p>反思是两种能力：一种是提出新的猜想，一种是验证猜想。</p> <p>你可以理解为：模型在解决问题的过程中，会不断提出新的猜想，这个猜想会得到自我验证。比如，它提出这个猜想之后，要判断是对是错，需要具备一定的验证能力。虽然你不是显式地训练一个验证模型，但它在推理过程中隐式地进行了验证。它对这个问题做了多次猜想和验证，最后得到一个答案。</p> <p>这大大提升了模型的能力。你本来只能做一次，直接给出一个答案，这个答案可能对，也可能错，你没有这个过程。但现在你可以不断提出猜想去验证，相当于等价尝试了好几次。</p> <p>你可以把Pass@k变成Pass@1，本质是这样的道理。</p> <p><strong>Pass@k</strong>：用于评估大模型的一种指标，表示模型在一次任务中生成k个候选答案时，至少有一个答案正确的概率。</p> <p>这跟人做科研或解题的过程很像，不断提出新的猜想，然后验证它。</p> <p>张小珺：是一个自由探索的过程，而不是一个线性的过程。</p> <p>杨植麟：它有效的工作方式，很多时候还是比较线性的。如果不考虑并行采样，假设做的是串行采样，它就是线性过程。</p> <p>你每次提出新的猜想，这个猜想可能基于之前的猜想，甚至是你已经否定过的猜想，再提出一个新的猜想。它会接近更线性的过程。</p> <p>现在你也可以把线性过程和并行策略搭配，比如同时采样很多个，结合了并行和串行两种方式。最近也有一些paper讲串行采样上限更高，这跟我们的实验结论一致。</p> <p>上面说的是一种范式，但它还是一个“缸中之脑”（brain in a vat），并不需要跟外界交互。</p> <p>张小珺：缸中之脑？</p> <p>杨植麟：想象一个鱼缸，你把一个脑子放在里面，跟外界没有联系。它只是在自己大脑里面想，一直想，不需要跟外界产生任何交互，就能解一道题。</p> <p>但有另一个很重要的范式，就是基于多轮的Agent（智能体）强化学习范式，或者通过强化学习技术训练出来的Agentic模型，它的特点是会跟外界做很多交互。</p> <p>比如我边思考边去做一些操作，可能做很多轮操作，一会儿调用一个搜索，一会儿使用一下浏览器，一会儿写几行代码，通过多轮解决一个问题。</p> <p>它就不再是“缸中之脑”，是跟外界有交互的——我的下一步行为，是根据交互中得到的反馈，和外界给我的新状态的更新有关系。</p> <p>但这两个东西都指向了同一个东西，是：test-time scaling（测试时扩展）。意思是，可以在测试时，或者在推理时，做到更好的规模化。</p> <p>比如之前做Chat（聊天），更多是单轮地输出一个结果：我让你写一篇文章，你就写一篇文章；我再让你润色一下，你又输出几百个token（词元），这个token数量是很少的。但不管是基于长思考的强化学习，还是Agent的强化学习，本质上都是一种在预测时对token进行规模化扩展的方式。</p> <p>你不管是把轮数打得更多，还是在每一轮有更多思考的token，都是一种规模化token的方法，让你能完成更复杂的任务。</p> <p>这也伴随完成时间更长。你现在花几小时去做一件复杂的事，过程中不需要人工参与。比如，把一个代码仓库克隆下来，翻译成另一种新语言，调试、测试，把所有bug（漏洞）修复，让它能正常运行。这样的工作可以端到端完成，得益于测试时计算（test-time）的规模化。</p> <p>还有一个很有意思的趋势是，现在有更多模型公司去做“一方的Agent产品”。</p> <p><strong>“一方的Agent产品”</strong>：指模型公司自己下场做产品，自己控制上下文环境、工具接口、prompt结构等，也就是自己当”使用方”，而不是只给别人提供模型API。 一开始，我们看半年前或者去年，很多产品是基于基础模型，你在上面搭一些脚手架，或者设计一些工具去更好地让模型使用，从而搭建一个产品。 张小珺：享受模型溢出的能力。 杨植麟：对，它本质做的是逆向工程这个模型的训练过程。因为模型训练过程也是通过各种手段——你可以认为Anthropic在内部（in-house）的环境、工具、脚手架，可能训练出这样一个模型，但它没有直接开放给你。</p> <p>你通过逆向，更接近拟合它的分布——到底用什么工具效果会好？到底用什么样的System Prompt（系统提示）效果会好？到底用什么样的Context Engineering（上下文工程）效果会好？这是一个逆向的过程。</p> <p>但你会发现，如果模型公司去做“一方的产品”，逻辑完全不一样。</p> <p>你不再需要这个逆向的过程，更多是正向的做法。我先把这些工具设计好，我的Context Engineering（上下文工程）的方法都设计好，我就在这个环境里训练这个模型，所以模型天然在你的环境里表现更好。</p> <p>这是两种不同思路，但第二种思路上限也许更高。</p> <p>你可以更好整合工具和模型。模型如果有些地方解决不好，你可以调整工具设计，把它设计得更好，同时又可以端到端训练。这也是在开发方式一个比较大的变量。</p> <p>张小珺：让大家比较好理解。第一种你说的脚手架，就是像Manus这种开发方式；第二种是你们这样的端到端训练模型的方式。</p> <p>杨植麟：对。当然，我们现在在“一方产品”投入还不算特别多，是以模型为主线。但Claude Code或ChatGPT Agent，就是“一方的产品”，应该也会是一个很大趋势。</p> <p>后面就看“一方”和“三方”产品怎么配合，在生态里会是什么样的状态。</p> <h3 id="03-l1到l5不一定是串行关系">03 L1到L5不一定是串行关系</h3> <p>张小珺：说到主线，OpenAI设置了从L1到L5的分级，我一直很好奇它背后的内在逻辑。</p> <p>L1是Chatbot（聊天机器人），L2是Reasoner（推理者），L3是Agent（智能体），L4是Innovator（创新者），L5是Organizer（组织者）。</p> <p>为什么是在有了Chatbot和Reasoner之后才有Agent？为什么接下来又是Innovator和Organizer？这个顺序在能力结构上是怎样递进的？</p> <p>杨植麟：它是能力一步一步的依赖。Agent的（L3）上限取决于，你有很强的Reasoning（L2、推理）能力，但并不是必须先有Reasoning。</p> <p>假设我们把技术发展的顺序稍微换一下，你先做出来Agent能力，再去做狭义的Reasoning，就是long CoT（长链式思维）的Reasoning，可能也是成立的。</p> <p>你可以认为Claude的路线就是bet（押注）这一点：它在Reasoning上做得不是特别多，但在Agent上做得非常好。这背后是不同技术路径的bet（押注）。但最终你绕不开，如果你想往山顶再多爬几步，这两个能力都要有，只是时间问题。</p> <p>所以，他们并不一定是互相依赖的。不是非得先做Reasoning再做Agent。但要做到最好的Agent，就必须把Reasoning也做到最好。而有了Agent的能力，就可以去做后面的一些事。</p> <p>为什么说下一阶段（L4）是Innovation（创新）？这里面最关键的是：模型什么时候能参与模型本身的开发？只有当模型参与到开发过程，才能解锁真正的Innovator（创新者）阶段。</p> <p>我们希望K2能参与到K3的开发，如果你没有Agentic能力，很难做到这件事。但当你具备了Agentic能力，它就可以提出一些新的想法，做对应的实验，分析实验结果，得出结论，迭代下一版想法，或者优化某个Infra（基础设施）性能。这些都依赖很强的Agentic能力才能做。</p> <p>Innovation（L4、创新）和Organization（L5、组织）也不一定是完全线性的关系，有的也是并行的。我们已经看到这样的趋势——</p> <p>比如说，当你有了一个Agent，就可以拓展成Multi-Agent System（多智能体系统）。你可以从一个Agent fork（分叉）出很多不同的Agents，让它们去做不同的事情。有些是串行的，有些是并行的，然后再合并，再拆分成不同的task（任务）。可能有的写测试，有的写文档，有的设计软件框架，有各自的分工。</p> <p><strong>Multi-Agent System（多智能体系统）</strong>：由多个相互独立但可以协作或竞争的智能体组成的系统。多智能体系统可以表现为多个由语言模型驱动的Agent在一个环境中协作、对话、解决任务，例如：一个Agent负责规划（planner），一个负责执行（executor），另一个监督结果（evaluator）。多个Agent扮演不同专家角色，围绕一个复杂问题展开”思辨式”讨论。 所以它不一定是线性关系，可能两个（L4和L5）同时发生。</p> <p>但Reasoning（L2）和Agent（L3），可能是Innovation（L4）和Organization（L5）的前提。</p> <p>张小珺：Innovation（L4）的标志是模型自我迭代，那Organization（L5）呢？</p> <p>杨植麟：比较简单的一个思考是，它会是一个 Multi-Agent（多智能体）系统。</p> <p>当然，你怎么把Multi-Agent系统很好地做端到端训练，不要过拟合到某几种Agent类型，让它有更好的泛化性，比较有挑战。</p> <p>张小珺：Organization是模型的“雪山封顶”吗？</p> <p>杨植麟：也不是，可能它真的就没有顶。</p> <p>张小珺：所以你把L1到L5的分级当作一个什么样的刻度？</p> <p>杨植麟：它是几个重要的技术milestone（里程碑），但它并不一定是串行关系。它不是我们预期某一个能力被解决之后，才去解决下面的问题。</p> <p>比如Reasoning。如果你真的要解决开放性推理问题，就需要做很强的Innovation，提出新的模型架构，而这又对推理能力提出了更高要求。本质上，是用L4的方法去解决L2的问题，把L2做得更好。</p> <p>这几个能力，随着时间推移，会持续变得更好。</p> <p>不过，你在里面有不同技术bet，会让你短期路径出现一些区别。这些短期路径的区别也会有影响——因为你面对的是动态的市场。</p> <p>张小珺：以前我们会固化认为终点是AGI，今天的终点不是AGI了，那么AGI是什么？</p> <p>杨植麟：AGI不是某一级台阶，你爬到了这级台阶，突然一夜之间达到AGI。而是说：它是一个方向。</p> <p>今天在很多领域，你可以认为已经AGI了，做得比99%人类更好。很多数学或编程竞赛，按现在的提升速度，预想很快有很多问题被充分解决。</p> <p>AGI有两个层面：一方面技术一直在提升；另一方面是技术对人类社会的影响。后者是一个更长周期的事情，也是AGI的一部分。</p> <p>这有点像蒸汽机产生后，社会变化需要几十、几百年去消化。一些工作变得不再必要，但会产生新的工作。每个人变成“超人”，可以做更多事情。社会的工作方式和运行效率会发生巨大变化。</p> <p>虽然我们用“登月”（Moonshot）命名公司，但它跟登月有区别。登月是你站上月球那一刻，可以号称“我达到了”。而AI很难在某个时间突然喊出口号，说“我们此时此刻实现了AGI”。</p> <p>你一直在往上爬。</p> <p>甚至，过一段时间之后，不一定是你自己在爬，是你用AI在爬。现在我们让K2做数据处理、模型分析、模型训练，以前都要人工做，以后慢慢交给模型做——它像一个放大器，帮你更好地攀登这座山。</p> <p>张小珺：如果雪山是无尽的，你追求的是什么？</p> <p>杨植麟：就是攀登的过程。</p> <p>你原来在山底下，现在又往上提升了一点，能看到的景色不一样。</p> <p>它是一个动态进化的过程。</p> <h2 id="第二章-k2是乔戈里峰-1">第二章 K2是乔戈里峰</h2> <h3 id="04-喂一样多的数据脑子长得更多">04 喂一样多的数据，“脑子”长得更多</h3> <p>张小珺：我们来复盘一下，你创业这两年的关键决策。2023到2024年你的关键决策是——在23年2月决定了创业、开始融资、组建团队；到了下半年，Kimi上线了、bet了长文本。</p> <p>2024到2025年，这一年你的几个关键决策是什么？</p> <p>杨植麟：很重要的一点是，技术上我们从以预训练和SFT（Supervised Fine-Tuning，监督微调）为重点研发范式，转变成以预训练和强化学习为重点的方式。这就需要做很多事——不管是人才的储备，还是研发方式的改变。</p> <p>另一点是，从对话到Agent是一个重要范式转变，很大程度影响我们的实际工作方式。</p> <p>张小珺：过去半年你们推出了K1.5和K2，它们分别对Kimi意味着什么？</p> <p>杨植麟：K1.5更多是强化学习技术的验证。</p> <p>张小珺：追赶o1？</p> <p>杨植麟：对，我们比较早在这个技术路线投入，得到一些结果，看背后的技术到底怎么做。</p> <p>当时我们发现不太需要太多的process reward（过程奖励），或者value function（价值函数），甚至它们在训练过程中还有一些副作用。</p> <p>我们发现，你可能直接用端到端的reward（奖励信号），就能把训练做得非常好。这在早期还不是非常明确。这个过程中，我们积累了一些强化学习的基建，还有一些算法的know-how（诀窍）。</p> <p>K2的重点有几个：一是我们希望它是一个非常好的基础模型（Base Model）。如果你想有更好的Base Model，就要去看现在整个领域预训练的瓶颈在哪。</p> <p>我们发现高质量数据的增长确实很缓慢，多模态数据又无法很好提升文本本身的“智商”，你可以认为高质量数据接近一个常数。这种情况下，我们希望能最大化地使用每一份数据，就是所谓的token efficiency（token效率）。</p> <p>你希望在吃下一样多数据的情况下，脑子能长得更多，你能得到更多智能。</p> <p>这里和之前的思路不太一样。你现在假设在训练系统做很多性能优化，让训练更快，这当然有价值。但训得更快本身，并不能提升智能上限，因为token数量还是那么多。你训得更快，只是更短时间完成训练，但模型效果不一定变好，这是训练效率或compute efficiency（计算效率）上的优化。</p> <p>之前有人做过这方面，我们现在更希望提升token efficiency，把一份数据当成几份用。</p> <p>我们很关注，比如Muon优化器。它很有意思，对token efficiency提升很大。像Adam优化器用了10年，大部分的模型训练都会用Adam，但它的token efficiency并不够好。</p> <p>Muon优化器不是把每个元素独立考虑，而是把一个矩阵的参数整体考虑它们之间的dependency（依赖关系）。通过这种方式，获得更好的学习效率——你学同样一份数据，能学到更多智能。</p> <p>我们早期的实验，如果在compute optimal（计算最优）的情况下，基本会有两倍提升。也就是，你学一份数据，相当于用Adam学两份数据。</p> <p>假设你有30T的高质量token，等价于你现在有60T的高质量token。</p> <p>张小珺：但它实际还是那么多数据啊。</p> <p>杨植麟：它学了之后，脑子会长得更快。因为学习效率更高，优化器更好，吸收得更快。</p> <p>你喂它一样多的数据，它吸收得更好，压缩率会涨得更快，loss（损失）会降得更快。</p> <p>张小珺：Muon优化器是你们原创吗？</p> <p>杨植麟：Muon优化器是Keller Jordan（一位计算机科学家和机器学习工程师，于2024年12月加入OpenAI）提出的，我们在他的基础上做了很多优化，使它能适配并训练非常大规模的语言模型。</p> <p>我们之前有一个Moonlight的工作，让它能够第一次在一定规模的语言模型上训练。后来在进一步规模化的过程中，发现了很多新的坑，比如max logit（最大logit值，观察训练是否正常的一个指标）可能会出现爆炸的问题。</p> <p>这个问题在小规模实验中很难发现，但在大规模训练时会遇到。于是我们提出了一些新的方法，比如clipping（截断）技术，让它在非常大规模的情况下，仍然能很好地训练。</p> <p>这非常重要——因为token数量有限，你希望每一份token能产生更大价值。</p> <p>张小珺：我读了你们的技术报告，你们尝试已有模型改写现有数据，生成新的语料，具体的改写策略是什么样的？——这个在报告里没有提。</p> <p>杨植麟：我们会对数据做很多Rephrase（改写）操作。比如你有30T token，但其中高质量数据更少，可能只有几十b或者几百b级别（百亿到千亿级参数量）。你希望这些高质量数据能被很好地利用，我们对这些数据做了一些改写，让它们更好地被模型吸收，并且有更好的泛化能力。</p> <p>主要思想是，如果你同一份数据学很多次，它可能泛化不一定那么好，有一些过拟合问题。我们希望通过改写，让它有一定程度的泛化。</p> <p>具体改写方式有非常多种，我们找到一种在实验里效果比较好的。</p> <p>张小珺：哪种？</p> <p>杨植麟：这个空间也很大，有非常多的研究机会。</p> <p>张小珺：你怎么看待一种观点——“改写和扩充其实没用，能够写出来知识，说明知识本身就在里面，没有新知识，除非改写的时候用到其他方法。”</p> <p>杨植麟：这是一个很好的问题，确实跟改写方式有关系。理论上，还是看你有没有新的熵的输入。它对改写方式有一些要求。但我们现在也不一定用了最好的改写方式，有很多探索的空间。</p> <p>回到刚讲的点，K2这个模型，一方面是希望它成为一个好的Base Model。我们很希望提升它的token efficiency，这些是我们对应的设计，包括通过更大的稀疏度去加更多的参数。</p> <p>那它的token efficiency也会更高，因为你参数多了之后，虽然学一样多的数据，但你会吸收得更好。反正通过实验可以验证，确实有更好的token efficiency。</p> <p>第二是我们希望它有好的Agentic能力。你通过各种强化学习，或者对工具和环境的模拟，让它能有比较好的泛化性。</p> <p>对于一个Agentic模型来讲，现在最大挑战是在模型的泛化上。</p> <p>因为现在的RL技术，局限性在于，不管是训练任务还是评价指标，很多时候都是单点。比如你就训SWE-bench同分布的数据，它就提升SWE-bench，是很确定的东西。但是你的指标提升上去之后，并不意味着模型的泛化会变得更好。</p> <p><strong>SWE-bench</strong>（ICLR 2024）：一个用于评估大模型在真实软件工程任务中表现的基准测试集。</p> <p>我们也在尝试去解决一部分泛化问题。不希望过拟合到某一些工具，或者过拟合到某一些环境，或者过拟合到某一些具体任务上。这些任务可能是很好的观测，但我们不希望过拟合它。</p> <p>这个问题在Agent训练更严重。相比于对话模型，Agent的泛化是一个更大挑战。</p> <p>张小珺：Agentic能力现在更多在Post-Train阶段训练，为什么不在Pre-Train阶段去训？</p> <p>杨植麟：这个也是接下来我们想探索的东西。</p> <p>张小珺：这有可能提高泛化性吗？</p> <p>杨植麟：取决于你的做法，比如数据分布是不是足够广泛，有没有很好的方法评估。</p> <p>现在整体的评估，是阻碍Agent模型变得更泛化的重要瓶颈。你会慢慢观察到，现在Agent能用的Benchmark（基准测试）不是非常多。你在那些Benchmark上观察到一个分数，很多时候它并不是对这个能力的反映，比较片面。这是大家要去想办法解决的问题。</p> <p>有一种潜在思路，我们需要用更AI native（原生人工智能）的方式去训练AI。我们希望让模型参与到更多训练过程。比如，如果你的AI能做很好的alignment research（对齐研究），它理论上会有更好的泛化，不仅只是在优化一些单点任务。</p> <p>今天Agent还不像对话有这么好的泛化性——接下来雪山上几百个台阶，有可能是这个。</p> <p>张小珺：听起来K1.5是跟着OpenAI跑，K2是在抢跑。</p> <p>杨植麟：我们借鉴了很多技术上的方向，但也希望有一些自己的创新。</p> <p>至少在公开资料，我们是第一个使用非Adam的，或者基于矩阵正交化的方式，去用新的优化器，在这么大规模的模型上去训练。这是一个创新点。</p> <p>我们在一些Agent数据的做法，至少在公开可查资料里也是比较早去做的。</p> <p>很有意思的是，当你在雪山上越往上爬，你会发现空间是在变大。因为现在你完成同一个任务用到的token在变多，问题复杂度变得更复杂。</p> <p>就像刚刚讲的：问题不可避免，但问题总可以被解决。</p> <p>这些不可避免的问题，看起来会比之前更多，但你的研究空间也会随之更广阔。</p> <p><em>（相比2024年1月访谈时，月之暗面已搬到一个更明亮的办公室。在北京知春路的京东科技大厦13层，那架白色钢琴还在。）</em></p> <h3 id="05-muon你去训的时候它会炸">05 Muon你去训的时候，它会炸</h3> <p>张小珺：我们具体说到K2这个项目，它是怎么立项的？中间筹备了多长时间？</p> <p>杨植麟：筹备是比较长时间的，涉及很多技术从去年开始研究。</p> <p>像Muon的技术，研究需要比较长周期。你一开始做早期实验，发现这个想法有潜力。我们会有一些小的实验验证这个idea（想法）潜力有多大。</p> <p>有了想法之后，到最后你能把它放到一个万亿模型去训练，要通过不同的scaling（规模化）实验去验证它的有效性。有些问题只有当你scale（扩展）到一定规模之后才会发现——所以周期比较长。</p> <p>当然，如果你只看这个模型训练，从按下训练按钮到训练结束，时间并没有那么长。但研发需要更前置做很多事，才能最后保证训练比较顺利。</p> <p>张小珺：做Agentic LLM（智能体大语言模型）这个bet是什么时间点？</p> <p>杨植麟：也要做很多积累，只是说，不同时间点做法不太一样。</p> <p>一开始你不一定端到端去做，但会积累一些环境和数据，到了后面更端到端去做强化学习。你中间需要很多基建和数据积累。很难说一两个月就能做得非常好。</p> <p>我整体觉得，大模型和相关技术很需要时间积累。还是“要做时间的朋友”吧。技术曲线还是有点陡峭，不是今天想做就能做出来。</p> <p>张小珺：所以什么时候立项的？为什么立这个项？</p> <p>杨植麟：一年前积累各种技术，但K2肯定是最近几个月，我们决定要去训一个这样的模型，然后把哪些技术用上，大概是这样一个决策。但不是我今天想训这个模型，从0去搞。</p> <p>我们一直训练下一代模型嘛。无非是一个决策：我下一代模型要加入哪些技术？你期待它是什么样的模型？就像现在也在考虑，K2之后下一代模型应该长什么样？——这是持续要思考和决策的。</p> <p>每次会看，现在工具箱又多了很多新东西，把哪些拿出来用？是这么一个过程。</p> <p>张小珺：你们做研究和做训练的团队是分开的吗？如果一年前已经开始研究这些技术，做正式训练，是一个团队在做整件事吗？</p> <p>杨植麟：是一个团队，这些东西很难分开。你在实际训练中会遇到问题，如果之前不了解，没办法解决它。</p> <p>张小珺：K2研发过程中遇到什么挑战没有？</p> <p>杨植麟：Muon你去训的时候，它就会炸。</p> <p>我们有画一些图在paper里，你的max logit会涨得非常高，涨到几百甚至更高。我们认为这个东西对训练稳定性有影响，你可能训久了，它很多所谓的内科指标（internal metrics）不正常，对模型上限有害。</p> <p>我们等于又回过头去revisit（重新审视），修复它。因为这个东西是你在小规模实验上没办法预测的，小规模上不会有爆炸的问题。</p> <p>其他基本还好，都在小规模上做了很多实验，是可迁移的，问题不是很大。唯一有这个问题是你小规模上验证不了，需要在scale（扩展）过程中再临时解决。</p> <p>张小珺：最近K2火了，你的心情有起伏变化吗？</p> <p>杨植麟：也没有，还好——这是一个漫长的旅程。</p> <p>要持续去做下一代模型，还是回到那两句刻在石头上的话：会产生新的问题，然后就去解决它。这也是最有意思的部分。</p> <p>张小珺：听说，你在内部群里形容K2意味着乔戈里峰。</p> <p>杨植麟：K2本来就是世界上最难攀登的山峰之一，名字有点重合。</p> <p>它不是终点，因为它不是最高的山峰，但可能是最难的。这是因为现在有很多范式转变，从对话到Agent，你的Base Model规模进一步变大，本身存在难度。</p> <p><strong>乔戈里峰（K2）</strong>：世界第二高峰，海拔8611米，仅次于珠穆朗玛峰（海拔8848米），位于中国与巴基斯坦交界的喀喇昆仑山脉中。它以极其险峻著称，攀登难度远超珠穆朗玛峰，被登山界誉为”山中之王”或”杀手峰”，因其恶劣的天气条件、复杂的地形和高死亡率而闻名。乔戈里峰多次成为登山者挑战极限的象征，也代表着极端高山探险的终极考验。 张小珺：K2发布的结果超出你预期了吗？</p> <p>杨植麟：差不多，模型训得怎么样，在过程中就已经知道了，没什么惊喜或意外。</p> <p>张小珺：你在K2训练中收获的最重要几个know-how（技术诀窍）是什么？</p> <p>杨植麟：我们都写在paper（论文）里写了。</p> <p>我们都很open（开放），还是想更多跟社区分享嘛。</p> <h3 id="06-当从缸中之脑变成跟世界交互的系统">06 当从“缸中之脑”变成跟世界交互的系统</h3> <p>张小珺：因为K2是一个Agentic大语言模型，你会怎么定义Agent（智能体）并对Agent进行分类？</p> <p>杨植麟：它可能是一个从“缸中之脑”变成可以跟世界交互，因为所谓Agent最重要的特征，就是它可以多轮地使用工具。</p> <p>有两个关键点：一个是多轮，一个是工具。</p> <p>多轮就是你能做很多次，是test time scaling（测试时扩展）的一种方式；工具则是连接这个“脑”跟外部世界的方式。</p> <p>比如，你用搜索引擎，就可以把模型跟整个互联网连接起来；你可以写代码，就能让“脑”跟数字世界连接，因为数字世界几乎所有自动化都可以用代码描述，它能拥有这种自动化能力。</p> <p>这两个是我想象中Agent的特征，接下来会有越来越多的工具。当然，工具会呈现长尾分布。如果模型泛化得好，它不只是使用常见工具，能使用非常个性化的工具。</p> <p>比如，模型能访问公司内部数据库、个人文档，甚至访问定制的API，完成退票、下单等业务操作。它应该能泛化到没见过的工具上。我一直觉得Agent最缺的是泛化能力。</p> <p>如果泛化能力强，大家讨论的各种垂直Agent就没那么必要了。因为通用Agent泛化到长尾工具上，很多领域专有问题都能通过接入不同工具解决。只要给它加上定制数据库、定制API、定制文档接口，就能做一个非常垂直的Agent。它的普适性会强很多。</p> <p>多轮主要是实现test time scaling（测试时扩展），可以做复杂任务。不像对话模型一次输出一轮，这个可以做不同的事情——就像人一样——人每天的工作，你可以认为是，多轮使用工具的序列。你希望把人的序列拟合进去，但你又搜集不到这样的数字化数据，你就可以用强化学习来构造。</p> <p>它本质是在模拟人的行为——不过，你也不能简单说是模拟人，叫“模拟人的行为”不太准确，它其实是通用的。</p> <p>张小珺：什么叫不能简单说在模拟人，人也很通用。</p> <p>杨植麟：对，人是通用的，人是所谓的universal constructor（万能构造器）。</p> <p><strong>“万能构造器”（universal constructor）</strong>：指一种能够制造任何物体或系统的机器或装置。这个概念源自理论计算机科学和自动机理论，最早由数学家约翰·冯·诺依曼提出。万能构造器能够读取自身的”蓝图”或程序指令，然后根据这些信息复制自己，或者制造其他复杂结构，理论上可以构建任意复杂的系统。 但它主要目的不是去模拟人，主要目的是通用性，这才是设计的目的。</p> <p>它跟人的做法类似，只是一个恰巧的结果，并不是设计系统的目的。</p> <p>张小珺：这就好比设计飞机，是为了让它成为交通工具，目的并不是像鸟一样能飞。</p> <p>杨植麟：我们做Agent系统，更多是为了做一个通用的智能，是跟这个目标对齐；但它刚好跟人相似。</p> <p>张小珺：怎么提高Agent通用性？你们探索到什么方法没有？</p> <p>杨植麟：这是很难的问题。今天Agent的泛化有一个风险，可能会陷入某些Benchmark过拟合，但现在又缺少很好的Benchmark。这是接下来的挑战。</p> <p>不过可能有些解法，我还是觉得能用更多的AI去训练AI，可以一定程度缓解这个问题。</p> <p>张小珺：什么时候能做到用AI训练AI？现在的瓶颈是什么？</p> <p>杨植麟：现在部分已经做到，但你希望它做更多。现在很多还是依赖人的设计。</p> <p>张小珺：这样就到下一个阶段Innovator（L4、创新者）的阶段了。</p> <p>杨植麟：这很有意思，你要用一些Innovation方式去解决Agent问题。因为Agent泛化不够，你得用创新去解决——用L4的技术去解决L3的问题。</p> <p>所以L1到L5的定义可能真的不是线性的。没有好的Innovation，没有用AI去训练，或者用AI对齐AI的方式，Agent很难做到好的泛化。</p> <p>你人工定义一些 task（任务），只fit（拟合）那个 task，但在别的看不见的task表现就不好。只刷几个task分数，但用户在更多OOD（分布外，out-of-distribution）场景中体感没有那么好。</p> <p>现在这个领域面临的是，Benchmark不够用或失效，Agent泛化有问题的阶段。</p> <p>张小珺：为什么数学和代码是相对容易泛化的领域？</p> <p>杨植麟：其实也没有。如果做强化学习，现在也有类似问题。</p> <p>强化学习本身的泛化性，比做SFT（监督微调）要好，因为过程中有更多的on-policy（基于当前策略）sample（采样），模型从自身采样中学习，泛化看起来更好，而且有负梯度。这两个因素导致从证据来看，泛化表现更好。</p> <p>但泛化是有限的。比如说，你在某种类型的数学竞赛做到99分，别的数学问题可能提升5个点，但很难直接做到99分。如果不做对应的RL任务，就很难直接做到这样的泛化性。</p> <p>所以做数学题也有类似问题，是被分布所制约的——还是“种瓜得瓜，种豆得豆”。</p> <p>但是我们希望强化学习或后训练用更多AI ，让模型摆脱“种瓜得瓜”的情况。</p> <p>张小珺：有没有可能最终就是摆脱不了，大幅提升不了泛化性？</p> <p>杨植麟：还是回到刚刚说的，问题不可避免，但问题可以被解决。你每次都会往前推进——泛化会变得更好，它不一定有尽头，一直会有更好的泛化。</p> <p>张小珺：对于Agent来说，任务和环境非常重要。怎么定义好的任务？怎么定义好的环境？你在探索过程中有没有一些思考？</p> <p>杨植麟：一种方式是，我给定一个模型，然后设计一些环境，去逆向拟合这个模型。当然你也可以正向设计，假设你是一方的开发者，正向设计工具和环境，让模型在这些环境里提升能力。</p> <p>关键是让这个设计有更好的通用性。它能做很多任务，不应该为了某些特定任务专门设计工具和环境。当设计足够通用时，模型能在这其中学习，而不是反过来拟合模型。这可能是更好的做法。</p> <p>张小珺：我注意到一点：一般大家认为在任务设计上，倾向于设计一个足够有挑战的任务，这样会催生一些更本质的新方法；但K2设计的是一些中等难度任务。这是出于什么考虑？这会影响通用性吗？</p> <p>杨植麟：它也是一个爬山过程。你不能一上来就让模型去证明一个还没有人证明过的数学问题，样本效率（sample efficiency）会非常低。</p> <p>现在比较好的方法是，强化学习如果搭配好的采样策略，本质是隐式的课程学习（curriculum learning）机制，希望模型从合适的难度开始学习，逐步提升难度，而不是一开始就学非常难的任务。否则采样效率低，基本学不到什么东西，算力可能都会被浪费掉。</p> <p>但挑战在于，今天的很多任务还是基于人类存量数据或人工设计的任务，AI native的部分还比较少，会带来泛化性问题。</p> <p>张小珺：在你眼中，Coding Agent（编程智能体）和通用Agent（通用智能体）是什么关系？</p> <p>杨植麟：Coding Agent是任务的一个子集，但可能是很重要的一个子集。</p> <p>最后还是希望不仅仅做Coding。包括现在我们训练的模型，也不是只让它做Coding，因为它本身有一些局限性。</p> <p>张小珺：可以这样说？——Coding相当于人类的手。</p> <p>相对来说，Coding对Agent是比较容易的任务，是吗？</p> <p>杨植麟：它比较好验证，所以比较好学习。它也会面临类似挑战——泛化性问题，即便是Coding Agent也会遇到一样的挑战。</p> <p>Coding Agent是很重要的一个子集在于，它代表了数字世界的自动化。现在很多Agent工具集合是固定的，如果你想创建一个新的工具，本质是写一段或者一大段代码实现。或者如果你想做更好的上下文管理（Context Engineering），背后也对应一个工具，这个工具可能也用代码实现。代码在这里面有独特的位置和作用。</p> <p>但并不是做了Coding Agent就足够。因为很多非程序员也会用Claude Code完成任务，比如律师、产品经理、设计师，他们用Claude Code是因为模型在一定程度上有泛化能力，不仅仅是写代码。</p> <p>张小珺：你们想做的是通用Agent，而不是Coding模型？</p> <p>杨植麟：我们还是希望做通用的模型。</p> <p>张小珺：从写代码到操纵整个数字世界，Agent目前还缺乏哪些能力？</p> <p>杨植麟：现在这些高频工具使用还不够好，能力上有很大空间。这也说明现在缺少更好的Benchmark观测。SWE-bench现在可能马上会饱和，很多Benchmark不够好，不够真实反映实际用户体验。</p> <p>高频工具本身会有空间。长尾工具，在一些你没有见过、完全OOD（Out-of-Distribution，分布外）的情况下，怎么有更好的泛化？也是很重要、需要解决的问题。</p> <p>张小珺：对于Agent ，Long Context（长上下文）和Long-Term Memory（长期记忆）重要吗？</p> <p>杨植麟：Long Context也很重要。因为现在很多任务，128K或256K这种Context完全解决不了，你需要百万级甚至更多。</p> <p>而挑战在于，你不仅要能处理这么长的Context，还要保证“脑子好用”，智商要非常高。</p> <p>这对于模型的训练，挑战是很大的。一方面你希望压缩率足够高，模型要足够大；另一方面你希望它比较长。这两者之间天然存在一些冲突，所以需要更好的架构。</p> <p>但是有些架构你会发现，它在更长Context下效果会有提升，但在短Context下不一定会有提升，甚至会有下降，这就涉及架构的平衡问题。</p> <p>不过这些问题接下来可以逐步被解决，我觉得有一些解法。</p> <p>此外，当前的RL训练方式还有很大提升空间。比如在训练复杂的多智能体系统（Multi-Agent System）时，如果只使用端到端的reward，很可能不够。中间的reward如何产生？是否能摆脱一些人工设计？</p> <p>这也是非常值得探索的方向。</p> <h2 id="第三章-既简单又复杂的系统-1">第三章 既简单又复杂的系统</h2> <h3 id="07-开源-vs-闭源">07 开源 vs 闭源</h3> <p>张小珺：我回看我们去年的对话，有一个问题非常想问你。 你去年说，开源会落后于闭源。因为开源的方式跟以前不一样，以前所有人都可以贡献到开源，而现在的大模型开源，本质是中心化的，社区贡献没有经过算力验证。相比之下，闭源阵营会人才和资本聚集，是对市场资源的整合。</p> <p>你当时说：“领先者不会开源，只有落后者才会这么做。”</p> <p>但今天你们开源了。</p> <p>杨植麟：因为我们现在，在全球范围内还没有完全领先（笑）。</p> <p>有些判断在大方向上是成立的：当你的模型发布，社区可以贡献一些东西。比如，你在推理侧可以做很多事，你可以让模型被更多人免费使用。</p> <p>但如果要贡献到模型本身、让模型变得更强，目前只有原厂能做。</p> <p>当然，如果你看Base Model，确实如此；但如果基于一个开源模型去做大量后训练（Post-Training），尤其是Agentic的Post-Training，可能催生新的机会。</p> <p>假设你现在非常想做一个法律相关Agent，你是创业公司，那你完全可以基于K2，在你的特定工具集合之下训练一个Specialized Agent（专用智能体），它可以在你关注的场景下表现得非常好。这种机会存在。</p> <p>更多是赋能下游应用，而不是反哺基础模型的提升。当然这个问题要动态观察。</p> <p>张小珺：你们会长期选择开源吗？</p> <p>杨植麟：这是我们希望长期做的，但不一定只做开源。我们希望跟社区分享技术know-how，这是加速技术提升的重要点。</p> <p>大家可以不完全是竞争，也可以有合作，甚至所有开源公司形成一个生态，更好地推动技术发展——雪山可以爬得更好，race to the top（冲向顶峰）。</p> <p>但也不一定所有都开源。比如跟某些公司合作，不一定都开出来。</p> <p>张小珺：总的来说，开源是一个技术体系的信仰，还是一个市场博弈的策略？</p> <p>杨植麟：客观说都有，而且都有好处。但最终我们希望通过这个让技术更安全、更快达到更好的水平。</p> <p>张小珺：开闭源的生态会怎么演进？在你的认知中，最终开源和闭源全球会剩下几家？</p> <p>杨植麟：不会很多，但几家还是会有的。你如果看过去两年，这个趋势比较明确——市场逐渐更集中、更收敛、更聚焦。可能一开始有几百个，到几十个，到几个。</p> <p>几个，或许是最终稳定数量，现在看是大概率的事。</p> <p>张小珺：你们属于开源那一边还是闭源这一边？</p> <p>杨植麟：这要动态去观察，我们希望长期分享更多技术。</p> <p>张小珺：为什么中国公司大部分都开源了？</p> <p>杨植麟：客观说，有市场博弈的因素。但这对社区是好事。</p> <h3 id="08-多模态不损伤脑子已经很好了">08 多模态不损伤“脑子”已经很好了</h3> <p>张小珺：你怎么看AI时代的产品？做AI产品跟做移动互联网产品有什么不一样？——你以前很喜欢说“模型即产品”。</p> <p>杨植麟：我只能说AI产品，移动互联网产品没做过。</p> <p>（模型即产品）现在没有变化。你做一个Agent产品，需要把模型跟工具和Context结合起来。但你会发现，训练模型的时候，基本得把这一整套系统搭好，才能训练这个模型。</p> <p>模型训练完成，产品也基本完成了。在这个基础上做一些交互上的改进当然有价值，但那是锦上添花的一步。</p> <p>你的模型性能在训练中已经打磨好，跟工具和环境有非常好的适配——也就是，产品是在训练过程中完成的。</p> <p>张小珺：去年，你提到现在的开发方式已经演变成——你要做一个巨大的系统，就像20世纪初Google做搜索引擎系统。你今天对于AI时代的巨大系统，有更多的想象吗？</p> <p>杨植麟：现在的系统复杂性在于，你想让这个模型变得通用。一方面它变简单了，另一方面它变复杂了。</p> <p>简单在于，你只要把所有东西放在同一个模型，不需要维护那么多模型，也不需要搞一堆的routing策略（路由策略）。从概念上，或从工程实现上，它变简单了。</p> <p>但同时，它也变得复杂。如果你希望它通用，就希望这个模型在各种场景下都能工作。比如你做Agent模型，你不希望它只在你的工具集工作，而是希望别人用这个模型时，即便是别的工具集，甚至你没见过的工具，或者定义和实现方式不同的工具，它也能工作。这个要求很高。</p> <p>像现在Agent里面，可能会有几种不同类型的任务，不管是Coding Agent（代码智能体）、Search Agent（搜索智能体），还是其他Agents，你要把它放在同一个通用模型，就可能有打架的问题。也许工具定义不一样，或者数据pattern（模式）不一样。</p> <p>就是，你把它做成一个通用模型的过程，有很多技术挑战。</p> <p>但如果你不做成通用模型，它的泛化性又没那么好，只能做一件事。特别是现在的Agent，它需要很多步才能完成任务。即便是程序员，也不仅仅是写代码；就算写代码，也不仅只做SWE-bench。你要做出很通用的、真正可用的东西，随着步数变多，对通用性要求会更高。</p> <p>它的系统复杂性，体现在训练模型的过程中，要让这个模型足够通用，而不是只拟合到某些单点能力上。你如果只拟合单点能力，可能Benchmark分数很好看，但通用性不够——这是现在这个系统，我能观察到的比较大的挑战。</p> <p>有一个例子是，如果你想往模型里加多模态能力，你就需要让这个多模态能力不要损伤它的“脑子”。</p> <p>张小珺：多模态只能做到不损伤？</p> <p>杨植麟：对，能不损伤已经很好了。</p> <p>你希望在多模态模式下，跟文本模式下，共用一个“脑子”；你希望它在多模态的模式下，也能把文本那部分的智商激发出来，而不是进入另外一部分参数，那它可能完全丢掉了原来文本学习的部分。</p> <p>当你做一个通用模型，会面临这样的挑战。当你有各种模态、各种任务类型，还有Agent、Reasoning、Chat这些，要全部融合到一起，是存在挑战的。</p> <p>而且现在不仅是做SFT，还要做RL，挑战进一步加重。</p> <p>通用的Pre-Training比较好做，你只要把所有文本放在一起，它基本不会有太多问题。但越到Post-Train后期，越到RL，这个问题会更加严重——这是它的系统复杂性。</p> <h3 id="09-当你通过新的交互收集的信号噪声减少">09 当你通过新的交互，收集的信号噪声减少</h3> <p>张小珺：你看，搜索引擎系统是构建在PC互联网之上，推荐引擎系统是构建在手机，也就是移动互联网之上。在AI时代，新的超级节点会出现在哪里？</p> <p>杨植麟：它会跑在很多数据中心，Jensen（英伟达创始人兼CEO黄仁勋）经常说的AI factory（人工智能工厂）。但还是会有更多终端，终端有些复用现在的，有些可能是新的。</p> <p>张小珺：会诞生新的交互方式吗？</p> <p>杨植麟：肯定会。两年前看，Chat是一种新的交互方式。现在Agent，有很多新的交互方式，比如你让它异步执行一个任务，可以看中间结果。</p> <p>你看Coding，一开始是Copilot，之后有Cursor，再之后有Claude Code——每一代的交互都发生了变化，交互是随着模型的变化而变化。</p> <p>当你有新一代模型，能力提升很多，就会发现交互可以改了。你不再需要一个一个点accept（接受）修改，而是多步执行一个Agentic Coding任务。</p> <p>当然，今天Claude Code的交互也不是终极形态，因为模型还会继续提升，能力提升之后，交互会持续变化。比如你有一个Multi-Agent System，交互方式会怎么样？可能随着能力边界不断变化。</p> <p>张小珺：今天的Scaling Law（扩展定律）放缓了吗？</p> <p>杨植麟：Scaling Law遇到数据墙了，这是客观事实。你要突破数据墙，就需要提高token efficiency。这也是我们为什么做提高token efficiency的事情，数据墙是存在的，同时你要scale（扩展）更多算力到各种RL任务上。</p> <p>但我们现在观察，模型变好的速度并没有减少，甚至在加速。</p> <p>张小珺：为什么AI产品发展到今天，还没有形成数据飞轮？</p> <p>杨植麟：因为基于算力的scaling太强大了。</p> <p>比如你先去scale Pre-Training（预训练），再去scale RL（强化学习），而RL的scaling效率又比Pre-Training高很多。因为它是on-policy（基于当前策略）且带负梯度的训练，所以scaling效率更高。</p> <p>当你有很高scaling效率的时候，你直接去scale compute（算力）、scale FLOPs（浮点运算次数）带来的提升非常大，相比之下其他手段带来的提升很小。这是一方面。</p> <p>另一方面，所谓数据飞轮很依赖外部环境的feedback（反馈）。这个feedback，我们不希望它有很多噪声。但现在还没有把这个问题解决得非常好。</p> <p>大模型的学习对噪声比较敏感，它跟传统的，比如推荐系统不太一样。推荐系统可能没那么怕噪声，但大模型是敏感的。</p> <p>现在看起来，基于FLOPs的scaling是更有效路径。但这个平衡什么时候会发生变化？——也有可能你通过新的交互，让你收集到的信号的噪声能够减少。</p> <p>张小珺：这就需要创造一种新的交互范式。</p> <p>杨植麟：对。但这个交互又要适配模型能力的发展。你的交互不能超越模型能力，应该是在当前模型能力范围内，设计一个好的交互。</p> <p>这是值得尝试的。只是在今天看，去scale FLOPs的维度，或者提升学习效率，是一个确定性更高、更有效的方法。</p> <p>张小珺：如果按闫俊杰（MiniMax创始人兼CEO）的说法，用户数据无法提高模型的智能，那今天是不是没必要做To C（面向消费者）产品，就一门心思提升智能就好了。</p> <p>杨植麟：这要看怎么理解。你可能没办法直接使用用户反馈去训练；但有一定用户量的好处是，你知道需求分布是什么样的，知道哪些地方用户用得好或不好，可以把这些东西抽象成evaluation（评估），再去优化模型。如果模型完全没人用，你不知道该往哪个方向优化。</p> <p>另外也要看用户的商业价值。现在又到了一个新的分水岭：用户是有可能产生商业价值的。你看OpenAI，C端用户产生了很大商业价值，占了它营收比较大比例。</p> <p>特别是现在很多Agent产品，能端到端产生价值，所以也要看你是什么用户。如果只是闲聊、查天气，商业价值没那么大。但如果是Agent专业用户，本身有很好的生产力价值。</p> <p>张小珺：最近一年，你对C端产品有哪些新的思考？</p> <p>杨植麟：更多还是想模型怎么做，因为模型训好了，产品基本做得差不多了。我们还是会沿着这个方式一直做。</p> <p>张小珺：有人说，Kimi是从最初想做“中国的OpenAI”——当然你以前并不认同这一说法——转而想做“中国的Anthropic”。你们内部有这样的定位转换吗？</p> <p>杨植麟：很难用这样的方式去定义。中美的语境、土壤不一样，今天更多是从全球视角去思考问题。“做中国的某某”，不太成立。</p> <p>其实简单一点，我们希望继续爬山，做时间的朋友，和社区一起加速技术的推进。</p> <h3 id="10-long-context架构会影响智商">10 Long Context架构会影响“智商”</h3> <p>张小珺：作为Founder，你现在生活节奏是什么样的？</p> <p>杨植麟：可能睡得比较晚，哈哈，每天不一样。</p> <p>但也还好，花很多时间看怎么把模型训得更好。</p> <p>张小珺：你的时间主要投入在模型训练上？</p> <p>杨植麟：是吧，但模型训练是个抽象概念，重要的是技术战略，这是公司战略里最关键的一部分——下一步哪些要做，哪些不要做，因为技术空间很大，总要选一些方向重点投入。</p> <p>我们在很多方向上的bet比较早，且是有效的。我们很早去做long CoT的RL，反应比较快；去做优化器；去做更大规模的Pre-Training；去做第一个Open的Agentic模型，这些都是技术关键决策。这些决策能决定公司五六成走向。</p> <p>但你要做很好的决策，需要很多证据，还得做很多实验。你得非常了解实验的具体结果，不能拍脑袋，得知道更多信息。</p> <p>张小珺：这些决策中令你最纠结的是哪个？</p> <p>杨植麟：也还好。关键是一个收集数据的过程。做实验，看实验是不是扎实。加上你对技术的理解去判断。很多时候只要数据足够充分，判断比较显然。</p> <p>接下来——至少现在，K2的性能潜力还没完全被压榨出来。我们之前放的更接近是一个Base Model。我们可以加更多Post-Training阶段的FLOPs（浮点运算量），上限应该比现在高很多。</p> <p>我们还会做下一代模型，但具体怎么做，我们通过实验来决策。</p> <p>张小珺：也会加多模态吧？</p> <p>杨植麟：多模态是比较确定的。</p> <p>但多模态的能力本身要做好不容易。里面有很多工作：怎么让它去借鉴文本的脑子，而不是自己单开一个脑子。比如你MoE（专家混合，Mixture of Experts）里假设有20个expert（专家），专门在做多模态，你可能不希望这种情况出现——这样，你可能学出来的多模态是个“傻的多模态”。</p> <p>我们希望它是个“聪明的多模态”。</p> <p>张小珺：接下来还会有哪些重要的技术里程碑？</p> <p>杨植麟：Agent的泛化性是最重要的。</p> <p>Long Context的支持，我们会继续研究。特别是在智商很高的情况下，还能有更长的Context，也是很重要的问题。</p> <p>现在很多Long Context架构还是会影响“智商”。</p> <p>张小珺：为什么Long Context架构会影响“智商”？</p> <p>杨植麟：纯粹的Linear Attention（线性注意力机制）可能就是会影响智商，因为这个架构会有一些bias（偏差），这些bias在一些场景下效果没有那么好。但一定程度上是可以被解决的。</p> <p>张小珺：你怎么看张祥雨（阶跃星辰首席科学家）说的next token prediction（下一个token预测）的本质缺陷？</p> <p>他的意思是，随着模型规模扩大，对话能力、知识量和情商都在变强，但推理能力尤其是数据表现是先上升后平缓，再扩大反而下降。用更大的模型做数学题，容易跳步、不老实。这是next token prediction的本质缺陷。</p> <p>杨植麟：所以要搭配强化学习的scaling（扩展）。如果今天不做强化学习，模型很难说很聪明。像数学题，不一定做得非常好。</p> <p>但更大的base（基础模型），强化学习的上限会更高。因为知识更多，本质是激活一个推理的范式，让它能把知识解锁出来。它的上限更高，但需要搭配RL去激活。</p> <p>张小珺：你怎么看待世界模型？——有人说，做世界模型是造世界，做Agent是造人。</p> <p>杨植麟：用AI训练AI有点这个意思。你有一个很好的世界模型，就能模拟这些东西，就是用AI训练AI的方式。</p> <p>它可能是通往更好泛化的一种路径。</p> <h3 id="11-边界与现实">11 边界与现实</h3> <p>张小珺：现在，我们来讨论一些现实问题。</p> <p>基座模型公司和做Agent产品的应用公司，长期看边界在哪？</p> <p>杨植麟：我没有明确答案。只能说今天，“一方产品”有个好处，可以垂直整合，把模型放在里面训练，模型和工具融为一体，不是分开做再逆向工程。</p> <p>但因为Agent领域广阔，“一方产品”不一定能做得过来。如果能找到一些空间，比如工具的实现需要非常多领域的know-how，或者evaluation是“一方产品”考虑不过来的东西，是有机会的。</p> <p>因为有像K2这样的开源模型，大家可以在上面微调（fine-tune），更容易产生Specialize Agent（专用智能体）、垂直Agent的可能性。</p> <p>张小珺：那要看通用模型通用到什么程度了。</p> <p>杨植麟：不管多通用，总还是有一些工具你要做。你有可能不一定做模型，而是把工具做得非常好。</p> <p>这个工具如果做得太通用，就会和“一方产品”overlap（重叠）比较大——这种情况下，垂直整合优势更大。</p> <p>但如果工具是专门针对某个场景，甚至别人做不了。比如你掌握了一些线下服务入口，你的下订单或者成交的工具别人做不出来，你可能产生独特价值。</p> <p>当然也有另外一种可能性，当“一方产品”或通用Agent的流量和商业模式足够成熟，很多专有的、本来垄断的工具也愿意接入，因为整体商业化效率会更高。但商业化效率的提升需要时间。在这段时间窗口内，专有Agent也会有空间。</p> <p>最终，通用之所以有效，是因为整体商业化效率更高。今天，包括很多内容平台，最终有可能你把内容接到通用Agent，商业化效率会比今天更高——但可能要花很长时间。</p> <p>张小珺：像Manus这种公司，会是你的潜在客户还是竞争对手？</p> <p>杨植麟：还很早期，很难判断到底是什么样，产品本身也会演进。</p> <p>短期，更多是合作大于竞争。今天Cursor、Perplexity、Genspark也都可以看到K2的身影。</p> <p>但未来会演进，有点像Claude和Cursor的关系。Cursor也可能需要动态调整产品策略。它可能需要一方面具备一定的模型能力，因为技术曲线还很陡峭；另一方面，它能不能有一些别人做不到的工具或环境？</p> <p>现在没法直接回答。只能说目前，一方的整合优势还存在。</p> <p>张小珺：你今天怎么思考商业模式？API是好生意吗？</p> <p>杨植麟：目前明确的商业模式：一是API服务，二是“一方产品”。我们都会做一些尝试。今天最主要优先级是把模型做得更好，这依然是首要目标。</p> <p>在模型提升过程中，如果在某些方面领先，确实有商业化空间。今天市场规模增长非常快，头部公司有几十亿甚至上百亿美元ARR（年度经常性收入），每一两个季度可能实现两三倍增长。我们会动态观察，做出相应尝试。</p> <p>张小珺：一位你们的用户说，他很喜欢Kimi，但也担心Kimi赚不到钱，你们能赚钱吗？</p> <p>杨植麟：还是先投资。能不能赚钱，取决于模型效果怎么样。</p> <p>我们也愿意服务用户的最后一公里体验，为用户交付高价值问题的deliverable（可交付成果）。</p> <p>全球百亿美金且高速增长的AI市场里，专注把技术做好，其他反而更有确定性。</p> <h2 id="第四章-在自己的故事里面-1">第四章 在自己的故事里面</h2> <h3 id="12-用rl的方式去管理而不是用sft">12 用RL的方式去管理，而不是用SFT</h3> <p>张小珺：过去一年，你对组织有新的思考没有？</p> <p>杨植麟：好问题。最近一直在想一个事，有几个东西是联系在一起。</p> <p>你看科研，或者创造新知识的过程，很像一个强化学习（RL）的过程。</p> <p>之前有种经验主义理论说，人是通过经验获取知识。但后来很多观点认为不是这样。人类在地球上存在非常多年，直到几百年前没有任何人说“地球是个球”。你一直在经验里，但你不知道事实是什么样的——经验并不能直接给你知识。而是，你提出这个猜想，说我认为“这个球是圆的”，我想各种方法验证它。</p> <p>包括训练神经网络，你可能观察到一些内科指标不太对，你提出“为什么它会这样”的猜想，设计实验去验证——这个过程和强化学习非常像。</p> <p>同时，你发现，管理一个团队，也是这样的方法。这是Tim（周昕宇，月之暗面联合创始人）天天跟我讲的——要用RL的方式去管理，而不是用SFT。</p> <p>当然现在，你做RL的时候也希望加一点SFT，因为SFT是很好的先验，防止模型“飞太远”。但你又要管住自己的手，你不能SFT太多。SFT太多，团队成员会失去主观能动性，没办法创新。这点我现在也在实践，看起来有一些效果。</p> <p>核心是掌握SFT和RL的平衡。</p> <p>SFT是你告诉他“这个事情该这样、这样做”； RL是你给他一个奖励，如果做成这样是好的，更多反映在目标上。</p> <p>可能要以RL为主，用一部分SFT通过先验去控制，或者防止它遗忘重要的东西。</p> <p>RL是一种很本质的东西。在科研、模型训练、组织管理上，是相通的。</p> <p>但这也带来一个挑战：在RL过程中，怎么定义reward（奖励）。你简单设定一个目标，比如“把所有Benchmark拉高”，大家会不择手段去overfit指标。但分数高了，模型本身并没有真的更好。</p> <p>所以，奖励的定义就很重要，需要你很理解具体细节是怎么运作的。不然会出现reward hacking（奖励机制被滥用）。</p> <p>张小珺：所以在组织内部，怎么定义reward？</p> <p>杨植麟：你建立更多观测指标，尽可能不要过拟合，是一定程度有效的。这样你才有更好的泛化，不会被hack（利用漏洞）。</p> <p>用RL管理团队最大问题是，你容易被hack。大家看起来各种结果很好，但实际并没有达到你最终想要的——这是风险。用SFT管理团队的风险，是大家失去创造力。最后这几个东西要有一定程度的balance（平衡）。</p> <p>当然我也在学习，今天不是做到很完美。</p> <h3 id="13-ai是人类文明的放大器">13 AI是人类文明的放大器</h3> <p>张小珺：过去一年Kimi在波峰波谷来回震荡，身处其中，你的心态是什么样的？需要平衡自己的心态吗？</p> <p>杨植麟：心态就是，做时间的朋友吧。</p> <p>张小珺：真实的人的心态不会这么简单的。</p> <p>杨植麟：像你说的，会有高点和低点。可能很重要的是，还是喜欢做这个事情，想把它做好。所以你也不用想别的，就想怎么把它做好。好像也比较简单，没有什么特别复杂的。</p> <p>很多复杂性都是人为强行加上去的，实际并没有那么复杂。</p> <p>张小珺：你对人性有更多的理解没有？</p> <p>杨植麟：这也还需要时间的打磨，不敢说那么深入。</p> <p>只能说是在自己的这个故事里面——你不断地感受自己到底是什么样的一个人，你为什么要做这个事情——不断去思考这些问题。</p> <p>张小珺：你是一个什么样的人？你为什么要做这样事情？</p> <p>杨植麟：就是觉得有意思。</p> <p>张小珺：什么有意思呢？做实验有意思，做科研有意思，还是做AI有意思？</p> <p>杨植麟：寻找真相的过程。去不断发现新的问题、解决它的过程。</p> <p>张小珺：那你也可以解决别的问题啊，为什么一定要解决这个问题？</p> <p>杨植麟：因为这个东西很重要，AI很重要。</p> <p>这个问题我也问过Kimi。他说，这个东西是“人类文明的放大器”，我觉得很有道理。</p> <p>又回到The Beginning of Infinity，从启蒙运动到现在，人类一直在寻找新的方法突破知识的边界。但是，可能下一个突破边界的，是靠AI，它是一个巨大的杠杆。</p> <p>你今天在任何一个前沿学科，要花二三十年，才能学到最前沿知识。但是AI一夜之间就能学会，往下去做新的突破。</p> <p>AI会成为Meta science（元科学）。</p> <p>它是人类文明的放大器。</p> <p>张小珺：它有可能摧毁人类文明吗？</p> <p>杨植麟：这个风险不能说不存在，但我们可以有很多事去做。不管是更安全地对齐，还是更好的社会机制。</p> <p>比如说，当AI可以做一些事情，它很有可能创造一些新的工作，我们需要有一些方法去完成这个过渡。</p> <p>我exactly问过Kimi这个问题。他说，虽然有这样的风险，但我们不能放弃。因为如果放弃，就等于放弃了人类文明的上限——你不知道上限能做到什么样，有一点“因噎废食”的感觉。</p> <p>但我承认，我们得做很多去应对。因为你今天看到很多AI的能力，是有点让人震惊的，半年前根本想不到它能做到。</p> <p>同时我认为，人类的独特价值在这个过程中会持续存在。人的体验、情感，没有办法被AI替代。所以，可能会有不同的活法，希望是能活得更好。</p> <p>张小珺：什么样不同的活法？</p> <p>杨植麟：我之前觉得，人的一生有几个意义：创造、体验和爱。当然每个人不一样，对我是这样。</p> <p>“创造”的很大一部分，也许AI可以做。我享受这个过程，但不得不承认，有一天很多创造性工作是AI去做。但后两条，“体验”和“爱”，会是以人为中心的。</p> <p>张小珺：如果AI把创造拿走了，也把生产力拿走了。</p> <p>杨植麟：这无所谓，人可以享受生产的结果，如果我们有好的机制。</p> <p>但它是一个缓慢过程，不会一两年做完，需要一二十年逐渐调整。</p> <p>张小珺：你会频繁地和Kimi聊天吗？</p> <p>杨植麟：当然。我要测试模型。</p> <p>张小珺：你会和他聊一些很深刻的话题或者自我探索的话题吗？</p> <p>杨植麟：有时候会。也还好，还有一些是工作上的问题。</p> <p>张小珺：过去这一年，你有经历过情绪很低落的时刻吗？</p> <p>杨植麟：我觉得也还好。更多是：有些东西会work，有些东西不work；会解决一些问题，会有新的问题产生——不断在这个过程中。</p> <p>只要你觉得这个东西有意思，就一直想继续做下去。</p> <h3 id="14-任何中间状态都有可能成为被批评的对象">14 任何中间状态都有可能成为被批评的对象</h3> <p>张小珺：过去一年，你有没有走过一些弯路？</p> <p>杨植麟：肯定有。过程中会有很多很多决策，有一些技术决策，有一些业务决策。</p> <p>很重要的是，一个公司在这个过程中逐渐调整的能力。知识创造的过程也是这样的过程——不可能创造出来的知识，所有东西都是对的，你会发现有些东西也是错的，但它在一定时间内可能是对的，一定时间可能又是错的。但当它错了之后，你就得去做调整。</p> <p>比如像牛顿做的很多东西，在当时是最好的理论，但不是完美的，在一些场景下是完全错的。万有引力需要有一些别的解释，需要有一些相对论的解释，通过时空的扭曲去解释。</p> <p>我觉得组织的进化、公司的发展也是一样，是一个动态过程。任何的中间点，你在某个时间点是对的，在另一个时间点可能就是错的。</p> <p>这也是Kimi跟我讲的——任何中间状态都有可能成为被批评的对象。你总是会有这个时代的局限性。</p> <p>更重要的是，你怎么在这个过程中，一方面投入一些“不变”的东西，比如人才、技术积累；另一方面适应和调整，针对环境变化和反馈信号做调整。这两个都很重要。</p> <p>张小珺：互联网产品通过市场推广去扩大DAU，扩大市场规模；AI产品似乎有所不同，增长和获客更依赖模型能力的大幅跃升——智能和推广，哪个更本质？</p> <p>杨植麟：它还是取决，两个变量哪个大。在技术快速发展的阶段，你很难通过市场推广的方式去赢得战争。它更多是一个辅助手段。</p> <p>只是说这个辅助手段跟你的主要手段之间，到底什么样的配比？需要动态调整，也取决于你现在商业化进展，或者PMF到底有多强。不同时间点有不同策略。</p> <p>甚至这个策略也许再过一两年，你发现又是一个好的策略。我觉得也不一定。</p> <p>我们是用更open的心态去看，但在每个时间点最重要的是去抓住——哪个是最大的变量。</p> <p>张小珺：又过了一年，你觉得Kimi的成功概率增大了还是失败概率增大？</p> <p>杨植麟：我觉得（成功概率）增大了。你只要每往上爬，成功概率会变大，因为会有一些人不继续爬了。</p> <p>张小珺：你恐惧摔下去吗？</p> <p>杨植麟：肯定有恐惧。</p> <p>更多要关注你当前这一步，能做什么？——想这个问题更重要。</p> <p>张小珺：我一直在问你的情绪，你都说：唉，还好、还好。你最近一次或两次“颅内自嗨”是什么情境？</p> <p>杨植麟：不以物喜，不以己悲。虽然很难做到，但要避免情绪化决策。</p> <p>张小珺：你会情绪化吗？</p> <p>杨植麟：多少肯定会——你是一个人嘛。但要避免一些情绪化决策。最终落实到决策和执行上，要更理性一点。</p> <p>张小珺：过去一年，你最大成长是什么？</p> <p>杨植麟：认识到这一点：问题不可避免，它会一直存在，持续解决新问题是最重要的，可能也是最有意思的——这是心态上的变化，它会改变很多做事的方式。</p> <p>张小珺：这听上去是一种正念。</p> <p>杨植麟：我不知道怎么理解，但可能差不多。（笑）</p> <p>张小珺：我问你最后几个快问快答。</p> <p>一个全球范围内你喜欢的食物。</p> <p>杨植麟：拉面！</p> <p>张小珺：为什么？</p> <p>杨植麟：好吃！</p> <p>张小珺：一个少有人知道但必须知道的知识点。</p> <p>杨植麟：我好像不太擅长回答这种问题。</p> <p>张小珺：基于所有读过的书，推荐必读书。</p> <p>杨植麟：有一本我刚刚一直在讲，就推荐这本。</p> <p>张小珺：你心目中影响AI进程的几篇论文是什么？</p> <p>杨植麟：最重要的几篇论文是Backpropagation（反向传播）、Transformer、GPT-3。</p> <p>当然有一些是building block（基础模块），也很重要，比如ResNet（残差网络），它可能是优化的基础。还有Adam（自适应矩估计优化算法）。现在可能还有Muon。</p> <p>张小珺：基于当下认知，一个最关键的bet是什么？</p> <p>杨植麟：泛化的Agent（智能体）。</p> <p>用Innovation（创新），用L4做L3。</p> <p>张小珺：这一年，你有没有任何的顿悟时刻？</p> <p>杨植麟：不知道，我感觉我脑子已经糊了。</p> <p>我已经把一年的话都讲了。</p> <p>现场第三位人士：这可能就是，Long Context影响智商。</p> <p>杨植麟：没办法。</p> <p>碳基生物的局限性。（笑）</p>]]></content><author><name></name></author><category term="blog"/><summary type="html"><![CDATA[KIMI创始人杨植麟深度访谈：攀登无限之山]]></summary></entry><entry><title type="html">OpenAI双巨头首次详解GPT-5：不是下一代GPT，终极形态是AI研究员</title><link href="https://emigmo.github.io/blog/2025/openai-gpt5-researcher-vision/" rel="alternate" type="text/html" title="OpenAI双巨头首次详解GPT-5：不是下一代GPT，终极形态是AI研究员"/><published>2025-10-23T00:00:00+00:00</published><updated>2025-10-23T00:00:00+00:00</updated><id>https://emigmo.github.io/blog/2025/openai-gpt5-researcher-vision</id><content type="html" xml:base="https://emigmo.github.io/blog/2025/openai-gpt5-researcher-vision/"><![CDATA[<h1 id="openai双巨头首次详解gpt-5不是下一代gpt终极形态是ai研究员">OpenAI双巨头首次详解GPT-5：不是下一代GPT，终极形态是AI研究员</h1> <p><em>访谈对象：Jakub Pachocki（OpenAI首席科学家）、Mark Chen(OpenAI首席研究官)</em><br/> <em>时间：2025年10月</em><br/> <em>来源：硅谷风投a16z深度访谈</em></p> <hr/> <h2 id="前言">前言</h2> <blockquote> <p><strong>“我们希望模型能自己发现新想法,自己推进研究。”</strong></p> <p><strong>“GPT-5不是GPT-4的简单升级,而是一个重要的转折点。”</strong></p> </blockquote> <p>前不久,OpenAI的两大巨头——首席科学家Jakub Pachocki与首席研究官Mark Chen共同接受硅谷风投a16z深度访谈,首次系统性地揭示了GPT-5的真实定位。震撼的不是GPT-5本身,而是它背后的野心：<strong>打造”自动化研究员”</strong>。</p> <p><strong>三个关键信号值得所有人关注：</strong></p> <ol> <li><strong>融合革命</strong>：GPT-5将整合GPT系列的”快速响应”与o1系列的”深度推理”,让模型自主判断”这个问题需要几秒还是几小时思考”</li> <li><strong>硬科学突破已现</strong>：物理学家、数学家试用后震惊地发现,GPT-5能提出非平凡的新数学结果</li> <li><strong>从”vibe coding”到”vibe researching”</strong>：OpenAI的真正目标是与AI协同做研究,这将彻底改变科研的传统方式</li> </ol> <hr/> <h2 id="目录">目录</h2> <ul> <li><a href="#一gpt-5诞生从快速响应到深度推理">一、GPT-5诞生：从”快速响应”到”深度推理”</a></li> <li><a href="#二评估标准大转向从考高分到创造新可能">二、评估标准大转向：从”考高分”到”创造新可能”</a></li> <li><a href="#三强化学习推理的引擎潜力仍然巨大">三、强化学习：推理的”引擎”,潜力仍然巨大</a></li> <li><a href="#四ai编程革命从vibe-coding到vibe-researching">四、AI编程革命：从”vibe coding”到”vibe researching”</a></li> <li><a href="#五ai的未来瞄准自动化研究员">五、AI的未来：瞄准”自动化研究员”</a></li> <li><a href="#六团队文化持续学习长期主义">六、团队文化：持续学习,长期主义</a></li> <li><a href="#结语ai从回答者变成合作者">结语：AI从”回答者”变成”合作者”</a></li> </ul> <hr/> <h2 id="一gpt-5诞生从快速响应到深度推理">一、GPT-5诞生：从”快速响应”到”深度推理”</h2> <h3 id="11-两条技术路线的融合">1.1 两条技术路线的融合</h3> <p>Mark介绍,过去OpenAI有两条并行的技术路线：</p> <p><strong>GPT系列</strong>：</p> <ul> <li>从GPT-2到GPT-4</li> <li>特点是快速响应、即时输出</li> </ul> <p><strong>o系列</strong>：</p> <ul> <li>不追求速度,而是”思考更久”</li> <li>力求给出最优答案</li> </ul> <blockquote> <p><strong>GPT-5做了一件关键的事：把这两条路线彻底融合。</strong></p> </blockquote> <p>它能自主判断”这个问题需要几秒钟还是几个小时思考”,不用用户手动选择模式。这让”推理能力”和”类代理能力”成了模型的默认配置,也让GPT-5成为首个真正意义上的”推理模型”。</p> <h3 id="12-推理过程的突破">1.2 推理过程的突破</h3> <p>在推理过程中,GPT-5像人类一样,也会经历<strong>“尝试—失败—调整—再尝试”</strong>的过程。更重要的是,它能显著延长”不跑偏”的持续推理时长,解决了行业里”步骤过多就会质量下降”的老难题。</p> <h3 id="13-训练中的挑战">1.3 训练中的挑战</h3> <p>不过,训练GPT-5的过程也并不是一帆风顺的。最常见的麻烦是<strong>“双重bug”</strong>：</p> <ul> <li>既有代码层面的漏洞</li> <li>也有研究者思维上的”偏差假设”</li> </ul> <p>这些问题一旦出现,可能让几个月的实验白费。Jakub坦言,很多重大突破的本质,其实就是”识别并修正这些隐藏的错误”。</p> <h3 id="14-gpt-5-codex推理智能落地编程">1.4 GPT-5 Codex：推理智能落地编程</h3> <p>除了推理能力的融合,GPT-5还有一个重要延伸——<strong>GPT-5 Codex</strong>,专门让推理智能落地到编程场景。</p> <p><strong>Codex团队做了三个升级：</strong></p> <ol> <li><strong>处理更复杂的真实编码环境</strong>：适配工业级开发需求</li> <li><strong>关注开发者的风格和习惯</strong>：能根据需求调整”模型主动性”</li> <li><strong>优化延迟时间</strong>：简单题快速答复,复杂题花更多时间求最优解,解决了过去”简单题耗时、难题不深入”的失衡问题</li> </ol> <hr/> <h2 id="二评估标准大转向从考高分到创造新可能">二、评估标准大转向：从”考高分”到”创造新可能”</h2> <h3 id="21-传统评估的饱和">2.1 传统评估的饱和</h3> <p>在GPT-2到GPT-4的时代,模型进步靠”评测(evals)”验证,分数从98%追到99%,已经逼近饱和。</p> <blockquote> <p><strong>但根据Jakub所言,GPT-5的价值,并不被定位在”答对多少题”上,而在于”能不能提出全新解法”。</strong></p> </blockquote> <h3 id="22-新的评估维度">2.2 新的评估维度</h3> <p>现在,OpenAI更关注三个维度：</p> <ol> <li>模型能不能自主发现问题？</li> <li>能不能在开放领域持续推进研究？</li> <li>能不能在没有提示的情况下找到新路径？</li> </ol> <h3 id="23-顶尖赛事中的表现">2.3 顶尖赛事中的表现</h3> <p>这种评估转向,在实际场景里已经有了清晰体现。比如在AtCoder、IMO(国际数学奥林匹克)、IOI(国际信息学奥林匹克)这些顶尖赛事中,GPT-5已经接近人类顶尖水平。</p> <p>但Jakub强调：</p> <blockquote> <p><strong>“这些比赛的排名不是重点,真正的进步是模型开始能发现新思路。”</strong></p> </blockquote> <h3 id="24-硬科学领域的突破">2.4 硬科学领域的突破</h3> <p>更让人惊喜的是硬科学领域的突破。OpenAI团队邀请许多物理学家、数学家试用后发现:</p> <ul> <li>GPT-5能提出”非平凡的新数学结果”</li> <li>过去学生要花数月计算的内容,模型几乎能自动完成</li> <li>对研究者来说,这简直是”灵光一现的时刻”</li> </ul> <h3 id="25-开放领域的探索">2.5 开放领域的探索</h3> <p>而在没有明确对错的开放领域,GPT-5的能力也很关键。</p> <p>Jakub认为：</p> <blockquote> <p><strong>“真正要推动科研,有明确定义的问题和开放性问题之间的界限会逐渐模糊。”</strong></p> </blockquote> <p>就像数学千禧难题,需要跨物理、数学分支设计研究路线,这和AI的推理本质高度契合。现在GPT-5正用长时推理能力,在这些开放领域探索未知路径。</p> <hr/> <h2 id="三强化学习推理的引擎潜力仍然巨大">三、强化学习：推理的”引擎”,潜力仍然巨大</h2> <h3 id="31-rl远未到顶点">3.1 RL远未到顶点</h3> <p>外界很多人觉得,强化学习(RL)的潜力已经耗尽了,但Jakub并不认同这种观点：</p> <blockquote> <p><strong>“RL还远未到顶点,它正让语言模型学会在复杂目标中自我进化。”</strong></p> </blockquote> <h3 id="32-语言建模与强化学习的结合">3.2 语言建模与强化学习的结合</h3> <p>其实OpenAI早在大语言模型出现前,就开始探索强化学习了。近些年来,他们最大的突破,是把”语言建模”和”强化学习”结合到了一起：</p> <ul> <li>语言模型为RL提供丰富的环境</li> <li>RL则让模型学会执行复杂目标、自主决策和修正</li> </ul> <h3 id="33-对企业的启发">3.3 对企业的启发</h3> <p>这对企业来说也有启发。现在很多公司不知道怎么设计RL奖励模型,Jakub给出了建议：</p> <blockquote> <p><strong>RL会逐渐变得更自然,未来会从”人工设置奖励”走向”类人学习”模式。</strong></p> </blockquote> <p>大家别被”当前的做法”限制,给模型一些试错空间,比制定更多规则更重要。</p> <hr/> <h2 id="四ai编程革命从vibe-coding到vibe-researching">四、AI编程革命：从”vibe coding”到”vibe researching”</h2> <h3 id="41-编程能力的飞跃">4.1 编程能力的飞跃</h3> <p>作为曾经的竞技编程选手,Jakub和Mark对AI编程的进步感触很深。现在GPT-5在很多编程比赛中已经接近顶尖人类水平,差距还在快速缩小。</p> <p>过去Jakub并不习惯使用AI工具进行编程工作,但现在他坦言：</p> <blockquote> <p><strong>“GPT-5能在15分钟里完美重构30个文件,这种生产力提升根本无法忽视。”</strong></p> </blockquote> <h3 id="42-当前的临界期">4.2 当前的临界期</h3> <p>不过目前行业还处在一个”有点不自然的临界期”——模型不像真正的同事,但大家又必须依赖它。</p> <p>就像Mark说的,很多年轻人已经把<strong>“vibe coding”(与模型协同写代码)</strong>当成默认工作方式。</p> <h3 id="43-更远大的目标">4.3 更远大的目标</h3> <p>但OpenAI的目标更加远大,他们想尽快跨过这个阶段,进入<strong>“vibe researching”(与模型协同做研究)</strong>的新时代。</p> <hr/> <h2 id="五ai的未来瞄准自动化研究员">五、AI的未来：瞄准”自动化研究员”</h2> <h3 id="51-长远目标">5.1 长远目标</h3> <p>谈到未来1-5年的路线,Jakub明确表示,GPT-5的长远目标是成为”自动化研究员”。</p> <p>他再次强调：</p> <blockquote> <p><strong>“我们希望模型能自己发现新想法,自己推进研究。”</strong></p> </blockquote> <p>而且这不只限于机器学习领域,还要推动物理、数学等其他科学领域的自动化进展。</p> <h3 id="52-两个关键突破方向">5.2 两个关键突破方向</h3> <p>要实现这个目标,有两个关键方向要突破。</p> <h4 id="521-延长思考跨度">5.2.1 延长”思考跨度”</h4> <p>目前GPT-5能连续推理1-5小时解决复杂任务,下一步要让它在更长时间线上保持规划和记忆能力,像人类研究者一样”持续推进工作”,而不是只做”短平快”的答题。</p> <h4 id="522-资源支撑">5.2.2 资源支撑</h4> <p>和过去相同,OpenAI仍然倾向于把计算资源投入核心算法研究,而不是单纯优化产品。</p> <p>Mark直言：</p> <blockquote> <p><strong>“在前沿AI研究中,计算力几乎决定一切。”</strong></p> </blockquote> <p>目前行业仍受算力限制,而非外界传言的”数据瓶颈”。</p> <h3 id="53-驻留研究员项目">5.3 驻留研究员项目</h3> <p>为了培养更多研究人才,OpenAI还推出了<strong>“驻留研究员”项目</strong>。</p> <p>这个项目能让物理、金融等非AI背景的研究者快速上手,通过”亲手实现核心成果、在错误中建立直觉”,相当于”加速版博士训练”,正好补充了学术界”长期攻坚”的优势。</p> <hr/> <h2 id="六团队文化持续学习长期主义">六、团队文化：持续学习,长期主义</h2> <h3 id="61-永不停止的学习">6.1 永不停止的学习</h3> <p>OpenAI能一直保持领先,离不开它独特的团队文化。Mark一句话道出了核心：</p> <blockquote> <p><strong>“在OpenAI,你永远不会停止学习。”</strong></p> </blockquote> <p>这里每周都有新突破,研究者必须全力以赴才能跟上,避免了其他公司”前两年学习、后续进入平台期”的困境。</p> <h3 id="62-多元化背景">6.2 多元化背景</h3> <p>背景的多元化也注定了研究者们需要具备持续学习的能力。OpenAI最成功的研究者,很多来自物理、数学、金融等非AI领域。</p> <p>他们的共同点不是背景,而是：</p> <ul> <li>扎实的技术基础</li> <li>能坚持攻克极具挑战的问题</li> </ul> <h3 id="63-用人标准">6.3 用人标准</h3> <p>在用人层面,OpenAI团队并不简单看重”社交媒体活跃度”或”表面成果”,而是更认可两种人：</p> <ol> <li><strong>擅长”提出新方向”的</strong>：不局限于实现现有想法,而是能打开全新研究思路</li> <li><strong>擅长”深挖与验证”的</strong>：能把一个想法彻底落地,通过反复实验验证价值</li> </ol> <h3 id="64-研究与产品的平衡">6.4 研究与产品的平衡</h3> <p>作为兼具顶尖研究机构和优秀产品公司属性的组织,OpenAI从研究人员的特质出发,努力做到<strong>“研究与产品”的平衡</strong>：</p> <p><strong>对研究人员的安排：</strong></p> <ul> <li>关心产品的研究员会和产品团队紧密合作</li> <li>专注基础探索的研究员则能自由创新</li> </ul> <p><strong>团队协作方式：</strong></p> <ul> <li>产品团队和领导层从不把现有产品当终点</li> <li>和研究团队一起,锚定”自动化研究员”的长期目标</li> <li>把扩散模型、代码推理等多样化方向,统一到同一路线图中</li> </ul> <h3 id="65-应对外界反馈的定力">6.5 应对外界反馈的定力</h3> <p>面对外界反馈,比如竞品发布新模型,OpenAI也有自己的定力——不被短期产品反应左右研究的优先级。</p> <p>Mark强调：</p> <blockquote> <p><strong>“研究的节奏是长期的,产品迭代更快。”</strong></p> </blockquote> <p>团队始终聚焦”未来一两年甚至更久的重大问题”,不会陷入”竞速思维”。</p> <hr/> <h2 id="结语ai从回答者变成合作者">结语：AI从”回答者”变成”合作者”</h2> <p>GPT-5不只是”长时推理时代”的开端,更在编程、硬科学领域打开了新可能。现在它不再是被动的”回答者”,而是能和人类协同研究、创造新解法的”合作者”。</p> <h3 id="对企业的三个转变">对企业的三个转变</h3> <ol> <li><strong>使用AI时</strong>：从”提问等待”升级为”共同研究”</li> <li><strong>衡量AI时</strong>：从”分数高低”转向”创新与洞见”</li> <li><strong>管理团队时</strong>：从”追热点”转向”培养长期攻坚与学习能力”</li> </ol> <h3 id="通往未来的里程碑">通往未来的里程碑</h3> <p>GPT-5不是终点,而是通往”自动化研究员”的关键里程碑。当AI能提出新数学定理、”vibe researching”成为常态,知识边界与创新模式都会被彻底重塑。</p> <blockquote> <p><strong>AI已经进入”长思考”时代,我们要学的不只是怎么用它,更是怎么跟上它的思考速度。</strong></p> </blockquote> <hr/> <p><strong>来源：</strong> 硅谷风投a16z深度访谈<br/> <strong>整理：</strong> OpenAI双巨头首次系统性揭示GPT-5定位</p>]]></content><author><name></name></author><category term="blog"/><summary type="html"><![CDATA[OpenAI双巨头首次详解GPT-5：不是下一代GPT，终极形态是AI研究员]]></summary></entry><entry><title type="html">Jason Wei：理解2025年AI进展的三种关键思路</title><link href="https://emigmo.github.io/blog/2025/jason-wei-ai-insights/" rel="alternate" type="text/html" title="Jason Wei：理解2025年AI进展的三种关键思路"/><published>2025-10-19T00:00:00+00:00</published><updated>2025-10-19T00:00:00+00:00</updated><id>https://emigmo.github.io/blog/2025/jason-wei-ai-insights</id><content type="html" xml:base="https://emigmo.github.io/blog/2025/jason-wei-ai-insights/"><![CDATA[<h1 id="jason-wei理解2025年ai进展的三种关键思路">Jason Wei：理解2025年AI进展的三种关键思路</h1> <p><em>演讲者：Jason Wei（前OpenAI核心研究员、CoT作者）</em><br/> <em>时间：2025年10月19日</em><br/> <em>地点：斯坦福大学AI Club</em><br/> <em>整理：深度访谈</em></p> <hr/> <h2 id="前言">前言</h2> <blockquote> <p><strong>「所有能被验证的任务，最终都会被 AI 解决。」</strong></p> <p><strong>「智能未来将成为一种商品，未来获取知识或进行某种推理的成本和可及性将趋近于零。」</strong></p> </blockquote> <p>最近，前 OpenAI 核心研究员、CoT（思维链）作者 Jason Wei 在斯坦福大学 AI Club 做了一场精彩的演讲。这也是他加入 Meta 超级智能实验室后少有的公开分享。</p> <p>Jason Wei 提出了三个理解和驾驭 2025 年 AI 发展至关重要的核心思想：<strong>验证者定律</strong>、<strong>智能的锯齿状边缘</strong>和<strong>智能商品化</strong>。</p> <p>某种意义上来说：</p> <ul> <li><strong>验证者定律</strong>决定「哪些点会被率先突破」</li> <li><strong>智能商品化</strong>解释「突破后如何被规模化与降本」</li> <li><strong>锯齿状边缘</strong>则强调「能力突破的时间序与不均衡版图」</li> </ul> <p>虽然没提创业，但似乎又句句不离创业。</p> <p><strong>Jason Wei 背景</strong>：目前在 Meta 超级智能实验室工作。在加入 Meta 之前，是 OpenAI 的核心科学家，参与了 o1 模型和 Deep Research 产品的创建，也是 CoT（Chain of Thought，思维链）的作者之一。</p> <hr/> <h2 id="一智能商品化智能和知识会变得又快又便宜">一、智能商品化：智能和知识会变得又快又便宜</h2> <h3 id="11-ai发展的两个阶段">1.1 AI发展的两个阶段</h3> <p>首先，我们来谈谈「智能商品化」。我认为，AI 的发展可以分为两个阶段：</p> <p><strong>第一阶段：推动前沿</strong></p> <ul> <li>AI 还不能很好地完成某项任务</li> <li>研究人员正在努力解锁这项新能力</li> <li>以 MMLU（大规模多任务语言理解）为例，过去五年的表现曲线显示性能逐渐提升</li> </ul> <p><strong>第二阶段：能力商品化</strong></p> <ul> <li>一旦 AI 掌握了某种能力，它就会被商品化</li> <li>达到特定性能水平所需的成本（以美元计）每年都在下降</li> <li>使用达到特定智能水平的模型成本趋近于零</li> </ul> <h3 id="12-自适应计算的突破">1.2 自适应计算的突破</h3> <blockquote> <p><strong>为什么这种趋势会持续下去？</strong></p> </blockquote> <p>我的观点是，这是深度学习历史上，<strong>自适应计算（adaptive compute）第一次真正奏效</strong>。</p> <p><strong>过去的模式</strong>：</p> <ul> <li>无论任务简单还是困难，用于解决特定问题的计算量都是固定的</li> <li>回答「加利福尼亚州的首府是什么」和解决奥数竞赛题使用相同的计算量</li> </ul> <p><strong>现在的突破</strong>：</p> <ul> <li>进入自适应计算时代，可以根据任务调整所使用的计算量</li> <li>如果任务非常简单，可以将计算成本降到最低</li> <li>不再需要持续扩大模型规模</li> </ul> <p><strong>o1模型的证明</strong>：</p> <ul> <li>一年多前发布的 o1 模型是最初突破</li> <li>在测试阶段为解决数学问题投入更多计算资源</li> <li>模型在基准测试上的表现显著提升</li> </ul> <h3 id="13-信息检索的四个时代">1.3 信息检索的四个时代</h3> <p>AI 商品化还有另外一个方面是，<strong>获取公共信息的时间会越来越短</strong>。我把信息检索分成了四个时代：</p> <table> <thead> <tr> <th>时代</th> <th>示例问题</th> <th>所需时间</th> <th>方法</th> </tr> </thead> <tbody> <tr> <td><strong>前互联网时代</strong></td> <td>1983年釜山的人口</td> <td>几小时</td> <td>开车去图书馆，翻阅百科全书</td> </tr> <tr> <td><strong>互联网时代</strong></td> <td>同上</td> <td>几分钟</td> <td>搜索引擎，浏览网页</td> </tr> <tr> <td><strong>聊天机器人时代</strong></td> <td>同上</td> <td>即时</td> <td>直接询问ChatGPT</td> </tr> <tr> <td><strong>智能Agent时代</strong></td> <td>1983年亚洲最多人口30城市的结婚人数排序</td> <td>几小时→几分钟</td> <td>AI自主搜索、分析、整合</td> </tr> </tbody> </table> <p><strong>复杂查询示例</strong>：</p> <ul> <li>问题：「1983 年釜山有多少人结婚」</li> <li>GPT-3：无法完成</li> <li><strong>OpenAI Operator</strong>：可以做到 <ul> <li>访问韩国统计信息服务（KOSIS）数据库</li> <li>自主点击查找</li> <li>找到正确的数据库查询</li> <li>返回答案</li> </ul> </li> </ul> <h3 id="14-browsecomp基准测试">1.4 BrowseComp基准测试</h3> <p>为了衡量这种能力，OpenAI 创建了 <strong>BrowseComp 基准测试</strong>：</p> <p><strong>特点</strong>：</p> <ul> <li>答案容易验证，但找答案非常耗时</li> <li>示例：「找出符合所有这些限制条件的足球比赛」</li> </ul> <p><strong>人类vs AI表现</strong>：</p> <ul> <li>人类：平均需要两个多小时，很多问题在两小时内无法完成</li> <li><strong>OpenAI Deep Research</strong>：可以解决其中大约一半的问题</li> </ul> <h3 id="15-智能商品化的三大影响">1.5 智能商品化的三大影响</h3> <p><strong>1. 领域民主化</strong></p> <blockquote> <p>那些过去因为知识门槛（比如编程）而受限的领域，会变得更加开放。</p> </blockquote> <ul> <li><strong>编程</strong>：技术门槛大幅降低</li> <li><strong>个人健康</strong>：过去去医生那里说「我想改善我的鼻呼吸」，医生可能只会说「试试我告诉你的方法」。但现在，ChatGPT 几乎能提供一个好医生能给你的所有信息</li> </ul> <p><strong>2. 私有信息价值提升</strong></p> <blockquote> <p>既然公共信息的成本降得这么低，那那些私密的、内部的、不公开的信息，相对价值就会高得多。</p> </blockquote> <ul> <li>非市场挂牌出售的房屋信息更值钱</li> <li>内部数据、专有知识的价值凸显</li> </ul> <p><strong>3. 个性化信息流</strong></p> <blockquote> <p>你访问的不再是人人共享的公共互联网，而是一个为你量身定制的个性化互联网。</p> </blockquote> <ul> <li>获取信息变得无摩擦、毫不费力</li> <li>AI会专门为你展示你想知道的内容</li> </ul> <hr/> <h2 id="二验证者定律训练ai解决任务的能力与任务的可验证性成正比">二、验证者定律：训练AI解决任务的能力与任务的可验证性成正比</h2> <h3 id="21-验证与求解的不对称性">2.1 验证与求解的不对称性</h3> <p><strong>核心概念</strong>：</p> <blockquote> <p>对于某些任务，验证解决方案比找到解决方案要容易得多。</p> </blockquote> <p><strong>典型示例</strong>：</p> <table> <thead> <tr> <th>任务类型</th> <th>生成难度</th> <th>验证难度</th> <th>不对称性</th> </tr> </thead> <tbody> <tr> <td><strong>数独</strong></td> <td>中等</td> <td>容易</td> <td>正向（易验证）</td> </tr> <tr> <td><strong>Twitter代码</strong></td> <td>困难（需几千工程师）</td> <td>容易（刷网页点几下）</td> <td>正向（易验证）</td> </tr> <tr> <td><strong>竞赛数学题</strong></td> <td>困难</td> <td>中等</td> <td>平衡</td> </tr> <tr> <td><strong>数据处理脚本</strong></td> <td>简单（自己写）</td> <td>困难（理解别人代码）</td> <td>反向（难验证）</td> </tr> <tr> <td><strong>事实性文章</strong></td> <td>容易（编造听起来有理的事实）</td> <td>困难（逐条核实）</td> <td>反向（难验证）</td> </tr> <tr> <td><strong>饮食方案</strong></td> <td>容易（随口说出）</td> <td>困难（需长期实验验证）</td> <td>反向（难验证）</td> </tr> </tbody> </table> <h3 id="22-验证者定律的定义">2.2 验证者定律的定义</h3> <blockquote> <p><strong>验证者定律（Verifiers Law）：训练 AI 解决任务的能力，与该任务的可验证性成正比。</strong></p> </blockquote> <p><strong>推论</strong>：</p> <ul> <li>任何<strong>可解决且易于验证</strong>的任务，最终都会被 AI 攻克</li> <li>首先被自动化的任务，将是那些非常容易验证的任务</li> </ul> <h3 id="23-可验证性的五个维度">2.3 可验证性的五个维度</h3> <p>具体来说，我认为「可验证性」体现在以下五个方面：</p> <ol> <li><strong>客观性</strong>：有没有明确的对错标准？</li> <li><strong>验证速度</strong>：检查起来快不快？</li> <li><strong>可批量验证</strong>：能不能一次性检查几百万个方案？</li> <li><strong>低噪音</strong>：验证结果是否稳定可靠？</li> <li><strong>连续反馈</strong>：是只有「对」和「错」两种结果，还是能给出具体的分数，衡量质量的好坏？</li> </ol> <h3 id="24-特权信息改变任务位置">2.4 特权信息改变任务位置</h3> <p>有意思的是，你可以通过提供一些<strong>特权信息（privileged information）</strong>来改变任务在「生成-验证」图上的位置：</p> <p><strong>示例</strong>：</p> <ul> <li><strong>竞赛数学</strong>：如果给你提供答案，检查就变得非常容易</li> <li><strong>编程任务</strong>：如果给你测试用例（如 SWE-bench），检查也变得非常容易</li> </ul> <blockquote> <p><strong>核心思想</strong>：有些任务你可以预先做一些工作，从而增加验证的不对称性。</p> </blockquote> <h3 id="25-ai基准测试的快速攻克">2.5 AI基准测试的快速攻克</h3> <p>大多数 AI 基准测试，从定义上来说，都是易于验证的。</p> <p><strong>历史证明</strong>：</p> <ul> <li>过去五年中关注的所有基准测试都相对快速地被 AI 解决</li> <li>这是验证者定律的最好实例</li> </ul> <h3 id="26-deepmind-alphadev的实践">2.6 DeepMind AlphaDev的实践</h3> <p><strong>AlphaDev项目</strong>是利用验证不对称性的绝佳例子：</p> <p><strong>任务示例</strong>：</p> <blockquote> <p>「找到这 11 个六边形的放置方式，使得围绕它们绘制的最小外围六边形面积最小。」</p> </blockquote> <p><strong>符合五个标准</strong>：</p> <ul> <li>✅ 结果客观（画出来就能验证）</li> <li>✅ 验证速度快且可扩展（计算性的，能批量检查）</li> <li>✅ 噪音低（每次检查结果都一样）</li> <li>✅ 连续反馈（外接六边形的大小直接反映方案优劣）</li> </ul> <p><strong>进化式搜索算法</strong>：</p> <pre><code class="language-mermaid">graph LR
    A[生成Sample] --&gt; B[评估Grade]
    B --&gt; C[迭代Iterate]
    C --&gt; A
    style A fill:#e1f5ff
    style B fill:#ffe1e1
    style C fill:#e1ffe1
</code></pre> <ol> <li><strong>生成（Sample）</strong>：让大语言模型生成大量候选解决方案（代码）</li> <li><strong>评估（Grade）</strong>：任务高度可验证，自动、快速地给每个方案打分</li> <li><strong>迭代（Iterate）</strong>：将得分最高的方案作为「灵感」，反馈给大语言模型</li> </ol> <p><strong>成果</strong>：</p> <ul> <li>通过投入海量计算资源进行循环</li> <li>能够发现比人类专家设计的算法更优的解</li> </ul> <p><strong>聪明之处</strong>：</p> <ul> <li>巧妙地避开了「泛化」问题</li> <li>训练和测试是同一个任务</li> <li>只关心解决这一个具体问题</li> <li>需要挑选那些有可能找到比已知答案更好的答案的问题</li> </ul> <h3 id="27-创业启示">2.7 创业启示</h3> <blockquote> <p><strong>未来一个非常重要的领域（无论是你想创业还是看好它会发展），就是发明衡量事物的方法。</strong></p> </blockquote> <p><strong>机会点</strong>：</p> <ul> <li>如果你能为某个原本难以衡量的领域（比如创造力、用户体验）设计出一套快速、客观、可扩展的评估体系</li> <li>那么接下来就可以利用 AI 来大规模地优化它</li> </ul> <hr/> <h2 id="三智能的锯齿状边缘发展不均衡">三、智能的锯齿状边缘：发展不均衡</h2> <h3 id="31-对ai影响的分歧">3.1 对AI影响的分歧</h3> <blockquote> <p><strong>「AI 的发展会怎么改变我们的世界？」</strong></p> </blockquote> <p>你会发现，不同的人会给出完全不同的答案：</p> <p><strong>量化交易朋友的看法</strong>：</p> <blockquote> <p>「ChatGPT 确实很酷，但它做不了我工作中那些具体的事情。」</p> </blockquote> <p><strong>顶尖实验室AI研究员的看法</strong>：</p> <blockquote> <p>「我们基本上只剩下两到三年的工作时间了，之后 AI 就会取代我们的工作。」</p> </blockquote> <p><strong>Boaz的观点</strong>：</p> <blockquote> <p>「东海岸的人低估了即将到来的变革，他们可能会说’哦，当前的模型做不到这个’，而不太考虑其发展轨迹。而在湾区，可能又会低估把我们训练出来的模型真正落地应用，需要克服多少障碍，耗费多少时间。」</p> </blockquote> <p><strong>Roon的观点</strong>：</p> <blockquote> <p>「现在不应该给出或接受任何职业建议。所有人普遍低估了变革的广度和规模，还有未来职业生涯的巨大不确定性。」</p> </blockquote> <h3 id="32-为什么快速起飞不会发生">3.2 为什么「快速起飞」不会发生</h3> <p>长期以来，有一个假说叫做<strong>「快速起飞」（fast takeoff）</strong>：</p> <p><strong>假说内容</strong>：</p> <ul> <li>一旦 AI 在某个方面超越了人类</li> <li>就会突然变得比人类强大得多</li> <li>在很短的时间内，实现智能的爆炸式增长</li> </ul> <p><strong>我的观点</strong>：这种情景可能不会发生。</p> <p><strong>更现实的场景</strong>：</p> <table> <thead> <tr> <th>时间线</th> <th>AI能力状态</th> </tr> </thead> <tbody> <tr> <td><strong>第一年</strong></td> <td>AI连研究代码库都跑不起来</td> </tr> <tr> <td><strong>第二年</strong></td> <td>AI可以勉强训练一个模型，但效果很差</td> </tr> <tr> <td><strong>第三年</strong></td> <td>AI可以自主训练了，但效果不如顶尖的人类研究团队</td> </tr> <tr> <td><strong>第四年</strong></td> <td>AI训练得很好，但偶尔还需要人类介入来解决疑难杂症</td> </tr> </tbody> </table> <blockquote> <p><strong>这更像是一个自我改进能力的「光谱」，而不是一个二元的选择。</strong></p> </blockquote> <h3 id="33-锯齿状边缘的形成">3.3 锯齿状边缘的形成</h3> <p><strong>核心观点</strong>：</p> <ul> <li>自我改进的速度，应该按「每个具体任务」来考量</li> <li>各种任务就像锯齿状的边缘</li> </ul> <pre><code class="language-mermaid">graph TD
    A[AI能力版图] --&gt; B[高峰：表现出色的领域]
    A --&gt; C[低谷：表现较弱的领域]
    B --&gt; D[复杂数学题]
    B --&gt; E[编程竞赛题]
    C --&gt; F[9.11 vs 9.9比较]
    C --&gt; G[特林吉特语翻译]
    style B fill:#90EE90
    style C fill:#FFB6C1
</code></pre> <p><strong>高峰示例</strong>（AI表现出色）：</p> <ul> <li>复杂的数学题</li> <li>某些编程竞赛题</li> </ul> <p><strong>低谷示例</strong>（AI表现较弱）：</p> <ul> <li>ChatGPT 曾经很长时间都说 9.11 比 9.9 大</li> <li>特林吉特语（Tlingit）翻译：只有几百个美洲原住民才会说的语言</li> </ul> <blockquote> <p><strong>我并不认为我们会看到这样的情况：一个自我改进的模型，突然之间就什么都搞定了。</strong></p> </blockquote> <h3 id="34-预测ai进步速度的三个窍门">3.4 预测AI进步速度的三个窍门</h3> <h4 id="窍门1ai擅长数字任务">窍门1：AI擅长数字任务</h4> <p><strong>原因</strong>：</p> <ul> <li>核心是<strong>迭代速度</strong></li> <li>搞数字任务，扩展计算资源比用真实机器人做实验容易多了</li> </ul> <p><strong>示例</strong>：</p> <ul> <li>「家庭作业机器」漫画（1981年）：对AI工作方式的描绘在今天看来还挺准</li> <li>《我，机器人》那种场景：也许很快会有，但目前还没实现</li> </ul> <h4 id="窍门2对人类来说越容易的任务ai往往也觉得越容易">窍门2：对人类来说越容易的任务，AI往往也觉得越容易</h4> <p><strong>推论</strong>：</p> <ul> <li>可以想象一下人类任务难度的分布</li> <li>AI可能能完成人类因为生理限制而无法完成的任务 <ul> <li>示例：预测乳腺癌（如果能看过1000万张图像）</li> </ul> </li> </ul> <h4 id="窍门3数据越充足ai就越如鱼得水">窍门3：数据越充足，AI就越如鱼得水</h4> <p><strong>实证</strong>：</p> <ul> <li>语言模型在不同语言中的数学表现</li> <li>某个语言的「使用频率」（数据量）和它的表现呈正相关</li> <li><strong>趋势非常明显：数据越多，AI在这个任务上就表现得越好</strong></li> </ul> <p><strong>强化学习的补充</strong>：</p> <blockquote> <p>如果存在一个明确的、单一的客观评估指标，那么你就可以采用 AlphaEvolve 或 AlphaZero 的策略，通过强化学习来生成「假数据」，实现自我训练。</p> </blockquote> <p><strong>Danny Do的推特</strong>：</p> <blockquote> <p>「只要任务提供清晰的评估指标，可以作为训练时的奖励信号，任何基准测试都可以被迅速解决。」</p> </blockquote> <h3 id="35-ai任务时间表预测">3.5 AI任务时间表预测</h3> <table> <thead> <tr> <th>任务</th> <th>人类难度</th> <th>是否数字任务</th> <th>数据充足度</th> <th>预计时间</th> </tr> </thead> <tbody> <tr> <td><strong>翻译（前50种语言）</strong></td> <td>不难</td> <td>✅</td> <td>充足</td> <td>✅ 已完成</td> </tr> <tr> <td><strong>调试基础代码</strong></td> <td>中等</td> <td>✅</td> <td>充足</td> <td>✅ 2023年</td> </tr> <tr> <td><strong>竞赛数学</strong></td> <td>难</td> <td>✅</td> <td>充足</td> <td>✅ 2024年</td> </tr> <tr> <td><strong>AI研究</strong></td> <td>很难</td> <td>✅</td> <td>中等</td> <td>🔮 2027年？</td> </tr> <tr> <td><strong>化学研究</strong></td> <td>难</td> <td>❌</td> <td>中等</td> <td>🔮 比AI研究晚</td> </tr> <tr> <td><strong>拍电影</strong></td> <td>非常难</td> <td>✅</td> <td>充足</td> <td>🔮 2029年？</td> </tr> <tr> <td><strong>预测股市</strong></td> <td>极难</td> <td>✅</td> <td>充足</td> <td>❓ 不确定</td> </tr> <tr> <td><strong>翻译特林吉特语</strong></td> <td>不难（对懂的人）</td> <td>✅</td> <td>极少</td> <td>❌ 可能性极低</td> </tr> <tr> <td><strong>修水管</strong></td> <td>中等</td> <td>❌</td> <td>不确定</td> <td>❓ 不确定</td> </tr> <tr> <td><strong>理发</strong></td> <td>中等</td> <td>❌</td> <td>中等</td> <td>❌ 很难</td> </tr> <tr> <td><strong>手工地毯制作</strong></td> <td>非常难</td> <td>❌</td> <td>极少</td> <td>❌ 短期不可能</td> </tr> <tr> <td><strong>带女朋友约会让她开心</strong></td> <td>😊</td> <td>❌</td> <td>极少</td> <td>❌ 永远搞不定！</td> </tr> </tbody> </table> <blockquote> <p><strong>注</strong>：这些年份都是我随口说的，大家别当真。</p> </blockquote> <h3 id="36-总结与启示">3.6 总结与启示</h3> <p><strong>核心观点</strong>：</p> <ol> <li>不会出现某种快速的超级智能起飞</li> <li>每项任务的能力和改进速度都不同</li> <li>AI影响最大的，是那些符合特定属性的任务： <ul> <li>✅ 数字任务</li> <li>✅ 对人类来说不难</li> <li>✅ 数据丰富</li> </ul> </li> </ol> <p><strong>影响预测</strong>：</p> <pre><code class="language-mermaid">graph LR
    A[AI影响] --&gt; B[极大加速的领域]
    A --&gt; C[保持不变的领域]
    B --&gt; D[软件开发]
    B --&gt; E[数据分析]
    B --&gt; F[内容创作]
    C --&gt; G[理发]
    C --&gt; H[水管维修]
    C --&gt; I[手工艺品]
    style B fill:#90EE90
    style C fill:#FFE4B5
</code></pre> <ul> <li><strong>某些领域将因 AI 而极大地加速</strong>：例如软件开发</li> <li><strong>另一些领域可能会保持不变</strong>：例如理发</li> </ul> <hr/> <h2 id="四结语与思考">四、结语与思考</h2> <p>Jason Wei 的三个核心思想为我们理解2025年AI发展提供了一个完整的框架：</p> <h3 id="核心框架总结">核心框架总结</h3> <pre><code class="language-mermaid">graph TD
    A[AI发展框架] --&gt; B[验证者定律]
    A --&gt; C[智能商品化]
    A --&gt; D[锯齿状边缘]
    B --&gt; E[决定哪些点被率先突破]
    C --&gt; F[解释突破后如何规模化与降本]
    D --&gt; G[强调能力突破的时间序与不均衡]
    style A fill:#FFD700
    style B fill:#87CEEB
    style C fill:#90EE90
    style D fill:#FFB6C1
</code></pre> <h3 id="对创业者的启示">对创业者的启示</h3> <p>虽然演讲没有直接提到创业，但其中蕴含的洞察对创业者极具价值：</p> <ol> <li> <p><strong>选择易验证的问题域</strong></p> <ul> <li>优先进入那些可以快速验证结果的领域</li> <li>投资于建立评估体系</li> </ul> </li> <li> <p><strong>关注成本降低趋势</strong></p> <ul> <li>智能商品化意味着私有信息的价值提升</li> <li>专注于获取和利用独特的数据资源</li> </ul> </li> <li> <p><strong>理解不均衡发展</strong></p> <ul> <li>不要指望AI在所有领域同步突破</li> <li>在数字任务、数据丰富的领域优先布局</li> <li>物理世界的服务仍将是人类的优势领域</li> </ul> </li> </ol> <h3 id="对研究者的启示">对研究者的启示</h3> <ol> <li> <p><strong>关注验证机制设计</strong></p> <ul> <li>好的验证机制能加速AI在该领域的进步</li> <li>评估体系的设计本身就是重要的研究课题</li> </ul> </li> <li> <p><strong>重视自适应计算</strong></p> <ul> <li>Test-time compute是重要的研究方向</li> <li>如何根据任务难度动态调整计算资源</li> </ul> </li> <li> <p><strong>数据效率仍然重要</strong></p> <ul> <li>长尾任务、小语种、特殊领域的数据仍然稀缺</li> <li>如何用有限数据达到好效果仍是关键问题</li> </ul> </li> </ol> <h3 id="最后的思考">最后的思考</h3> <p>Jason Wei 的框架提醒我们：</p> <blockquote> <p><strong>AI的发展不是一场革命，而是一系列不均衡的进化。</strong></p> </blockquote> <p>我们不应该期待某个「奇点」时刻的到来，而应该理解：</p> <ul> <li>哪些任务会被快速解决（易验证、数字化、数据丰富）</li> <li>哪些能力会被商品化（成本趋近于零）</li> <li>哪些领域仍将保持人类优势（物理世界、低数据领域）</li> </ul> <p>这种务实而精准的视角，或许正是我们在AI时代最需要的。</p> <hr/> <p><strong>演讲视频</strong>：<a href="https://www.youtube.com/watch?v=b6Doq2fz81U">Jason Wei at Stanford AI Club</a></p> <p><strong>编译整理</strong>：Founder Park</p>]]></content><author><name></name></author><category term="blog"/><summary type="html"><![CDATA[Jason Wei：理解2025年AI进展的三种关键思路]]></summary></entry><entry><title type="html">Nick Joseph访谈：Anthropic预训练的核心思考与实践</title><link href="https://emigmo.github.io/blog/2025/anthropic-pretraining-nick-joseph/" rel="alternate" type="text/html" title="Nick Joseph访谈：Anthropic预训练的核心思考与实践"/><published>2025-10-10T00:00:00+00:00</published><updated>2025-10-10T00:00:00+00:00</updated><id>https://emigmo.github.io/blog/2025/anthropic-pretraining-nick-joseph</id><content type="html" xml:base="https://emigmo.github.io/blog/2025/anthropic-pretraining-nick-joseph/"><![CDATA[<h1 id="nick-joseph访谈anthropic预训练的核心思考与实践">Nick Joseph访谈：Anthropic预训练的核心思考与实践</h1> <p><em>访谈对象：Nick Joseph（Anthropic预训练团队负责人）</em><br/> <em>时间：2025年10月10日</em><br/> <em>来源：Y Combinator深度访谈</em></p> <hr/> <h2 id="前言">前言</h2> <p>本文基于Y Combinator于2025年9月30日对Anthropic预训练团队负责人Nick Joseph的深度访谈整理而成。Nick Joseph曾在Vicarious和OpenAI从事AI安全与模型缩放研究，深度参与了多代大语言模型的开发与优化。</p> <p><strong>核心观点速览：</strong></p> <ul> <li>预训练的核心是推动损失函数下降，这是我们一直追求的唯一目标</li> <li>对齐问题在于如何让模型分享人类的目标，尤其是在模型比人类更聪明时</li> <li>如果拥有无限计算资源，真正的挑战将是如何有效利用这些资源并解决规模扩展中的工程难题</li> <li>当前AI研究最大的瓶颈之一是计算资源受限，而非算法突破</li> </ul> <hr/> <h2 id="目录">目录</h2> <ul> <li><a href="#一从ai安全初心到anthropic预训练掌舵人">一、从AI安全初心到Anthropic预训练掌舵人</a></li> <li><a href="#二预训练基石与扩展定律自回归建模成为ai发展的核心引擎">二、预训练基石与扩展定律：自回归建模成为AI发展的核心引擎</a></li> <li><a href="#三工程实战深水区万卡集群硬件极限调试与分布式训练挑战">三、工程实战深水区：万卡集群、硬件极限调试与分布式训练挑战</a></li> <li><a href="#四合成数据风险模型评估指标设计与价值嵌入博弈">四、合成数据风险、模型评估指标设计与价值嵌入博弈</a></li> <li><a href="#五agi之路范式转移焦虑架构变革与未来展望">五、AGI之路：范式转移焦虑、架构变革与未来展望</a></li> </ul> <hr/> <h2 id="一从ai安全初心到anthropic预训练掌舵人">一、从AI安全初心到Anthropic预训练掌舵人</h2> <h3 id="11-从vicarious到openai的早期探索">1.1 从Vicarious到OpenAI的早期探索</h3> <p><strong>Ankit Gupta</strong>：大家好，今天非常高兴邀请到Anthropic的预训练负责人Nick Joseph来和我们对谈。我想先聊一聊你的背景，了解一下你是如何走到今天这一步的。</p> <p><strong>Nick Joseph</strong>：我之前在Vicarious工作，后来去了OpenAI，然后才加入Anthropic。Vicarious最初是一家以AGI为目标的实验室，我加入时他们正处于转型阶段，逐渐开始开发一些具体的产品，尤其是机器人相关的项目。我当时负责的主要是为机器人产品训练计算机视觉模型。那是我的第一份工作，所以我在那段时间主要学会了如何构建机器学习模型，以及如何搭建机器学习的基础设施。</p> <h3 id="12-选择实践而非学术的职业路线">1.2 选择实践而非学术的职业路线</h3> <p><strong>Ankit Gupta</strong>：那时候你有没有考虑过走学术路线？</p> <p><strong>Nick Joseph</strong>：其实我对这件事的想法有点不同，这很大程度上源于我之前在一个叫GiveWell的非营利机构实习的经历。GiveWell主要负责评估慈善项目的效果，当时那里有一些人提出——也许未来我们会拥有AGI，而它可能带来风险，需要提前关注这种潜在的威胁。</p> <p>那时我对这种说法并不是特别信服，我更倾向于直接去做一些可以帮助贫困人口的事情。后来因为种种原因，这条路没有走通，于是我决定至少去做AI相关的工作。这样无论未来AI安全是不是一个重大问题，我都能有所贡献：如果它真的重要，我就投身其中；如果不是，我也能用AI创造出一些能切实帮助贫困人群的东西。</p> <blockquote> <p><strong>所以我并不是以学术研究为出发点来进入这个领域。实际上，我之所以选择这条路，其中一个吸引我的地方是——我可以立即投入到AI实践中去。</strong></p> </blockquote> <h3 id="13-ai安全的早期状态与哲学探讨">1.3 AI安全的早期状态与哲学探讨</h3> <p><strong>Ankit Gupta</strong>：那么，当时AI安全这方面的研究处于什么状态呢？</p> <p><strong>Nick Joseph</strong>：在我看来，当时关于AI安全的大部分讨论都还停留在理论层面。那时候的模型其实并没有多强，也不存在真正的威胁。因此，当时的讨论更多是哲学性的——比如，假设未来我们会拥有比人类更聪明的AI，那我们是否应该提前重视这种潜在风险？</p> <h3 id="14-加入openai与代码能力的惊人突破">1.4 加入OpenAI与代码能力的惊人突破</h3> <p><strong>Ankit Gupta</strong>：接下来你去了OpenAI。当时的OpenAI是什么样的？</p> <p><strong>Nick Joseph</strong>：我当时加入的是一个安全研究团队，同时也在参与代码模型的相关研究。刚到那儿时，我看到的第一个项目就是他们对GPT-3进行微调，让它能够写代码。而且效果相当好。</p> <p>这让我突然意识到——如果人们担心AI会变得极其强大，甚至能自我编写、改进自己的代码，那么这种能力确实看起来有可能导致自我提升。于是我开始做很多评估和研究，分析哪些因素会促成这种能力。</p> <p>大概八个月后，我所在团队的几位AI安全负责人相继离开，而我之所以加入OpenAI，本身就是因为我非常关心AI安全问题，希望能和他们共事。后来他们中的一些人去了Anthropic，我也几乎在Anthropic成立初期就跟随加入了。</p> <hr/> <h2 id="二预训练基石与扩展定律自回归建模成为ai发展的核心引擎">二、预训练基石与扩展定律：自回归建模成为AI发展的核心引擎</h2> <h3 id="21-什么是预训练从互联网数据到下一个词预测">2.1 什么是预训练？从互联网数据到下一个词预测</h3> <p><strong>Ankit Gupta</strong>：既然提到了Anthropic，我们就来聊聊你现在的工作吧。如今你是Anthropic的预训练团队负责人。你能先谈谈什么是”预训练”吗？</p> <p><strong>Nick Joseph</strong>：我们知道让AI模型变得更强的关键要素之一就是”规模”。你需要投入大量的算力。而如果退一步思考，要想让模型获得尽可能多的算力，我们就需要一个拥有海量数据的训练目标。</p> <p>一个显而易见的想法是——互联网本身就是庞大的数据源，可能是人类历史上最大的数据集合。而且这些数据是无标签的，你不可能指望有人去把整个互联网内容都看一遍、逐条标注。因此，我们希望能从数据本身提取出”标签”。</p> <blockquote> <p><strong>于是，就有了这样的思路：我们可以让模型预测下一个词。这种方式的好处是，你能得到非常密集的学习信号——每一个词都是一个新的训练样本。</strong></p> </blockquote> <p>从GPT-1到GPT-2的研究发现，只要你持续增加算力、使用更多数据、训练更大的模型，模型的能力就会不断增强，表现也会更智能。可以说，这就是整个预训练理念的核心假设。</p> <h3 id="22-扩展定律与正反馈循环">2.2 扩展定律与正反馈循环</h3> <p>这里还涉及”扩展定律”的概念，也就是说，我们可以用相当精确的方式去量化：当你增加算力、数据量或模型参数时，模型在预测下一个词时的损失会以可预期的方式降低，性能也会相应提升。</p> <p>真正出乎意料的是，这一机制形成了一个<strong>“正反馈循环”</strong>：</p> <ol> <li>你训练出一个模型</li> <li>它能被用来创造有用的产品</li> <li>这些产品带来收入</li> <li>你再把收入投入更多算力</li> <li>从而训练出更好的模型</li> </ol> <p>过去五年左右，我们其实反复地在运行这一循环。</p> <h3 id="23-为什么自回归建模胜出">2.3 为什么自回归建模胜出？</h3> <p><strong>Ankit Gupta</strong>：”下一个词预测”这种自回归方式似乎已经成为主流的预训练方法。但如果回到2017年至2020年，当时其实存在各种各样不同的预训练目标。例如BERT、BART这些模型采用的是”掩码语言建模”。你对那个阶段有什么回顾或感想吗？</p> <p><strong>Nick Joseph</strong>：我认为答案主要是经验驱动的——换句话说，我们是通过大量实验得出的。我的观点是，这类问题最终要靠实证：都试一试，看哪种更有效。</p> <p><strong>自回归建模的巨大优势：</strong></p> <ul> <li>你可以直接从模型中采样生成文本，这个过程非常自然</li> <li>损失函数本身就能直接反映出你真正关心的目标</li> <li>如果你能把这个任务做到完美，模型自然就能像人一样写作</li> <li>容易转化为产品应用</li> </ul> <p>相比之下，其他一些方法并不具备这种天然的生成特性。</p> <h3 id="24-算力才是王道">2.4 算力才是王道</h3> <p><strong>Nick Joseph</strong>：没错，这种方式赋予了模型最具开放性的潜力。一般的流程是：你先训练一个基础模型，然后针对不同任务进行微调。</p> <p>不过我总体的直觉是：<strong>真正起决定作用的是算力</strong>。只要你投入足够的算力，无论采用哪种预训练目标，最终都能训练出表现不错的模型，然后再通过微调适配各种用途。</p> <blockquote> <p><strong>令人意外的是，很多我们以为关键的细节，其实远不如”增加算力”来得重要。</strong></p> </blockquote> <hr/> <h2 id="三工程实战深水区万卡集群硬件极限调试与分布式训练挑战">三、工程实战深水区：万卡集群、硬件极限调试与分布式训练挑战</h2> <p>Ankit Gupta：确实如此。而且当我们谈到“增加算力”时，这本身也有很多维度。比如，对于一个固定的模型架构，你可以给它输入更多数据；或者让模型更深，增加层数或参数量；再或者通过神经架构搜索去尝试不同结构的组合。我想如今大家已经比较明确哪种架构更有效，但在早期阶段，这方面的探索应该更具不确定性。能否谈谈当时你们是怎么思考这些问题的？你们的基础设施又是怎样支持这些探索和决策的？</p> <p>Nick Joseph：我想，简短的答案是——这真的很难。你要做的事情其实是训练一个庞大而昂贵的模型，而你面对的是一个包含上百个超参数的空间。比如你要决定层数、宽度等等，而你希望所有这些超参数都能最优。你需要在“它们到底重要到什么程度”之间取得平衡——也就是说，你能不能凭直觉选一个差不多的配置，然后只要增加算力就能得到不错的效果？</p> <p>Ankit Gupta：也就是说，没关系你怎么调都行？</p> <p>Nick Joseph：对，只要别太离谱。但有趣的是，实际上这并没有那么重要。我记得这在早期的扩展定律论文里也提到过——你可以调整这些参数获得一些小的提升，但只要你持续增加计算资源，模型的性能一般都会稳定地提升。当然，如果你调得太离谱，效果会停止提升，但你又不会知道到底出了什么问题。这其实是最难的部分之一。</p> <p>Ankit Gupta：因为你不知道反事实是什么，对吧？你没有足够长时间去跑出结果。</p> <p>Nick Joseph：对。我们有这些“扩展定律”，你可以预期，当你增加计算量时，损失值会按幂律下降——实际上是“幂律+常数”。所以最终你会看到这条曲线开始偏离幂律，这就意味着出问题了。而这时问题可能是根本性的，也可能只是你应该微调一下学习率。如何判断是哪一种，就是一大挑战。通常的做法是先在小规模下测试，再在大规模上运行。</p> <p>Ankit Gupta：这里的小规模是指数据规模，还是别的？</p> <p>Nick Joseph：是所有方面。你希望比例缩放，比如如果你要把计算量增加十倍，你就要有一套理论去指导：这十倍的算力该怎么分配——多少给层数、多少给数据、多少给注意力机制。然后在小规模下按比例缩放去验证。</p> <p>Ankit Gupta：那在Anthropic早期，你们团队可能十来个人的时候，作为一个小型但有资金的创业公司，你们当时能用到什么样的大规模基础设施？</p> <p>Nick Joseph：这其实是件挺疯狂的事。你永远不知道别人到底在做什么，但我们感觉自己就在最前沿。那时关心这件事的人其实很少。我当时的心态是：我们在做AGI，这是人类历史上最重要的技术。但我环顾四周，发现好像全世界只有30个人在认真干这件事。虽然我只是个初级工程师，但我惊讶于事情的“简单”——比如当时公开估算GPT-3的训练成本是500万美元。听起来多，但从公司角度看其实不算高。所以我们完全能买到足够的算力来训练类似规模的模型。</p> <p>Ankit Gupta：你们是用云计算，还是自建机房？</p> <p>Nick Joseph：我们用的是云服务，但其实差别不大。让我意外的是，我们真的得理解硬件的物理布局。有次同事甚至跑了聚类算法来推测芯片分布在哪些机房，因为我们怀疑不同机房间的网络延迟导致训练瓶颈。结果真能“反推”出来两个聚类，连接状况不同。这种极限优化在当时很重要——我们资金比别人少，只能靠算力效率取胜。</p> <p>Ankit Gupta：那你们具体做了什么来提升算力利用率？这听起来像早期Google那种“便宜硬件+极致优化”的故事。</p> <p>Nick Joseph：我们主要是把分布式框架调到极致。因为训练要跨大量GPU并行进行。分布式有多种模式：数据并行、流水线并行、模型并行等，要把这些都整合好。</p> <p>Ankit Gupta：那时候还没有现成的开源框架能直接用，对吧？</p> <p>Nick Joseph：对，有一些，但很有限。比如我们当时用的数据并行方法需要自己写all-reduce通信，不能完全依赖现有包。因为像PyTorch Distributed虽然有工具，但我们要扩展到比Facebook还大的规模，就得自己写，以便后续能灵活修改。</p> <p>Ankit Gupta：你刚说“我们要比Facebook更大规模”，这挺颠覆的。毕竟那时Facebook AI Research是最顶尖实验室之一。你们不觉得冒险吗？</p> <p>Nick Joseph：确实有点意外。但也许我有点自信过头吧。当时我觉得他们都忽略了重点。扩展定律已经很清楚了，而反对的论点听起来没道理。那篇原始论文横跨11个数量级，学界却争论它能不能再延伸一个数量级——我觉得，这种怀疑没什么根据。</p> <p>Ankit Gupta：毕竟都已经延展11个数量级了。</p> <p>Nick Joseph：对，所以我觉得继续下去的概率相当高。而且这类规律很多时候真的就是“直接有效”。但我能理解，从外部看就没那么显然——论文太多，每篇都说自己很重要。尤其像FAIR那种地方，研究者更独立，重视发表，而不是去协调一整个庞大的工程项目。训练一个大型语言模型需要几十人协作搭建复杂的基础设施，而那种成果不会是一篇论文，所以那类文化对这事其实并不重视。</p> <p>Ankit Gupta：你提到你们有时要修改PyTorch底层实现，那你们是停留在高层API还是直接写CUDA？</p> <p>Nick Joseph：看情况。大多数操作我停留在torch.matmul这种层面，不去管矩阵乘法内部实现。但像注意力机制这种复杂操作，我们会深入优化底层，因为它在GPU上效率很难调。</p> <p>Ankit Gupta：那你们会先纸上推导理论效率，再实现？</p> <p>Nick Joseph：对。你其实可以用纸笔算出理论上能达到的最大效率（MFU）。效率差的原因通常就是显存带宽瓶颈、CPU传输瓶颈等等。这些约束项不多，也就六七个。建模清楚后再实现。实现后用profiler分析每步耗时，对比预期，再不断优化。</p> <p>Ankit Gupta：那时有现成的分析工具吗？</p> <p>Nick Joseph：单GPU的Python profiler已经不错，但成百上千GPU的分布式Profiling几乎没人做过，我们得自己改写分析器来聚合所有追踪数据。</p> <p>Ankit Gupta：那你这些都是怎么学的？</p> <p>Nick Joseph：我入职Anthropic时，内部资料还少，我第一天就把整个内部Wiki都读完了。然后主要靠结对编程学，像Tom Brown、Sam McCandlish这些人之前都做过。我跟他们大量结对，看他们怎么调Profiler、怎么排错。比如我以前从没用过调试器，只靠print调试，后来才发现PDB调试器的效率高太多。</p> <p>Ankit Gupta：后来你们的预训练规模越来越大，算力暴涨——那策略上发生了什么变化？</p> <p>Nick Joseph：其实变化不大，真的令人惊讶。到今天我还在盯着和当年一样的指标——损失函数。可以把五年前第一个模型的loss曲线和现在的放在一起看，核心目标一直没变。</p> <p>Ankit Gupta：所以你们的OKR就是“loss越低越好”？</p> <p>Nick Joseph：对，当然现在的变化是团队更专业化。早期我会看每个PR，知道所有模块；后来各模块分工更细，有人专攻attention，有人专攻并行策略。但这样带来一个挑战：要平衡“专家”和“通才”。如果全是通才，大家懂点皮毛没人精通；全是专家，又容易出现系统割裂，需要管理者去把体系连起来。我个人更喜欢保持平衡。</p> <p>Ankit Gupta：那在算力规模暴涨后，有没有遇到一些意想不到的挑战？</p> <p>Nick Joseph：有，比如最典型的——“连接问题”。当你要并联越来越多的GPU时，最小的硬件故障都可能导致整个训练崩溃。比如一台GPU坏了，整个模型就会挂掉。你可以想象，如果模型每层在不同GPU上，那掉一个“第七层”的GPU就意味着整个网络失效。</p> <p>还有一点，整个技术栈都太新，从芯片架构到数据中心布局都在快速演进。以前我写代码出错会想“肯定是我写错了”，但现在有时真的是“电脑错了”。比如有次GPU真的坏了，换了之后一切正常。如今你得考虑的变量太多：GPU可能有瑕疵、供电可能波动、数据中心线路可能老化等等，对一个Python程序员来说，这些都是意料之外的复杂性。</p> <p>Ankit Gupta：那早期你们单次训练大概用多少GPU？</p> <p>Nick Joseph：上千个，能塞进一个机房。现在则是一整栋楼、甚至园区。那时我们还在研究：这些GPU是不是得放在同一个房间？带宽要多少？供电能不能扛得住？有时候只是一个电容不足，都可能导致整个训练任务瞬间断电崩溃。</p> <p>Ankit Gupta：那么，你们是否需要考虑不同类型芯片之间的差异？我的意思是，你们和各种不同的云服务提供商都有合作。从你的角度来看，这些芯片只是计算资源吗？还是说如果你们使用TPU和GPU，它们就像谷歌的CPU和英伟达的GPU那样？作为工程师，你在使用这两者进行训练时，是否需要采取不同的思路？</p> <p>Nick Joseph：是的，从根本上来说，它们做的都是同样的事情，对吧？都是在进行计算。进行同一类操作、矩阵乘法等等。它们实现的方式相当不同，编程方式也很不同。而且实际规格也差别很大。有些芯片可能拥有很多浮点运算能力，但内存不多；有些可能内存带宽大，但内存容量有限。所以拥有多种芯片在某些方面很有优势，这意味着你可以根据任务特点选择最合适的芯片来执行。</p> <p>Ankit Gupta：比如，有些任务更适合在TPU集群上执行，而另一些更适合在NBHP集群上？你们会怎么选择？你可以谈谈这个。</p> <p>Nick Joseph：有趣，我举个例子，推理任务通常需要更多的HBM带宽，因为你在一次时间步中需要加载每个token的所有权重，这意味着需要很高的HBM带宽。而预训练通常更依赖于浮点运算，因为批量更大。所以你可以针对不同用途选择不同芯片。但拥有多种芯片的缺点是，你可能需要为每种芯片重复编写代码。理论上可以通过抽象层来统一，但实际差异太大，很难做到。因此如果你处理所有工作负载和所有芯片，工作量会按芯片数量成倍增加。</p> <p>Ankit Gupta：关于你提到计算机有时会出故障，我记得你之前做过类似事情。我当时公司在使用Google TPU时遇到一些奇怪的segfault错误，你告诉我一个有效的方法，如果六个月前用上它们，就能解决一半的问题。我可以想象，你们在使用这些非常新的芯片时，会遇到很多问题，需要和提供商紧密合作来解决。</p> <p>Nick Joseph：是的，项目组在解决问题上很积极。有趣的是如何找到合适的合作方式。他们有强烈动机去修复问题，因为希望芯片能正常工作，从而未来能卖更多芯片。我们当然也有很强动机让芯片工作，因为我们提前大量采购这些芯片。所有工作都建立在让集群正常运行的基础上，但我们不一定能共享所有信息。有些信息不能完全共享。因此一种策略是制作小规模复现环境，当遇到问题时，你可以在单芯片或单文件上复现，然后发给对方进行调试。</p> <p>Ankit Gupta：你们是在共享的Slack上交流，互相发送问题和数据吗？还是说你们和大厂的人员实际上在同一个办公室？</p> <p>Nick Joseph：主要是共享Slack，有时候见面更有效，但Slack是常用方式。</p> <p>合成数据风险、模型评估指标设计与价值嵌入博弈 Ankit Gupta：那我们谈谈近期预训练的现状。这几年，各家公司对预训练的关注似乎有所分散，除了预训练，还有后训练的强化学习、微调和安全性调整等。从外部看，预训练似乎相对不那么受关注，而推理类模型的进展主要依赖后训练。你怎么看？这种理解是否合理？在推理和新型后训练方法的时代，有没有预训练层面仍然重要的因素，对实现优秀模型有影响？</p> <p>Nick Joseph：以前预训练意味着做一个大规模训练，但其实已经有变化，比如直接进行大量自由训练，把大部分计算资源用于训练。现在人们发现强化学习也能带来很大收益，你可以把更多算力投入强化学习，从而得到更好的模型。因此如何平衡预训练和后训练、各自作用叠加还是互补，这些问题仍在早期阶段，还没有定论。</p> <p>Ankit Gupta：你认为这些更多是经验性问题吗？像我们之前讨论的，你会尝试多种方法看效果，还是有一些基于原理的方式来判断？</p> <p>Nick Joseph：最终还是经验为主。可以提出理论，但实践中大多数理论都需要验证，多半是错的。所以最可靠的办法是收集数据再做判断。解决问题的经验方法对于做出正确决策至关重要，但在组织内很难实现。关键是不要因为你管理预训练，就坚持预训练必须胜出。</p> <p>Ankit Gupta：团队间是否存在某种竞争？还是视为同一个整体？</p> <p>Nick Joseph：我们这边合作性很强，基本上是共同产出一个模型。但据我了解，有些公司团队间存在摩擦，这是一个有趣的组织设计问题：如何设置团队，避免科学问题被个人团队观念绑架。</p> <p>Ankit Gupta：关于预训练，你如何看待高质量数据的可用性？你们已经训练了几乎所有互联网文本。外界常说数据已经枯竭，是否如此？尤其当大量数据由AI生成时，是否存在模式崩塌风险，模型会过拟合AI生成数据？</p> <p>Nick Joseph：我对数据问题看到很多自信的说法。有人说互联网数据已经用尽，我不确定实际情况。数据的质量与数量总是有权衡。基本事实是数据量巨大，增长速度慢于算力增长。</p> <p>Ankit Gupta：也就是说，虽然新数据在增加，但算力也在增加，不容易判断哪个增长更快。</p> <p>Nick Joseph：我需要强调，我并不完全确定。一方面互联网似乎无限，你可以不断生成文本。但“有用的互联网”规模无人知晓。</p> <p>Ankit Gupta：我脑子里简单想法是，用PageRank过滤出有价值的网页，不是可行吗？</p> <p>Nick Joseph：我认为不完全可行。人眼认为有价值的内容与模型学习所需的有用信息不完全相同。有些内容虽然链接少，但对模型可能很重要，尤其是处理难题的尾部知识。</p> <p>Ankit Gupta：这是原始Google的链接算法。</p> <p>Nick Joseph：对，它是质量指标，但不一定是最优指标。</p> <p>Ankit Gupta：AI的任务可能不同。</p> <p>Nick Joseph：尾部数据可能更有价值，可以通过蒸馏或智能模型生成数据训练新模型，接近原始模型的智能水平。</p> <p>Ankit Gupta：开放源代码模型中小模型蒸馏大模型的例子很多。</p> <p>Nick Joseph：完全可行。问题是，如果用现有模型生成数据训练更好模型，可能无法超越原模型，因为你只是学到了原模型的分布。如果分布有误，新模型也不会学到真实知识。</p> <p>Ankit Gupta：这是因为下一个token预测的损失对原模型生成内容很低，对吧？</p> <p>Nick Joseph：没错。模型只会学到原分布，如果原分布错误，就学不到真理。例如模型认为5+5=11，新模型也会学到11。这是一个研究难点，因为小规模研究难以直接扩展到大规模训练。还有一层问题是互联网上大量内容由LLM生成，其影响不易量化。1%的LLM内容，会浪费1%的算力，还是破坏5%-10%的模型表现？难以判断。</p> <p>Ankit Gupta：这不一定坏吧？如果训练目标是从当前分布向真实分布靠近，互联网上流通的数据本身可能有助于校正。</p> <p>Nick Joseph：你说的是通过互联网自然过滤，可能有效，但垃圾内容和恶意内容仍存在，这会影响模型。</p> <p>Ankit Gupta：你之前提到评估指标，除了模型本身，还有数据质量等指标。有没有可以量化的数据和模型质量指标，除了损失函数？</p> <p>Nick Joseph：损失函数其实很有效。理想的评估应关注实际关心的目标，而不是代理指标；评估需低噪声、快速易用。三点标准缺一不可，但第一点最难：明确你关心的到底是什么。</p> <p>Ankit Gupta：即使微小差异在评估中也要能体现出来，以便优化方向。</p> <p>Nick Joseph：对，比如GPT-4的MLA分数86.4%，下一代Gemini90%，差异明显，可用于判断优劣。评估需快速执行且易于操作。</p> <p>Ankit Gupta：例如AI医生任务，考试题可能轻松通过，但实际长时间与患者交流、提取关键信息更难，这类评估难度高。</p> <p>Nick Joseph：确实。创业公司可以做这些评估，而大实验室往往只优化标准化指标。医生场景中，我认为可用真实医生与患者的对话记录训练，预测对话文本，低噪声，模型可用于辅助诊疗。</p> <p>Ankit Gupta：这可以作为创业项目。外部讨论排列时，你能定义排列吗？它在预训练中如何体现？</p> <p>Nick Joseph：我们目标是AGI，即能完成大部分人类能做的事情。Sci-fi常被误导，人类一般想象一个机器人，而实际上应是大量智能体复制。关键问题是AI的目标是什么，目前下一token预测是目标，但人类目标不同。排列就是让模型目标与人类一致。</p> <p>Ankit Gupta：这与人类目标不同。</p> <p>Nick Joseph：是的。排列可从理论或经验角度解决，现有模型往往不符合期望。另一层是实际控制模型行为，比如通过宪法式规则或系统提示来约束模型交互方式。</p> <p>Ankit Gupta：系统提示类似提词，而非训练时调整。</p> <p>Nick Joseph：可以训练时加入，也可通过系统提示，取决于所需鲁棒性。</p> <p>Ankit Gupta：如何选择模型体现哪些价值？</p> <p>Nick Joseph：这是个难题。比喻为装方向盘，先获取控制权，再考虑驾驶者是谁。最好有民主化的价值设定，而非单人价值，以避免走向极权。</p> <p>Ankit Gupta：现阶段，你们如何实现排列？是通过后训练调整模型人格吗？</p> <p>Nick Joseph：大体正确。后训练迭代快，效果反馈快，适合调整模型。预训练用于基础科学探索，小模型无法有效模拟复杂行为。</p> <p>Ankit Gupta：必须在足够智能的模型上进行。</p> <p>Nick Joseph：对，但某些排列可以融入预训练，增强鲁棒性和智能性，例如让模型在学习智能的过程中融入人类反馈。</p> <p>Ankit Gupta：这如何在预训练中体现？</p> <p>Nick Joseph：可参考论文《Pretraining on Human Feedback》，将人类反馈特性融入预训练，观察效果。但缺点是灵活性下降，无法在后训练中快速调整。</p> <p>Ankit Gupta：你提到迭代速度关键，三个月与一天的差距巨大，可在短时间内尝试多种后训练策略并行执行。</p> <p>Nick Joseph：完全正确，自由训练本质困难，因为一次训练周期长且不可中断。</p> <hr/> <h2 id="五agi之路范式转移焦虑架构变革与未来展望">五、AGI之路：范式转移焦虑、架构变革与未来展望</h2> <h3 id="51-未来最大的挑战范式转变与隐藏的bug">5.1 未来最大的挑战：范式转变与隐藏的Bug</h3> <p><strong>Ankit Gupta</strong>：所以我现在在想，未来几年你们打算做的事情，作为团队，你们是如何考虑的呢？比如，你们会遇到哪些已知的问题，必须去应对？</p> <p><strong>Nick Joseph</strong>：我觉得我最关注的可能是<strong>范式的转变</strong>。我认为向强化学习的转变就是一个领域内的范式变化。我认为未来可能还会出现更多变化。很多人会争论，比如说，现有的范式是否足够让我们达到通用智能。我不知道，也许够，但我几乎可以肯定还会有新的范式。</p> <p>如果结果只是简单地扩大规模，没有任何意外，那会非常令人惊讶。但我真正感到最紧张的，其实是一些<strong>非常难以解决的bug</strong>。</p> <p>Ankit Gupta：这很有意思。</p> <p>Nick Joseph：是的，可能有点出乎我意料，但一个bug就可能让你搁置几个月。因为模型训练需要几个月的时间，一个小小的代码错误可能导致整代模型失效，而且难以被发现。机器学习本身就很难找到bug，但在大规模系统中，这类问题更难解决。</p> <p>Ankit Gupta：是啊，有时候甚至不知道从哪里下手。比如你写一个网络架构，漏掉了单元测试，或者没办法写测试去覆盖这种架构，你该怎么验证呢？</p> <p>Nick Joseph：你可以发送一个数据包，确认它正常传输，或者用小模型训练试一下，但即使是小模型，也不明显。</p> <p>Ankit Gupta：如果早期做ML的人遇到过经典bug，比如网络有10层，层7连到了层9，而不是8到9，模型依然可以训练，权重也在更新，但架构实际上是错的。这类bug非常隐蔽，很难发现。你说的这些随机bug，是这个意思吗？</p> <p>Nick Joseph：对，就是这种情况。随着系统复杂度上升，你可能在某个底层内核里用了错误的精度，这会让大规模模型崩掉。</p> <p>Ankit Gupta：训练一个月后才发现，甚至可能永远都发现不了。</p> <p>Nick Joseph：对，有时候甚至永远不会发现。代码量成万行，你怎么排查？所以最让我担心的就是这种微妙而棘手的bug。有时候你会看到模型崩溃或者训练速度突然下降，这类问题也非常难调试。我记得Nelson Nelha曾遇到过一个“诅咒”的bug，我遇到它时就觉得很棘手，于是把它交给别人，一个月后才松了一口气，自己可能永远解决不了。</p> <p>我觉得一个非常有价值的能力是可以深入到任何层面去分析问题，但这是一项罕见技能。我在Torch底层工作过，如果不了解CUDA，Torch底层出问题，我就无法自己解决。通讯方面也是一样，我可以发送数据，但如果底层网络协议有问题，我必须学整个领域才能理解数据包和TCP等细节。能从ML学习动态到字节级别全栈掌握的人非常少。</p> <p>Ankit Gupta：完全理解。那你们团队成员的背景是怎样分布的？外界可能认为你们全是写论文的博士研究员，但我觉得事实可能并非如此。</p> <p>Nick Joseph：是的，团队混合多种背景。我们最需要的几乎一直都是工程师。在这个领域的历史中，往往只要算力足够，模型就能工作，真正的挑战是如何正确实现。</p> <p>Ankit Gupta：行动力是关键，对吧？</p> <p>Nick Joseph：没错。实现正确并非ML问题，架构其实很简单，你甚至不必完全理解数学，只要实现正确即可。然后你面临的工程问题是如何在大规模上并行化、验证正确性。这种工程技能是关键，但与快速迭代网站等技能不同，更偏向于解决极难工程问题。</p> <p>Ankit Gupta：你们找的工程师是有类似Anthropic经验的人，还是学术出身的人？</p> <p>Nick Joseph：目前我们倾向于直接聘请有相关经验的人。早期我们会从各种背景挑选，但现在领域足够大，有经验的人可以直接上手。也有一些非常聪明、勤奋的人可以快速学习，比如一些理论物理学家，他们通过实习掌握编程，也能做出出色工作。</p> <p>Ankit Gupta：我想换个话题，谈谈未来你对AI领域其他方向的看法。你怎么看非下一步预测的方向？比如不是用Transformer架构，或者非自回归训练，有没有值得关注的？</p> <p>Nick Joseph：我觉得这些很有趣，但我不认为自回归是唯一路径。不过，自回归可能足够达到EGI。主要驱动还是规模和对基础科学的精细研究，而不是完全新颖的架构。确实存在更优新颖方法，但规模更容易、可靠性更高，而且仍有很大提升空间。</p> <p>Ankit Gupta：你花很多时间研究开源论文，看到一些中国实验室对架构做优化，比如缓存或高效注意力机制。你觉得这些优化是“加算力就行”的小改进，还是可能像Transformer一样带来革命性变化，必要时才能实现AGI？</p> <p>Nick Joseph：我认为是两者结合。我的猜测是，你会不断调整，随着算力增加，实验价值也会提升。同时还有推理优化，比如服务大量用户时做出更低成本、高效率的推理，这涉及推理堆栈和芯片细节。</p> <p>Ankit Gupta：预训练团队是否需要考虑推理问题，还是只管降低loss，然后交给别人处理？</p> <p>Nick Joseph：不，我们非常关注推理问题。我们提供的模型必须快速运行，否则用户体验会受影响。</p> <p>Ankit Gupta：能举例说明吗？</p> <p>Nick Joseph：最简单的例子是把模型做得过大，推理会变慢，或者增加不必要的通信步骤，使推理复杂化。这并非技术难题，而是架构设计问题。</p> <p>Ankit Gupta：明白。</p> <p>Nick Joseph：推理团队是我最常合作的团队，因为我们共同设计模型，使其既聪明又经济高效。有限算力下，优化推理是服务更多用户的关键。</p> <p>Ankit Gupta：如果算力无限呢？</p> <p>Nick Joseph：即便算力无限，挑战也在于如何利用它。大规模系统会遇到芯片故障等工程问题。无限算力能大幅提升速度和实验频率，但仍需解决复杂工程问题。现在的AI研究非常受制于算力，算力限制了模型训练和迭代速度。</p> <p>Ankit Gupta：你怎么看Diffusion方法，比如Gemini diffusion模型？在蛋白质设计等领域应用广泛，你觉得有发展潜力吗？</p> <p>Nick Joseph：坦白说，我们没做过图像生成，主要是扩散模型用途。我自己理解不够深入，但团队中有人可以更好回答。我觉得这类方法属于“不是范式性转变，但可能带来运行效率提升”的类别。</p> <p>Ankit Gupta：那么在近期，如果Anthropic每年持续改进模型，你认为创业公司有哪些机会？</p> <p>Nick Joseph：任何能受益于模型智能提升的方向都有机会。虽然大公司算力和资源更强，但他们做的是通用系统，我们的目标是让创业公司用这些模型完成具体工作。关键是利用当前模型基础上稍加努力就能落地的应用，但要注意不要过度依赖搭建复杂脚手架，因为下一代模型可能不需要。</p> <p>Ankit Gupta：在训练堆栈中，有没有问题是如果有公司解决，我们会直接购买产品的？</p> <p>Nick Joseph：有很多。比如芯片计算错误，如果有初创公司能检测每块芯片的精确性并报告故障，非常有用。还有组织管理方面，如果有服务能帮快速扩展团队，管理人员招聘和组织问题，也很有价值。未来更值得关注的是AGI普及后的社会影响，如何让其积极造福世界，而不仅仅是经济增长。</p> <p>Ankit Gupta：非常认同。最后一个问题，如果回到10年前，你还是学生，正从经济学转向AI，你会给学生什么建议，尤其是想进入你现在这种岗位的学生？</p> <p>Nick Joseph：时间点不同，策略也不同。如果回到10年前，我会专注AI，特别是工程技能，而不仅仅是数学或理论ML文献。同时会关注AGI相关应用，这是我认为最重要的两件事。</p> <hr/> <h2 id="结语">结语</h2> <p>Nick Joseph的访谈为我们提供了一个难得的窗口，深入了解Anthropic预训练团队的核心思考与实践。从AI安全初心到技术路线选择，从万卡集群的工程挑战到对齐问题的深层思考，这次对话展现了一个预训练团队负责人的完整视角。</p> <p><strong>核心要点总结：</strong></p> <ol> <li><strong>算力是王道</strong>：预训练的核心就是推动损失函数下降，扩展定律已被证明在11个数量级上有效</li> <li><strong>工程能力关键</strong>：正确实现比理论创新更重要，全栈能力是稀缺资源</li> <li><strong>预训练与后训练的平衡</strong>：如何平衡两者仍在早期探索阶段，强化学习带来了新的范式转变</li> <li><strong>推理与训练并重</strong>：预训练团队必须考虑推理问题，模型要既聪明又经济高效</li> <li><strong>未来挑战</strong>：范式转变和隐藏的Bug是最大威胁，AGI的社会影响值得关注</li> </ol> <p>正如Nick所说，现在AI研究最大的瓶颈是计算资源受限，而非算法突破。在这个领域，工程实践的价值远远超过纸面上的理论创新。对于想要进入这个领域的年轻人来说，培养扎实的工程技能，保持对AGI应用的关注，将是最重要的两件事。</p> <hr/> <p><strong>原视频：</strong> <a href="https://www.youtube.com/watch?v=YFeb3yAxtjE">Anthropic Head of Pretraining on Scaling Laws, Compute, and the Future of AI</a></p> <table> <tbody> <tr> <td><strong>编译：</strong> Zhenning Du</td> <td><strong>来源：</strong> Z Potentials</td> </tr> </tbody> </table>]]></content><author><name></name></author><category term="blog"/><summary type="html"><![CDATA[Nick Joseph访谈：Anthropic预训练的核心思考与实践]]></summary></entry><entry><title type="html">徐扬生院士：人工智能时代的教育</title><link href="https://emigmo.github.io/blog/2025/xuyangsheng-CUHK-SZ/" rel="alternate" type="text/html" title="徐扬生院士：人工智能时代的教育"/><published>2025-10-05T00:00:00+00:00</published><updated>2025-10-05T00:00:00+00:00</updated><id>https://emigmo.github.io/blog/2025/xuyangsheng-CUHK-SZ</id><content type="html" xml:base="https://emigmo.github.io/blog/2025/xuyangsheng-CUHK-SZ/"><![CDATA[<h1 id="徐扬生院士人工智能时代的教育">徐扬生院士：人工智能时代的教育</h1> <p><em>演讲人：徐扬生（中国工程院院士、美国国家工程院外籍院士、香港中文大学（深圳）校长）</em><br/> <em>时间：2025年10月5日</em><br/> <em>地点：普通高中校长年会</em><br/> <em>来源：主旨报告</em></p> <hr/> <h2 id="目录">目录</h2> <ul> <li><a href="#人工智能时代的教育">人工智能时代的教育</a> <ul> <li><a href="#目录">目录</a></li> <li><a href="#引言教育的三个核心问题">引言：教育的三个核心问题</a></li> <li><a href="#一理解未来ai时代的本质特征">一、理解未来：AI时代的本质特征</a> <ul> <li><a href="#11-教育将受到最大冲击">1.1 教育将受到最大冲击</a></li> <li><a href="#12-人工智能的本质认知感知行动">1.2 人工智能的本质：认知、感知、行动</a></li> <li><a href="#13-人工智能与人类智能的七大差异">1.3 人工智能与人类智能的七大差异</a></li> <li><a href="#14-教育的真正重点比感情比创造比个性">1.4 教育的真正重点：比感情、比创造、比个性</a></li> </ul> </li> <li><a href="#二重新定义人才从会考试到真优秀">二、重新定义人才：从”会考试”到”真优秀”</a> <ul> <li><a href="#21-ai时代对人才的四项要求">2.1 AI时代对人才的四项要求</a></li> <li><a href="#22-当前教育的误区培养会考试的人">2.2 当前教育的误区：培养”会考试”的人</a></li> <li><a href="#23-真正优秀人才的四个维度">2.3 真正优秀人才的四个维度</a></li> </ul> </li> <li><a href="#三培养人才学思践悟">三、培养人才：学、思、践、悟</a> <ul> <li><a href="#31-学掌握学习的方法">3.1 学：掌握学习的方法</a></li> <li><a href="#32-思闲暇是思考的土壤">3.2 思：闲暇是思考的土壤</a></li> <li><a href="#33-践实践比学校更重要">3.3 践：实践比学校更重要</a></li> <li><a href="#34-悟事教人是教训">3.4 悟：事教人是教训</a></li> </ul> </li> <li><a href="#四教育改革的七个核心方向">四、教育改革的七个核心方向</a> <ul> <li><a href="#41-少教一点多育一点">4.1 少”教”一点，多”育”一点</a></li> <li><a href="#42-重理性轻记忆">4.2 重”理性”轻”记忆”</a></li> <li><a href="#43-增加实践环节践能生悟">4.3 增加实践环节：”践”能生”悟”</a></li> <li><a href="#44-培养创新人才学会提问">4.4 培养创新人才：学会提问</a></li> <li><a href="#45-加强艺术教育爱与美是生命支点">4.5 加强艺术教育：爱与美是生命支点</a></li> <li><a href="#46-文理融合跨学科发展">4.6 文理融合：跨学科发展</a></li> <li><a href="#47-观世界才能有世界观">4.7 观世界，才能有世界观</a></li> </ul> </li> <li><a href="#结语带着灵魂往前走">结语：带着灵魂往前走</a> <ul> <li><a href="#第一句话">第一句话</a></li> <li><a href="#第二句话">第二句话</a></li> </ul> </li> </ul> </li> </ul> <hr/> <h2 id="引言教育的三个核心问题">引言：教育的三个核心问题</h2> <p>今天现场有来自全国各地的中学校长，还有网上那么多关心教育事业的家长、同学、老师跟校长，我想把我这几十年来的一些思考跟大家分享。</p> <p>我做过中学老师，做过大学老师，做过大学校长，也教过大概三十几个国家的学生，所以有点感悟。同时我也在人工智能领域做了整整40年的研究工作，所以有一点点思考，跟大家分享。</p> <p><strong>教育是什么？</strong> 我把它定义为：<strong>教育是”为未来社会培养人才”</strong>。</p> <p>这里有两个关键词：</p> <ul> <li><strong>未来</strong>：未来到底是怎么样的？</li> <li><strong>人才</strong>：什么样的人算人才？</li> </ul> <p>由此引出第三个问题：<strong>怎么培养未来的人才？</strong></p> <p>今天就围绕这三个核心问题展开讨论。</p> <hr/> <h2 id="一理解未来ai时代的本质特征">一、理解未来：AI时代的本质特征</h2> <h3 id="11-教育将受到最大冲击">1.1 教育将受到最大冲击</h3> <p>教育，就是教书、育人。但我们需要重新审视这个定义。</p> <p><strong>学校还是教书最好的地方吗？</strong> 上个星期，我的一位美国朋友在硅谷跟我讨论这件事情。他说，教书，学校不是最好的地方。我非常吃惊，我说，哪里是最好的地方呢？他说你去看看网上，全是最好的课程，而且还都是免费的，为什么要把孩子送到学校来呢？</p> <p><strong>学校还是育人最好的地方吗？</strong> 在美国西部，有些家庭，大概十来个小孩，他们组成一个团体，做一个像小作坊这样的东西，来培养自己的孩子。</p> <blockquote> <p><strong>如果一个学校不知道教什么书，育什么样的人，那要我们学校干什么？</strong></p> </blockquote> <p>人工智能时代来了，<strong>最直接的冲击在哪里？教育。</strong></p> <p>为什么？因为人工智能可能是社会乃至人类历史上最重要的进展，整个社会要重构，社会阶层要重新划分，职业也会重新划分，会深深影响人类思想文明的走向，而教育就是为人类社会培养各阶层各领域的人才。</p> <h3 id="12-人工智能的本质认知感知行动">1.2 人工智能的本质：认知、感知、行动</h3> <p>人工智能是什么？实际上，<strong>人工智能就是仿照人的智能去做一些事情</strong>。</p> <p><strong>1. 认知</strong> — 怎么认识这个世界，怎么做判断。比如这是白衣服，白衣服大概是衬衣，衬衣大概是夏天穿的。这些都是判断、推理、决策。</p> <p><strong>2. 感知</strong> — 生活环境反馈给我们的信息。比如视觉、听觉，我们看到这个人穿白衣服，不是黑衣服。</p> <p><strong>3. 行动</strong> — 对感受到的世界有认知，有意愿去参与，就要付诸行动，比如走路、挥手。</p> <p>一个东西能够做到有认知的功能、感知的功能、行动的功能，合起来，我们叫作人工智能。</p> <p><strong>AI发展的现状：</strong></p> <ul> <li><strong>认知部分</strong>：尤其是大语言模型出来以后，做得很好，大家感觉真的是智能</li> <li><strong>感知部分</strong>：稍微差一点。比如打开一瓶茅台酒让它闻闻，这是不是酱香型的？它不一定懂</li> <li><strong>感情部分</strong>：更加不行</li> <li><strong>行动部分</strong>：进步很慢。我40年前开始做这件事情，到今天，进度非常之慢，目前状态跟二十几年前差不多</li> </ul> <p>现在都在讲具身智能，这个名字很好，也是我们提出来的。但很多人有点夸张。其实，<strong>现在的人工智能就是一个能说会道的残疾人</strong>。与人类共建社会是在将来，距离现在有多远，很难说。</p> <h3 id="13-人工智能与人类智能的七大差异">1.3 人工智能与人类智能的七大差异</h3> <p>很多人觉得，人工智能都比人聪明了，那人怎么办？朋友们，<strong>人工智能跟人的智能不是一回事</strong>。</p> <table> <thead> <tr> <th>维度</th> <th>人工智能</th> <th>人类智能</th> </tr> </thead> <tbody> <tr> <td><strong>知识与智慧</strong></td> <td>知道得越多越聪明</td> <td>知道得多不一定更聪明</td> </tr> <tr> <td><strong>时间取向</strong></td> <td>向后看（总结、整理）</td> <td>向前看（创造、预见）</td> </tr> <tr> <td><strong>智能分布</strong></td> <td>集中型智能</td> <td>分布性智能（全身都是智能体）</td> </tr> <tr> <td><strong>思维模式</strong></td> <td>重理性</td> <td>感性与理性结合</td> </tr> <tr> <td><strong>认知方式</strong></td> <td>重视分析与整合</td> <td>重视直觉与体验</td> </tr> <tr> <td><strong>心脑关系</strong></td> <td>重视脑</td> <td>心脑并用</td> </tr> <tr> <td><strong>个性通性</strong></td> <td>追求通性</td> <td>追求个性</td> </tr> </tbody> </table> <p><strong>一个重要的文化观察：</strong> 在中国文化里，”脑”这个字是月字旁，是身体的一部分，凡是身体一部分的字，都是月字旁，比如肝、脾、胃、胆。唯一一个例外是”心”。因为古人始终认为心不仅是人身体的一部分，”心”字有两点，一点在中心，是身体内的，另一点在旁，不在身体内。对人来说，心脑是并用的。</p> <p><strong>AI时代的危险：机器越来越像人，人越来越像机器</strong></p> <p>前一阵子，我让我的司机开车带我到广州一个地方见朋友。晚上11点，他一直开到一个大工地里面，下面全是水泥地，漆黑一片。我说这是什么地方？他说这是您叫我来的地方，GPS就导航到这里来了。</p> <blockquote> <p><strong>现在的人开车不去思考了，因为有GPS。人放弃思考是非常危险的，而思考是人区别于动物的唯一的东西。</strong></p> </blockquote> <p>人工智能时代的特征：</p> <ul> <li>获取知识的途径改变了</li> <li>整个社会将会趋于平庸</li> <li>10年以后，讲的话大家都差不多，个性没有了，观点没有了</li> </ul> <h3 id="14-教育的真正重点比感情比创造比个性">1.4 教育的真正重点：比感情、比创造、比个性</h3> <p>你不能跟AI比聪明，就像我们发明了汽车，我们不可以跟汽车比谁跑得快；我们也不能跟它比记忆，它记得比你好；我们跟它比知识，也比不过它。</p> <p><strong>那我们可以跟它比什么？</strong></p> <blockquote> <p><strong>比感情、比创造、比个性，这才是我们教育的真正重点。</strong></p> </blockquote> <h2 id="二重新定义人才从会考试到真优秀">二、重新定义人才：从”会考试”到”真优秀”</h2> <h3 id="21-ai时代对人才的四项要求">2.1 AI时代对人才的四项要求</h3> <p>人工智能时代对人才的要求：</p> <ol> <li><strong>领导力</strong> — 语言、沟通、判断、同理心</li> <li><strong>理性</strong> — 提问、分析、逻辑、批判性思维</li> <li><strong>创造力</strong> — 想象、艺术、探索能力</li> <li><strong>品性</strong> — 勇气、顽强、世界观、人文素养</li> </ol> <h3 id="22-当前教育的误区培养会考试的人">2.2 当前教育的误区：培养”会考试”的人</h3> <p>我分析了这几年的高考试卷，我们对人才的要求大概体现在高考卷子上面：</p> <table> <thead> <tr> <th>能力维度</th> <th>当前高考占比</th> <th>AI时代需求</th> </tr> </thead> <tbody> <tr> <td>记忆</td> <td>70%</td> <td>↓</td> </tr> <tr> <td>理性</td> <td>20%</td> <td>↑</td> </tr> <tr> <td>创造力</td> <td>5%</td> <td>↑↑</td> </tr> <tr> <td>品性</td> <td>5%</td> <td>↑↑</td> </tr> </tbody> </table> <p>不仅是文科的卷子，理科的卷子也是这样。化学、生物甚至物理卷子都基本上是这样，记忆占百分之六七十。</p> <blockquote> <p><strong>记忆好的人，高考成绩就好，而高考成绩好的，我们就叫他优秀人才——所以我们目前在培养的是会考试的人才。</strong></p> </blockquote> <h3 id="23-真正优秀人才的四个维度">2.3 真正优秀人才的四个维度</h3> <p>什么样的人才是真正优秀的？我总结了4条：</p> <ol> <li><strong>勤奋</strong> — 勤奋你才有动力</li> <li><strong>理性</strong> — 有主见，能思辨，能逻辑分析</li> <li><strong>创造性</strong> — 能创新，能突破</li> <li><strong>顽强</strong> — 能坚持，不放弃</li> </ol> <p><strong>中国学生的现状（我40年教育经验的观察）：</strong></p> <table> <thead> <tr> <th>能力</th> <th>中国学生表现</th> <th>对成功的重要性</th> </tr> </thead> <tbody> <tr> <td>勤奋</td> <td>★★★★☆</td> <td>15%</td> </tr> <tr> <td>理性</td> <td>★★★☆☆</td> <td>15%</td> </tr> <tr> <td>创造性</td> <td>★★☆☆☆</td> <td>30%</td> </tr> <tr> <td>顽强</td> <td>★☆☆☆☆</td> <td><strong>40%</strong></td> </tr> </tbody> </table> <p>很多人问我，你认识那么多聪明的人，优秀的人才有什么共同特点？<strong>一个非常明显的就是，他们无论在什么样的情况下都能够坚持下来。</strong></p> <p>我们中国内地的学生，勤奋是很好的，但顽强这点是最差的。我们看美国以及其他国家，比如印度、东南亚、欧洲跟南美一些国家，根据我的观察，他们的理性、勤奋可能不如我们，但他们能坚持，顽强性比较好。他们不怕批评，明天照样继续坚持做。</p> <h2 id="三培养人才学思践悟">三、培养人才：学、思、践、悟</h2> <p>我们到底该怎么来培养人才呢？我认为大概是这4个过程：<strong>学、思、践、悟</strong>。</p> <h3 id="31-学掌握学习的方法">3.1 学：掌握学习的方法</h3> <p>学是不容易的，要有好奇心，有兴趣。没有兴趣，学到最后还给老师了。我们学的东西是前人的东西。学习要专注，要学会学习方法。</p> <blockquote> <p><strong>Learn how to learn，这是最重要的。</strong></p> </blockquote> <p>因为大多数知识到最后，不是老师教的，是你自己学的。我的经验是，<strong>90%以上的知识都不是老师教授的，是你自己学的</strong>。所以要培养自己学习的能力，在学校要系统地教学生这样的能力。</p> <h3 id="32-思闲暇是思考的土壤">3.2 思：闲暇是思考的土壤</h3> <p>学完了以后你要能够去思考。有一位领导问我，怎么让我们的孩子们真正能够思考？我说，给他们点空余时间。</p> <p>他们晚上睡觉之前是否有一个小时是自由的时间？你去想一想，如果没有闲暇的时间，人怎么会思考呢？</p> <blockquote> <p><strong>闲暇的时间是思考的土壤，没有土壤你怎么能成长呢？</strong></p> </blockquote> <h3 id="33-践实践比学校更重要">3.3 践：实践比学校更重要</h3> <p>今天我会着重讲这个事情。<strong>人工智能教育本质上就是人的教育，实践的教育，创新的教育，如果不重视实践的话，根本谈不上人工智能教育。</strong></p> <p>人工智能时代，体验是重要的。优秀教育的效果主要看体验。实践本身就是一所学校，甚至实践比学校更重要。</p> <p>中国的同学欠缺就欠缺在实践这里，没有实践，那就把知识全部还给了老师：</p> <ul> <li>学，不是你的东西</li> <li>思考，无非你想过而已</li> <li>没有实践，光靠课堂教学，学到的就会全部还给老师，你悟不出来</li> </ul> <blockquote> <p><strong>因为只有践，才能生悟。</strong></p> </blockquote> <h3 id="34-悟事教人是教训">3.4 悟：事教人是教训</h3> <blockquote> <p><strong>人教人是知识，事教人是教训。</strong></p> </blockquote> <p>只有通过实践，你才能真正领悟在你一生中应该记住的东西。</p> <h2 id="四教育改革的七个核心方向">四、教育改革的七个核心方向</h2> <p>人工智能时代的教育改革，应该往以下几个核心方向走。</p> <h3 id="41-少教一点多育一点">4.1 少”教”一点，多”育”一点</h3> <p>我们要把重心放在育人上，而不在教书上。现在，我们全社会的人，包括你们，包括我，都应该问一下我们自己：<strong>我们是知道的太多了，还是知道的太少了？</strong></p> <p>每天晚上睡觉的时候我在想：我今天看了那么多东西，有多少是我应该看到的，有多少其实我不应该看到？我大概算了算，有60%是我不应该看到的，40%是我应该看到的。大多数人估计还达不到这个程度，估计80%～20%之间。</p> <blockquote> <p><strong>信息与知识把我们每一个人的脑袋占得太满了。</strong></p> </blockquote> <p>我的一个学生问我，你认识那么多有智慧的人，你告诉我这些有智慧的人跟我们一般的人有什么差别？我想来想去，有一个差别：<strong>他们知道得很少</strong>。</p> <ul> <li>因为知道很少，他们就能专注</li> <li>因为专注，他们就能出成果</li> </ul> <p>所以我们教的东西不用教得太多，你把核心的东西教给人家就可以了。</p> <p><strong>为什么读书越多越不容易创新？</strong></p> <p>这个问题我思考了13年，我把它想清楚了。因为人的脑袋是有容量的，你装东西都装满了以后，脑袋里面会有一个固定的”程式”，这个程式决定了，每当出现新的问题，他会习惯用已有的程式来处理这些新问题。换言之，<strong>他会把所有新的问题都当作这个程式能够处理的旧问题</strong>。</p> <p>举例：</p> <ul> <li>你问一个学生问题，他首先想到的是上网去找一找——他在假定人家已经问过这个问题了</li> <li>我带一个博士生，我跟他说某个课题应该怎么做。他第一时间就问我，教授，你告诉我，有没有参考文献？</li> </ul> <p>参考文献是什么？那是与这个课题有关的、人家已经做过的工作，当然应该知道点。但假如这个工作是你第一个开始做的，你就没有参考文献。</p> <p>朋友们，这不是小事情。<strong>任何一个人，如果你去问他一个事情，他都是假定人家已经碰到过这件事情，他就没有意愿去创新了。</strong></p> <p><strong>读书越多的三个负面效应：</strong></p> <ol> <li><strong>胆子越小</strong> — 了解太多案例，越小心谨慎，越害怕失败</li> <li><strong>大趋势越不清楚，小事情越清楚</strong> — 被细节困住</li> <li><strong>越来越成为小心翼翼的观察者，而不是勇敢的实践者</strong></li> </ol> <h3 id="42-重理性轻记忆">4.2 重”理性”轻”记忆”</h3> <p>理性其实比记忆重要得多。但是我们目前的教育是倾向于记忆，我们要把重心转移到理性的思辨能力的培养上来，要培养学生的科学思维、科学精神。</p> <p>我走了100所中学，我很清楚地告诉大家，有些中学做得蛮好的，在全世界的中学里都是好的，有些则不是。</p> <p><strong>中学需要做的：</strong></p> <ul> <li>加强理性分析的课程内容和考试要求</li> <li>加强对学生综合分析能力的培养</li> <li>数理的教学要<strong>提高深度，而不是广度</strong></li> <li>加强跨学科的课程教学</li> <li>加强学生理性分析辩论的兴趣小组</li> </ul> <h3 id="43-增加实践环节践能生悟">4.3 增加实践环节：”践”能生”悟”</h3> <p><strong>实践比学校重要。</strong> 人工智能教育，如果不重视实践的话，你最后要损失很多东西。我们要培养具有伟大格局的实践者。</p> <p>朋友们，你去看看，我们每天在看的网上的所有信息，都是在观察人家，看看A在说什么，B在做什么，C在做什么，哪个好哪个不好，在那里评论。</p> <blockquote> <p><strong>评论家很多，观察家很多，实践家很少。</strong></p> </blockquote> <p>体验是AI时代首要的教育重点。人教人是知识，事教人是教训。没有教训就没有实践经验，孩子长不大，所以我们的孩子普遍晚熟。</p> <p><strong>一个有趣的对比：</strong></p> <p>我们这个学校是国际大学，有很多国家的学生，各个国家学生跟我们国内的学生混在一起，你去看，他们总是比我们的孩子要成熟一点。我们的孩子，有什么事情都要跟爸爸妈妈商量一下，他们从来不是这样，可以自己做决定。</p> <blockquote> <p><strong>我们的孩子普遍晚熟，我们的家长普遍早熟。</strong></p> </blockquote> <p>小孩子还没长大，我们的家长就什么事情都给他想好了——”我这个孩子数学不行，以后不知道能不能到银行里面去工作？”他还是三年级的小学生啊，家长就这么想。</p> <p><strong>家长的早熟决定了孩子的晚熟</strong>，因为什么都给他想好了，孩子没有机会能自己做一些事情。</p> <p><strong>一个值得赞赏的案例：</strong> 我们有一个同事，他的孩子考上了全世界最好的大学之一。在上大学之前，他让孩子去非洲支教，很多人想不通。他跟我说，我举双手赞成，你这个孩子以后一定有出息。</p> <h3 id="44-培养创新人才学会提问">4.4 培养创新人才：学会提问</h3> <p>创新并不是你想创新就可以创新的。<strong>创新是一种文化</strong>，我们的社会，这种文化有没有呢？教育是这种文化的体现。</p> <p><strong>中国文化当中创新为什么比较困难？三个根源：</strong></p> <p><strong>1. 过于重实用</strong></p> <p>什么东西一出来，首先想有没有用。做个机器人出来了，人家说机器人干什么用？我做一个爬树机器人，他们就问爬树为什么要用机器人？</p> <p>实用当然是重要的，但你光想着实用价值，你就会停留在那个实用上面，就不会去深入了解后面的东西了。我们看到了烟花和炸药，不会想到它背后的化学，不会深入去研究，创新就被阻碍了。</p> <p><strong>2. 对传承的纠结</strong></p> <p>中国人一讲到创新就想到传承。我的感悟，世界上那么多创新，不是所有东西都是要通过传承的，有的是直接可以创新的。</p> <p><strong>3. 认识论上的不严格性</strong></p> <p>在我们中国文化当中，认识论是不严格的，而且非常严重。在西方的哲学里，包括苏格拉底，提出一个事情后会问你：为什么可以这样说呢？中国人是不讲的，不过庄子是个例外。这使人不会深究，创新就有困难了。</p> <blockquote> <p><strong>人工智能时代最大的挑战就是培养创新人才。在座的校长们，你们是中国的希望，中国的希望在10岁到30岁的人当中，而你们肩负着培养这一代人的任务。</strong></p> </blockquote> <p><strong>创新的三个条件：</strong></p> <ol> <li> <p><strong>不满</strong> — 鲁迅先生讲”不满是向上的车轮”，一个人对所有东西都满意的话，他还创什么新？创新就是打破格局。不满就是要提出问题来。</p> </li> <li> <p><strong>想象</strong> — 如果没有想象能力是无法创新的。想象是怎么来的？是跟艺术有关，跟跨学科有关。</p> </li> <li> <p><strong>自由</strong> — 要有面对现实，完全自由的、充分想象的能力。</p> </li> </ol> <blockquote> <p><strong>人工智能时代的教育要教我们的孩子学会提问，提问本身就是创新的一个元素。</strong></p> </blockquote> <h3 id="45-加强艺术教育爱与美是生命支点">4.5 加强艺术教育：爱与美是生命支点</h3> <p>我在不同的场合都讲过，<strong>艺术是了不起的</strong>。</p> <p>我走了100所中学，大概有25所中学是符合艺术教育方面的要求的，欧洲的学校、美国的学校做得比我们好。艺术教育的严重缺乏，将影响我们下一代的整体素质。</p> <blockquote> <p><strong>因为缺少爱是一个生命的缺陷，一个孩子，永远有一个生命的缺陷在那里，这是多么遗憾的一件事情。</strong></p> </blockquote> <p><strong>世界上有两样东西使我们的生活值得苟且，那就是爱与美。</strong></p> <p>这是生命的支点，生命退到最后退不过去的那点，而这两点，都跟艺术有关。如果不懂艺术的话，生命的支点就没有了，情感世界塌陷了。</p> <p>而在理性世界当中，<strong>艺术是创造力的源泉</strong>，所以艺术是很重要的东西。未来社会可能会有一半的生活跟艺术有关。</p> <h3 id="46-文理融合跨学科发展">4.6 文理融合：跨学科发展</h3> <p>这句话好像是跟大学讲的，但其实我是对中学讲的。<strong>文科跟理科是一个世界的两面，不是两个世界。</strong></p> <p>现在教孩子们是两个世界，所以造成了：</p> <ul> <li>理科生严重缺乏人文素养</li> <li>文科生的就业产生了很大的困难</li> </ul> <p>所以：</p> <ul> <li>要让我们的理科生能够欣赏文科</li> <li>要让文科生了解理科</li> <li>AI是不分文理、跨学科的</li> </ul> <blockquote> <p><strong>学校的目的是提供完整的教育，启发完整的人格。从这个意义上讲，文理是不应该分科的。</strong></p> </blockquote> <h3 id="47-观世界才能有世界观">4.7 观世界，才能有世界观</h3> <p>我跟你们讲一个小小的故事。以前我在香港教书的时候，有一群香港学生来跟我讲世界观。</p> <ul> <li>我问一个同学：你是哪里人？——我是番禺人。</li> <li>番禺是哪个省的？——不知道。</li> <li>旁边一个女同学说：我妈妈说我是中山人。</li> <li>你知道为什么那个地方叫中山吗？——不知道。</li> <li>去过中国内地吗？——回乡证里注着15年前去过。</li> </ul> <p>15年当中，中国内地发生了巨大的变化。我说那世界上你还去过什么地方呢？”我其实没去过世界什么地方，我就在沙田这一带。”</p> <blockquote> <p><strong>我说你下次跟我讲的时候，你就跟我讲”沙田观”，你不要讲”世界观”了。</strong></p> </blockquote> <p><strong>一个人的世界观很重要，但世界观怎么来？世界观是从观世界中来。</strong></p> <p>要让学生们：</p> <ul> <li>长见识</li> <li>有全球眼光</li> <li>有同理心</li> <li>有审视世界的能力</li> <li>用世界的眼光看中国</li> <li>更要用中国的精神来引导世界</li> </ul> <hr/> <h2 id="结语带着灵魂往前走">结语：带着灵魂往前走</h2> <p>总结一下我刚才讲的几个观点：</p> <blockquote> <p><strong>人工智能时代的教育，是人的教育，是实践的教育，是创新的教育。</strong></p> </blockquote> <p>最后我用两句话，来结束我的演讲。</p> <h3 id="第一句话">第一句话</h3> <blockquote> <p><strong>人类因为创造了人工智能而伟大，因为知道人工智能的局限而成熟。</strong></p> </blockquote> <p>创造了人工智能，可能是人类历史上最伟大的贡献。所有人，连我也不知道，后面可能会发生什么。以前我们所知道的是人是在进化的，生物是进化的，现在说地球也是在进化的，整个宇宙都是在进化的。</p> <p>人类是不是已经创造了人工智能？现在只是在中途，刚刚开始；人类是不是知道人工智能的局限，如何来面对这些局限性，都在考验人类的智慧和成熟。</p> <h3 id="第二句话">第二句话</h3> <blockquote> <p><strong>对世界文明的真正贡献不在于人口多少，不在于高楼大厦，不在于科技发展，是在这个国家和这个地区造就了什么样的人。</strong></p> </blockquote> <p>所以在座的各位任重道远，世界走得很快，<strong>要教育我们的孩子，带着灵魂往前走。</strong></p> <p>谢谢各位。</p> <hr/> <p><strong>注释：</strong> 本文根据中国工程院院士、美国国家工程院外籍院士、香港中文大学（深圳）校长徐扬生在普通高中校长年会（2025）上的主旨报告《人工智能时代的教育》整理而成。</p> <p>关注我，点击最上端的蓝字”徐扬生”或长按识别二维码关注</p> <p>Image</p>]]></content><author><name></name></author><category term="blog"/><summary type="html"><![CDATA[徐扬生院士：人工智能时代的教育]]></summary></entry></feed>